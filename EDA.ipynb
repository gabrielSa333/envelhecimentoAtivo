{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb3ce5b",
   "metadata": {},
   "source": [
    "# An√°lise Explorat√≥ria de Dados: Envelhecimento Ativo no Brasil\n",
    "\n",
    "## O que √© este notebook?\n",
    "\n",
    "Este documento apresenta uma an√°lise completa sobre o **envelhecimento ativo** no Brasil, utilizando dados da Pesquisa Nacional de Sa√∫de (PNS 2019). Aqui, transformamos dados complexos em insights pr√°ticos para orientar pol√≠ticas p√∫blicas e a√ß√µes sociais.\n",
    "\n",
    "### Por que isso importa?\n",
    "\n",
    "O Brasil est√° envelhecendo rapidamente. Em 2019, havia mais de 30 milh√µes de pessoas com 60 anos ou mais. Garantir que esses idosos tenham uma vida digna, saud√°vel e participativa √© um desafio nacional que exige dados precisos e a√ß√µes direcionadas.\n",
    "\n",
    "### O que vamos descobrir?\n",
    "\n",
    "Ao longo desta an√°lise, responderemos perguntas como:\n",
    "- Como est√° a qualidade de vida dos idosos brasileiros?\n",
    "- Quais munic√≠pios mais precisam de aten√ß√£o?\n",
    "- Quais fatores influenciam o envelhecimento saud√°vel?\n",
    "- Existem grupos diferentes de idosos com necessidades distintas?\n",
    "\n",
    "### Como funciona o √çndice de Envelhecimento Ativo (AAI)?\n",
    "\n",
    "Criamos um \"term√¥metro\" chamado AAI que mede o envelhecimento ativo combinando quatro pilares principais:\n",
    "1. **Sa√∫de**: Capacidade funcional e controle de doen√ßas cr√¥nicas\n",
    "2. **Participa√ß√£o Social**: Engajamento comunit√°rio e acesso a redes de apoio\n",
    "3. **Seguran√ßa Econ√¥mica**: Renda adequada e prote√ß√£o social\n",
    "4. **Educa√ß√£o e Acesso**: Conhecimento e conectividade digital\n",
    "\n",
    "Cada pilar recebe uma nota de 0 a 1, e o AAI final √© a m√©dia desses pilares.\n",
    "\n",
    "### Nossa abordagem rigorosa\n",
    "\n",
    "Usamos t√©cnicas estat√≠sticas avan√ßadas para garantir que os resultados representem toda a popula√ß√£o idosa brasileira, n√£o apenas as pessoas entrevistadas. Isso inclui:\n",
    "- **Pesos amostrais**: Para corrigir diferen√ßas na probabilidade de sele√ß√£o\n",
    "- **Intervalos de confian√ßa**: Para mostrar a precis√£o das nossas estimativas\n",
    "- **Bootstrap**: Para validar a robustez dos resultados\n",
    "\n",
    "---\n",
    "\n",
    "*Este notebook foi desenvolvido para ser acess√≠vel a gestores p√∫blicos, profissionais de sa√∫de, pesquisadores e qualquer pessoa interessada em melhorar a qualidade de vida dos idosos brasileiros.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f20bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>estrato</th>\n",
       "      <th>upa</th>\n",
       "      <th>id_domicilio</th>\n",
       "      <th>num_pessoas_domicilio</th>\n",
       "      <th>area_metropolitana</th>\n",
       "      <th>mora_sozinho</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>raca_cor</th>\n",
       "      <th>...</th>\n",
       "      <th>iadl_score</th>\n",
       "      <th>functional_raw</th>\n",
       "      <th>functional_score</th>\n",
       "      <th>dependencia_SUS</th>\n",
       "      <th>cobertura_influenza</th>\n",
       "      <th>autoav_z</th>\n",
       "      <th>multimorb_z</th>\n",
       "      <th>functional_z</th>\n",
       "      <th>health_score_raw</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C√¥njuge ou companheiro(a)</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Outro morador</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.522010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>1.200084</td>\n",
       "      <td>3.196276</td>\n",
       "      <td>3.167954</td>\n",
       "      <td>0.744213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>-0.146557</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.856293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uf  estrato        upa  id_domicilio  num_pessoas_domicilio  \\\n",
       "0  Rond√¥nia  1110011  110000016             1                      1   \n",
       "1  Rond√¥nia  1110011  110000016             1                      1   \n",
       "2  Rond√¥nia  1110011  110000016             1                      1   \n",
       "3  Rond√¥nia  1110011  110000016             1                      1   \n",
       "4  Rond√¥nia  1110011  110000016             1                      1   \n",
       "\n",
       "   area_metropolitana               mora_sozinho       sexo  idade raca_cor  \\\n",
       "0                   1  C√¥njuge ou companheiro(a)  Masculino   69.0    Parda   \n",
       "1                   1              Outro morador   Feminino   78.0    Parda   \n",
       "2                   1       Pessoa de refer√™ncia  Masculino   81.0    Parda   \n",
       "3                   1       Pessoa de refer√™ncia  Masculino   81.0    Parda   \n",
       "4                   1       Pessoa de refer√™ncia   Feminino   72.0    Parda   \n",
       "\n",
       "   ... iadl_score  functional_raw  functional_score dependencia_SUS  \\\n",
       "0  ...          7              18              0.10               0   \n",
       "1  ...          5              17              0.15               0   \n",
       "2  ...          2               9              0.55               0   \n",
       "3  ...          7              19              0.05               0   \n",
       "4  ...          7              16              0.20               0   \n",
       "\n",
       "  cobertura_influenza  autoav_z multimorb_z functional_z health_score_raw  \\\n",
       "0                   0       NaN   -1.027069     0.187726              NaN   \n",
       "1                   0       NaN   -1.027069     0.522010              NaN   \n",
       "2                   2 -0.344963    1.200084     3.196276         3.167954   \n",
       "3                   2 -0.344963    0.795147    -0.146557        -0.559990   \n",
       "4                   0       NaN   -1.027069     0.856293              NaN   \n",
       "\n",
       "  health_score  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2     0.744213  \n",
       "3     0.305083  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/processed/pns_2019_pandas.csv\")    \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adcc9f",
   "metadata": {},
   "source": [
    "# An√°lise Avan√ßada do √çndice de Envelhecimento Ativo (AAI) - PNS 2019\n",
    "\n",
    "Este notebook realiza uma an√°lise completa dos dados da Pesquisa Nacional de Sa√∫de (PNS 2019) para construir e validar o √çndice de Envelhecimento Ativo (AAI) no Brasil. \n",
    "\n",
    "**Objetivos principais:**\n",
    "- Construir um √≠ndice multidimensional de envelhecimento ativo\n",
    "- Identificar munic√≠pios priorit√°rios para interven√ß√µes\n",
    "- Analisar desigualdades por subgrupos populacionais\n",
    "- Desenvolver modelos preditivos de vulnerabilidade\n",
    "\n",
    "**Metodologia:**\n",
    "- An√°lise survey-aware com pesos amostrais\n",
    "- Intervalos de confian√ßa via bootstrap\n",
    "- Agrega√ß√£o municipal com controle de qualidade\n",
    "- Modelagem preditiva com valida√ß√£o cruzada\n",
    "\n",
    "**Outputs esperados:**\n",
    "- Scores municipais com intervalos de confian√ßa\n",
    "- Lista de munic√≠pios priorit√°rios\n",
    "- Perfis de envelhecimento via clustering\n",
    "- Drivers de vulnerabilidade identificados\n",
    "- Policy brief automatizado\n",
    "- Visualiza√ß√µes e datasets processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b30d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas dispon√≠veis no df:\n",
      "['uf', 'estrato', 'upa', 'id_domicilio', 'num_pessoas_domicilio', 'area_metropolitana', 'mora_sozinho', 'sexo', 'idade', 'raca_cor', 'situacao_ocupacional', 'anos_estudo', 'renda_percapita', 'possui_plano_saude', 'consulta_12m', 'internacoes_12m', 'atendimento_sus', 'dificuldade_alimentar', 'dificuldade_banho', 'dificuldade_vestir', 'ajuda_adl', 'dificuldade_compras', 'dificuldade_medico', 'ajuda_iadl', 'queda_12m', 'usa_internet', 'usa_celular', 'depressao_diag', 'vacina_influenza', 'autoavaliacao_saude', 'peso_real', 'altura', 'atividade_fisica', 'fumante_atual', 'hipertensao', 'diabetes', 'doenca_cardiaca', 'avc', 'doenca_respiratoria', 'cancer', 'num_medicamentos', 'id_individuo', 'area_urbana', 'peso_amostral', 'regiao', 'imc', 'multimorbidity_count', 'multimorb_cat', 'adl_score', 'iadl_score', 'functional_raw', 'functional_score', 'dependencia_SUS', 'cobertura_influenza', 'autoav_z', 'multimorb_z', 'functional_z', 'health_score_raw', 'health_score']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colunas dispon√≠veis no df:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca89c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>estrato</th>\n",
       "      <th>upa</th>\n",
       "      <th>id_domicilio</th>\n",
       "      <th>num_pessoas_domicilio</th>\n",
       "      <th>area_metropolitana</th>\n",
       "      <th>mora_sozinho</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>raca_cor</th>\n",
       "      <th>situacao_ocupacional</th>\n",
       "      <th>anos_estudo</th>\n",
       "      <th>renda_percapita</th>\n",
       "      <th>possui_plano_saude</th>\n",
       "      <th>consulta_12m</th>\n",
       "      <th>internacoes_12m</th>\n",
       "      <th>atendimento_sus</th>\n",
       "      <th>dificuldade_alimentar</th>\n",
       "      <th>dificuldade_banho</th>\n",
       "      <th>dificuldade_vestir</th>\n",
       "      <th>ajuda_adl</th>\n",
       "      <th>dificuldade_compras</th>\n",
       "      <th>dificuldade_medico</th>\n",
       "      <th>ajuda_iadl</th>\n",
       "      <th>queda_12m</th>\n",
       "      <th>usa_internet</th>\n",
       "      <th>usa_celular</th>\n",
       "      <th>depressao_diag</th>\n",
       "      <th>vacina_influenza</th>\n",
       "      <th>autoavaliacao_saude</th>\n",
       "      <th>peso_real</th>\n",
       "      <th>altura</th>\n",
       "      <th>atividade_fisica</th>\n",
       "      <th>fumante_atual</th>\n",
       "      <th>hipertensao</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>doenca_cardiaca</th>\n",
       "      <th>avc</th>\n",
       "      <th>doenca_respiratoria</th>\n",
       "      <th>cancer</th>\n",
       "      <th>num_medicamentos</th>\n",
       "      <th>id_individuo</th>\n",
       "      <th>area_urbana</th>\n",
       "      <th>peso_amostral</th>\n",
       "      <th>regiao</th>\n",
       "      <th>imc</th>\n",
       "      <th>multimorbidity_count</th>\n",
       "      <th>multimorb_cat</th>\n",
       "      <th>adl_score</th>\n",
       "      <th>iadl_score</th>\n",
       "      <th>functional_raw</th>\n",
       "      <th>functional_score</th>\n",
       "      <th>dependencia_SUS</th>\n",
       "      <th>cobertura_influenza</th>\n",
       "      <th>autoav_z</th>\n",
       "      <th>multimorb_z</th>\n",
       "      <th>functional_z</th>\n",
       "      <th>health_score_raw</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C√¥njuge ou companheiro(a)</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Ocupado</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Outro morador</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>N√£o aplic√°vel</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.522010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>N√£o aplic√°vel</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>1</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>Muito boa</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o, mas j√° fumou</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>0</td>\n",
       "      <td>117.758255</td>\n",
       "      <td>Norte</td>\n",
       "      <td>123.456790</td>\n",
       "      <td>11</td>\n",
       "      <td>3+</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>1.200084</td>\n",
       "      <td>3.196276</td>\n",
       "      <td>3.167954</td>\n",
       "      <td>0.744213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Desocupado</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>Muito boa</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o, mas j√° fumou</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>0</td>\n",
       "      <td>117.758255</td>\n",
       "      <td>Norte</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>3+</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>-0.146557</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rond√¥nia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de refer√™ncia</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Fora da for√ßa de trabalho</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>N√£o sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.856293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uf  estrato        upa  id_domicilio  num_pessoas_domicilio  \\\n",
       "0  Rond√¥nia  1110011  110000016             1                      1   \n",
       "1  Rond√¥nia  1110011  110000016             1                      1   \n",
       "2  Rond√¥nia  1110011  110000016             1                      1   \n",
       "3  Rond√¥nia  1110011  110000016             1                      1   \n",
       "4  Rond√¥nia  1110011  110000016             1                      1   \n",
       "\n",
       "   area_metropolitana               mora_sozinho       sexo  idade raca_cor  \\\n",
       "0                   1  C√¥njuge ou companheiro(a)  Masculino   69.0    Parda   \n",
       "1                   1              Outro morador   Feminino   78.0    Parda   \n",
       "2                   1       Pessoa de refer√™ncia  Masculino   81.0    Parda   \n",
       "3                   1       Pessoa de refer√™ncia  Masculino   81.0    Parda   \n",
       "4                   1       Pessoa de refer√™ncia   Feminino   72.0    Parda   \n",
       "\n",
       "        situacao_ocupacional  anos_estudo  renda_percapita possui_plano_saude  \\\n",
       "0                    Ocupado          6.0           1200.0                N√£o   \n",
       "1              N√£o aplic√°vel          6.0           1200.0                N√£o   \n",
       "2              N√£o aplic√°vel          5.0           1200.0                N√£o   \n",
       "3                 Desocupado          5.0           1200.0                N√£o   \n",
       "4  Fora da for√ßa de trabalho          6.0           1200.0                N√£o   \n",
       "\n",
       "    consulta_12m  internacoes_12m atendimento_sus       dificuldade_alimentar  \\\n",
       "0  N√£o se aplica                1             N√£o  N√£o consegue de modo algum   \n",
       "1  N√£o se aplica                1             N√£o  N√£o consegue de modo algum   \n",
       "2       N√£o sabe                1             N√£o         Nenhuma dificuldade   \n",
       "3  N√£o se aplica                1             N√£o  N√£o consegue de modo algum   \n",
       "4  N√£o se aplica                1             N√£o           Muita dificuldade   \n",
       "\n",
       "            dificuldade_banho          dificuldade_vestir ajuda_adl  \\\n",
       "0  N√£o consegue de modo algum           Muita dificuldade       N√£o   \n",
       "1  N√£o consegue de modo algum  N√£o consegue de modo algum       N√£o   \n",
       "2           Muita dificuldade           Muita dificuldade       Sim   \n",
       "3  N√£o consegue de modo algum  N√£o consegue de modo algum       NaN   \n",
       "4           Muita dificuldade           Muita dificuldade       N√£o   \n",
       "\n",
       "          dificuldade_compras   dificuldade_medico ajuda_iadl queda_12m  \\\n",
       "0  N√£o consegue de modo algum    Muita dificuldade        N√£o       N√£o   \n",
       "1  N√£o consegue de modo algum  Nenhuma dificuldade        Sim       Sim   \n",
       "2         Nenhuma dificuldade  Nenhuma dificuldade        Sim       Sim   \n",
       "3  N√£o consegue de modo algum    Muita dificuldade        N√£o       N√£o   \n",
       "4  N√£o consegue de modo algum    Muita dificuldade        Sim       N√£o   \n",
       "\n",
       "  usa_internet usa_celular depressao_diag vacina_influenza  \\\n",
       "0          N√£o         N√£o       N√£o sabe         N√£o sabe   \n",
       "1          N√£o         N√£o       N√£o sabe         N√£o sabe   \n",
       "2          Sim         N√£o       N√£o sabe              N√£o   \n",
       "3          Sim         N√£o       N√£o sabe              N√£o   \n",
       "4          N√£o         N√£o       N√£o sabe         N√£o sabe   \n",
       "\n",
       "  autoavaliacao_saude  peso_real  altura atividade_fisica      fumante_atual  \\\n",
       "0                 NaN        NaN     NaN         N√£o sabe                N√£o   \n",
       "1                 NaN        NaN     NaN         N√£o sabe                N√£o   \n",
       "2           Muito boa       81.0    0.81              N√£o  N√£o, mas j√° fumou   \n",
       "3           Muito boa       75.0    0.75              N√£o  N√£o, mas j√° fumou   \n",
       "4                 NaN        NaN     NaN         N√£o sabe                N√£o   \n",
       "\n",
       "  hipertensao  diabetes doenca_cardiaca       avc doenca_respiratoria  \\\n",
       "0    N√£o sabe  N√£o sabe        N√£o sabe  N√£o sabe            N√£o sabe   \n",
       "1    N√£o sabe  N√£o sabe        N√£o sabe  N√£o sabe            N√£o sabe   \n",
       "2         Sim       N√£o             N√£o  N√£o sabe                 N√£o   \n",
       "3         Sim       Sim             N√£o  N√£o sabe                 N√£o   \n",
       "4    N√£o sabe  N√£o sabe        N√£o sabe  N√£o sabe            N√£o sabe   \n",
       "\n",
       "     cancer  num_medicamentos  id_individuo area_urbana  peso_amostral regiao  \\\n",
       "0  N√£o sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "1  N√£o sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "2  N√£o sabe               2.0     85.589085           0     117.758255  Norte   \n",
       "3  N√£o sabe               2.0     85.589085           0     117.758255  Norte   \n",
       "4  N√£o sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "\n",
       "          imc  multimorbidity_count multimorb_cat  adl_score  iadl_score  \\\n",
       "0  149.253731                     0             0         11           7   \n",
       "1  149.253731                     0             0         12           5   \n",
       "2  123.456790                    11            3+          7           2   \n",
       "3  133.333333                     9            3+         12           7   \n",
       "4  149.253731                     0             0          9           7   \n",
       "\n",
       "   functional_raw  functional_score  dependencia_SUS  cobertura_influenza  \\\n",
       "0              18              0.10                0                    0   \n",
       "1              17              0.15                0                    0   \n",
       "2               9              0.55                0                    2   \n",
       "3              19              0.05                0                    2   \n",
       "4              16              0.20                0                    0   \n",
       "\n",
       "   autoav_z  multimorb_z  functional_z  health_score_raw  health_score  \n",
       "0       NaN    -1.027069      0.187726               NaN           NaN  \n",
       "1       NaN    -1.027069      0.522010               NaN           NaN  \n",
       "2 -0.344963     1.200084      3.196276          3.167954      0.744213  \n",
       "3 -0.344963     0.795147     -0.146557         -0.559990      0.305083  \n",
       "4       NaN    -1.027069      0.856293               NaN           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quero ver todas as colunas sem supressao visual\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca89c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BIBLIOTECAS CARREGADAS COM SUCESSO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# AN√ÅLISE AVAN√áADA DO √çNDICE DE ENVELHECIMENTO ATIVO (AAI)\n",
    "# PNS 2019 - Vers√£o Corrigida e Metodologicamente Robusta\n",
    "# ===============================================================================\n",
    "# Autor: An√°lise Senior - Metodologia Survey-Aware\n",
    "# Data: Outubro 2024\n",
    "# Objetivo: AAI municipal com infer√™ncia v√°lida e interven√ß√µes acion√°veis\n",
    "# ===============================================================================\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pacotes opcionais\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from esda.moran import Moran, Moran_Local\n",
    "    import libpysal\n",
    "    SPATIAL_AVAILABLE = True\n",
    "except:\n",
    "    SPATIAL_AVAILABLE = False\n",
    "    print(\" Pacotes espaciais n√£o dispon√≠veis (instale: geopandas, esda, libpysal)\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\" SHAP n√£o dispon√≠vel (instale: shap)\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BIBLIOTECAS CARREGADAS COM SUCESSO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69ee4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados de: data/processed/pns_2019_pandas.csv\n",
      "Dataset carregado: 43,554 linhas √ó 59 colunas\n",
      "Dataset carregado: 43,554 linhas √ó 59 colunas\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 1: CONFIGURA√á√ÉO E CARREGAMENTO\n",
    "# ===============================================================================\n",
    "\n",
    "# üîß AJUSTE OS CAMINHOS AQUI\n",
    "DATA_PATH = \"data/processed/pns_2019_pandas.csv\"\n",
    "SHAPEFILE_PATH = \"data/processed/BR_municipios_2019.shp\"\n",
    "DATASUS_PATH = \"data/processed/datasus_facilities.csv\"\n",
    "OUTPUT_DIR = Path(\"./outputs_aai\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configura√ß√µes metodol√≥gicas\n",
    "MIN_N_MUNICIPAL = 30  # M√≠nimo de observa√ß√µes para estimativas municipais confi√°veis\n",
    "N_BOOTSTRAP = 500     # Itera√ß√µes para CIs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"\\nCarregando dados de: {DATA_PATH}\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "    print(f\"Dataset carregado: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo n√£o encontrado. Ajuste DATA_PATH\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9424a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " PADRONIZA√á√ÉO DE VARI√ÅVEIS\n",
      "================================================================================\n",
      "Coluna de peso identificada: 'peso_amostral'\n",
      "\n",
      "Valida√ß√£o de vari√°veis essenciais:\n",
      "  ‚úì idade        - Idade do indiv√≠duo\n",
      "  ‚úó codmun       - C√≥digo do munic√≠pio [FALTANDO]\n",
      "  ‚úì uf           - Unidade Federativa\n",
      "  ‚úì estrato      - Estrato amostral\n",
      "\n",
      "Aten√ß√£o: Vari√°veis ausentes podem limitar an√°lises: ['codmun']\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 2: PADRONIZA√á√ÉO DE VARI√ÅVEIS CR√çTICAS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PADRONIZA√á√ÉO DE VARI√ÅVEIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col_name in ['peso', 'peso_amostral', 'peso_exp', 'weight']:\n",
    "    if col_name in df.columns:\n",
    "        WEIGHT_COL = col_name\n",
    "        print(f\"Coluna de peso identificada: '{WEIGHT_COL}'\")\n",
    "        break\n",
    "\n",
    "if WEIGHT_COL is None:\n",
    "    raise SystemExit(\"Erro critico: Coluna de peso n√£o encontrada. Estimativas n√£o-ponderadas s√£o invalidas.\")\n",
    "\n",
    "# Validar vari√°veis essenciais\n",
    "essential_vars = {\n",
    "    'idade': 'Idade do indiv√≠duo',\n",
    "    'codmun': 'C√≥digo do munic√≠pio',\n",
    "    'uf': 'Unidade Federativa',\n",
    "    'estrato': 'Estrato amostral'\n",
    "}\n",
    "\n",
    "print(\"\\nValida√ß√£o de vari√°veis essenciais:\")\n",
    "missing_essentials = []\n",
    "for var, desc in essential_vars.items():\n",
    "    if var in df.columns:\n",
    "        print(f\"  ‚úì {var:12s} - {desc}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {var:12s} - {desc} [FALTANDO]\")\n",
    "        missing_essentials.append(var)\n",
    "\n",
    "if missing_essentials:\n",
    "    print(f\"\\nAten√ß√£o: Vari√°veis ausentes podem limitar an√°lises: {missing_essentials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539baede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Coluna 'codmun' derivada de 'upa'\n"
     ]
    }
   ],
   "source": [
    "# Derivar codmun se n√£o existir\n",
    "if 'codmun' not in df.columns:\n",
    "    if 'upa' in df.columns:\n",
    "        df['codmun'] = df['upa'].astype(str).str[:6].astype(int)\n",
    "        print(\" Coluna 'codmun' derivada de 'upa'\")\n",
    "    else:\n",
    "        raise SystemExit(\" ERRO: N√£o √© poss√≠vel derivar 'codmun'. Coluna 'upa' n√£o encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0caa642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " APLICANDO FILTROS\n",
      "================================================================================\n",
      "Registros originais: 43,554\n",
      "Apos filtro 60+: 43,554 registros (100.0%)\n",
      "Removendo 20826 registros com peso missing\n",
      "\n",
      "Distribui√ß√£o et√°ria (ponderada):\n",
      "  60-69: 20,778,673 (60.4%)\n",
      "  70-79: 9,720,855 (28.3%)\n",
      "  80+: 3,899,325 (11.3%)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 3: FILTROS E PREPARA√á√ÉO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" APLICANDO FILTROS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_original = len(df)\n",
    "print(f\"Registros originais: {n_original:,}\")\n",
    "\n",
    "# Filtro 60+\n",
    "if 'idade' in df.columns:\n",
    "    df = df[df['idade'] >= 60].copy()\n",
    "    print(f\"Apos filtro 60+: {len(df):,} registros ({len(df)/n_original*100:.1f}%)\")\n",
    "else:\n",
    "    raise SystemExit(\"Erro: Coluna 'idade' n√£o encontrada\")\n",
    "\n",
    "# Verificar pesos v√°lidos\n",
    "invalid_weights = df[WEIGHT_COL].isnull().sum()\n",
    "if invalid_weights > 0:\n",
    "    print(f\"Removendo {invalid_weights} registros com peso missing\")\n",
    "    df = df[df[WEIGHT_COL].notna()].copy()\n",
    "\n",
    "# Criar faixa et√°ria\n",
    "df['faixa_etaria'] = pd.cut(df['idade'], \n",
    "                             bins=[60, 70, 80, 120], \n",
    "                             labels=['60-69', '70-79', '80+'],\n",
    "                             include_lowest=True)\n",
    "\n",
    "print(f\"\\nDistribui√ß√£o et√°ria (ponderada):\")\n",
    "for age_group in ['60-69', '70-79', '80+']:\n",
    "    pop = df[df['faixa_etaria'] == age_group][WEIGHT_COL].sum()\n",
    "    pct = pop / df[WEIGHT_COL].sum() * 100\n",
    "    print(f\"  {age_group}: {pop:,.0f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce075b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " DEFININDO FUN√á√ïES ESTAT√çSTICAS SURVEY-AWARE\n",
      "================================================================================\n",
      "Fun√ß√µes definidas com bootstrap para CIs\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 4: FUN√á√ïES PONDERADAS COM BOOTSTRAP\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DEFININDO FUN√á√ïES ESTAT√çSTICAS SURVEY-AWARE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def weighted_mean(data, col, weight_col=WEIGHT_COL):\n",
    "    \"\"\"M√©dia ponderada com tratamento de missing\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna()\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    return (valid[col] * valid[weight_col]).sum() / valid[weight_col].sum()\n",
    "\n",
    "def weighted_std(data, col, weight_col=WEIGHT_COL):\n",
    "    \"\"\"Desvio padr√£o ponderado\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna()\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    mean = weighted_mean(data, col, weight_col)\n",
    "    variance = ((valid[col] - mean)**2 * valid[weight_col]).sum() / valid[weight_col].sum()\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "def weighted_quantile(data, col, q, weight_col=WEIGHT_COL):\n",
    "    \"\"\"Quantil ponderado\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna().sort_values(col)\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    cumsum = valid[weight_col].cumsum()\n",
    "    cutoff = valid[weight_col].sum() * q\n",
    "    return valid[col].iloc[(cumsum >= cutoff).argmax()]\n",
    "\n",
    "def weighted_mean_bootstrap_ci(data, col, weight_col=WEIGHT_COL, n_boot=N_BOOTSTRAP, ci=95):\n",
    "    \"\"\"\n",
    "    CORRE√á√ÉO CR√çTICA: Bootstrap para intervalos de confian√ßa\n",
    "    Respeita estrutura de pesos amostrais\n",
    "    \"\"\"\n",
    "    valid = data[[col, weight_col]].dropna().reset_index(drop=True)\n",
    "    if len(valid) < 10:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    estimates = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(valid), size=len(valid), replace=True)\n",
    "        boot_data = valid.iloc[idx]\n",
    "        boot_mean = (boot_data[col] * boot_data[weight_col]).sum() / boot_data[weight_col].sum()\n",
    "        estimates.append(boot_mean)\n",
    "    \n",
    "    point_est = weighted_mean(data, col, weight_col)\n",
    "    lower = np.percentile(estimates, (100-ci)/2)\n",
    "    upper = np.percentile(estimates, 100-(100-ci)/2)\n",
    "    \n",
    "    return point_est, lower, upper\n",
    "\n",
    "print(\"Fun√ß√µes definidas com bootstrap para CIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d4b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " AN√ÅLISE DE DADOS FALTANTES\n",
      "================================================================================\n",
      "\n",
      "Disponibilidade de dom√≠nios:\n",
      "  ‚úì health_score              - 0.0% missing\n",
      "  ‚úì functional_score          - 0.0% missing\n",
      "  ‚úó participation_score       - N√ÉO DISPON√çVEL\n",
      "  ‚úó econ_score                - N√ÉO DISPON√çVEL\n",
      "  ‚úó access_score              - N√ÉO DISPON√çVEL\n",
      "\n",
      "Total de dom√≠nios dispon√≠veis: 2/5\n",
      "\n",
      "Padr√£o de missing por idade (potencial vi√©s):\n",
      "Faixa       60-69 70-79   80+\n",
      "Vari√°vel                     \n",
      "anos_estudo  0.0%  0.0%  0.0%\n",
      "\n",
      "================================================================================\n",
      "CONSTRU√á√ÉO DOS SCORES FALTANTES\n",
      "================================================================================\n",
      "\n",
      "Construindo participation_score...\n",
      "   ‚úì Internet access inclu√≠do\n",
      "   ‚úì Celular access inclu√≠do\n",
      "   ‚Üí participation_score criado (m√©dia de 2 indicadores)\n",
      "\n",
      "Construindo econ_score...\n",
      "   ‚úì Educa√ß√£o inclu√≠da\n",
      "   ‚Üí econ_score criado (m√©dia de 1 indicadores)\n",
      "\n",
      "Construindo access_score...\n",
      "   ‚úì Plano de sa√∫de inclu√≠do\n",
      "   ‚úì Consulta m√©dica inclu√≠da\n",
      "   ‚Üí access_score criado (m√©dia de 2 indicadores)\n",
      "\n",
      "Valida√ß√£o dos scores criados:\n",
      "   ‚úì participation_score : m√©dia=51.4, missing=0.0%\n",
      "   ‚úì econ_score          : m√©dia=42.5, missing=0.0%\n",
      "   ‚úì access_score        : m√©dia=7.7, missing=0.0%\n",
      "\n",
      "Constru√ß√£o de scores conclu√≠da!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 5: AN√ÅLISE DE MISSINGNESS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" AN√ÅLISE DE DADOS FALTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identificar dom√≠nios dispon√≠veis\n",
    "ALL_DOMAINS = ['health_score', 'functional_score', 'participation_score', \n",
    "               'econ_score', 'access_score']\n",
    "\n",
    "print(\"\\nDisponibilidade de dom√≠nios:\")\n",
    "available_domains = []\n",
    "for domain in ALL_DOMAINS:\n",
    "    if domain in df.columns:\n",
    "        missing_pct = df[domain].isnull().mean() * 100\n",
    "        print(f\"  ‚úì {domain:25s} - {missing_pct:.1f}% missing\")\n",
    "        available_domains.append(domain)\n",
    "    else:\n",
    "        print(f\"  ‚úó {domain:25s} - N√ÉO DISPON√çVEL\")\n",
    "\n",
    "if len(available_domains) == 0:\n",
    "    raise SystemExit(\"Erro critico: Nenhum dom√≠nio encontrado. Verifique nomes das colunas.\")\n",
    "\n",
    "print(f\"\\nTotal de dom√≠nios dispon√≠veis: {len(available_domains)}/{len(ALL_DOMAINS)}\")\n",
    "\n",
    "# Missing por faixa et√°ria (detectar vi√©s)\n",
    "key_vars = ['renda', 'anos_estudo', 'uso_internet', 'plano']\n",
    "print(\"\\nPadr√£o de missing por idade (potencial vi√©s):\")\n",
    "\n",
    "missing_by_age = []\n",
    "for var in key_vars:\n",
    "    if var in df.columns:\n",
    "        for age_group in ['60-69', '70-79', '80+']:\n",
    "            subset = df[df['faixa_etaria'] == age_group]\n",
    "            miss_pct = subset[var].isnull().mean() * 100\n",
    "            missing_by_age.append({\n",
    "                'Vari√°vel': var,\n",
    "                'Faixa': age_group,\n",
    "                'Missing %': f\"{miss_pct:.1f}%\"\n",
    "            })\n",
    "\n",
    "if missing_by_age:\n",
    "    miss_df = pd.DataFrame(missing_by_age).pivot(index='Vari√°vel', \n",
    "                                                  columns='Faixa', \n",
    "                                                  values='Missing %')\n",
    "    print(miss_df)\n",
    "\n",
    "# ===============================================================================\n",
    "# CONSTRU√á√ÉO DOS SCORES FALTANTES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONSTRU√á√ÉO DOS SCORES FALTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Fun√ß√£o para normalizar vari√°veis (0-100)\n",
    "def normalize_score(series, reverse=False):\n",
    "    \"\"\"Normaliza s√©rie para escala 0-100\"\"\"\n",
    "    if reverse:\n",
    "        series = -series\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    if max_val == min_val:\n",
    "        return pd.Series([50] * len(series), index=series.index)\n",
    "    normalized = (series - min_val) / (max_val - min_val) * 100\n",
    "    return normalized\n",
    "\n",
    "# 1. PARTICIPATION_SCORE (acesso √† internet + celular)\n",
    "print(\"\\nConstruindo participation_score...\")\n",
    "if 'participation_score' not in df.columns:\n",
    "    participation_vars = []\n",
    "    \n",
    "    # Internet\n",
    "    if 'usa_internet' in df.columns:\n",
    "        internet_score = df['usa_internet'].map({'Sim': 1, 'N√£o': 0}).fillna(0) * 100\n",
    "        participation_vars.append(internet_score)\n",
    "        print(\"   ‚úì Internet access inclu√≠do\")\n",
    "    \n",
    "    # Celular\n",
    "    if 'usa_celular' in df.columns:\n",
    "        celular_score = df['usa_celular'].map({'Sim': 1, 'N√£o': 0}).fillna(0) * 100\n",
    "        participation_vars.append(celular_score)\n",
    "        print(\"   ‚úì Celular access inclu√≠do\")\n",
    "    \n",
    "    if participation_vars:\n",
    "        df['participation_score'] = pd.concat(participation_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   ‚Üí participation_score criado (m√©dia de {len(participation_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma vari√°vel de participa√ß√£o dispon√≠vel\")\n",
    "else:\n",
    "    print(\"   ‚úì participation_score j√° existe\")\n",
    "\n",
    "# 2. ECON_SCORE (educa√ß√£o + renda)\n",
    "print(\"\\nConstruindo econ_score...\")\n",
    "if 'econ_score' not in df.columns:\n",
    "    econ_vars = []\n",
    "    \n",
    "    # Educa√ß√£o\n",
    "    if 'anos_estudo' in df.columns:\n",
    "        educ_score = normalize_score(df['anos_estudo'].fillna(df['anos_estudo'].median()))\n",
    "        econ_vars.append(educ_score)\n",
    "        print(\"   ‚úì Educa√ß√£o inclu√≠da\")\n",
    "    \n",
    "    # Renda\n",
    "    if 'renda' in df.columns:\n",
    "        renda_score = normalize_score(df['renda'].fillna(df['renda'].median()))\n",
    "        econ_vars.append(renda_score)\n",
    "        print(\"   ‚úì Renda inclu√≠da\")\n",
    "    \n",
    "    if econ_vars:\n",
    "        df['econ_score'] = pd.concat(econ_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   ‚Üí econ_score criado (m√©dia de {len(econ_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma vari√°vel econ√¥mica dispon√≠vel\")\n",
    "else:\n",
    "    print(\"   ‚úì econ_score j√° existe\")\n",
    "\n",
    "# 3. ACCESS_SCORE (acesso a servi√ßos de sa√∫de)\n",
    "print(\"\\nConstruindo access_score...\")\n",
    "if 'access_score' not in df.columns:\n",
    "    access_vars = []\n",
    "    \n",
    "    # Plano de sa√∫de\n",
    "    if 'possui_plano_saude' in df.columns:\n",
    "        plano_score = df['possui_plano_saude'].map({'Sim': 1, 'N√£o': 0}).fillna(0) * 100\n",
    "        access_vars.append(plano_score)\n",
    "        print(\"   ‚úì Plano de sa√∫de inclu√≠do\")\n",
    "    \n",
    "    # Consulta m√©dica recente\n",
    "    if 'consulta_12m' in df.columns:\n",
    "        consulta_score = df['consulta_12m'].map({'Sim': 1, 'N√£o': 0}).fillna(0) * 100\n",
    "        access_vars.append(consulta_score)\n",
    "        print(\"   ‚úì Consulta m√©dica inclu√≠da\")\n",
    "    \n",
    "    if access_vars:\n",
    "        df['access_score'] = pd.concat(access_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   ‚Üí access_score criado (m√©dia de {len(access_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma vari√°vel de acesso dispon√≠vel\")\n",
    "else:\n",
    "    print(\"   ‚úì access_score j√° existe\")\n",
    "\n",
    "# Valida√ß√£o dos scores criados\n",
    "print(\"\\nValida√ß√£o dos scores criados:\")\n",
    "for score in ['participation_score', 'econ_score', 'access_score']:\n",
    "    if score in df.columns:\n",
    "        mean_val = df[score].mean()\n",
    "        missing_pct = df[score].isnull().mean() * 100\n",
    "        print(f\"   ‚úì {score:20s}: m√©dia={mean_val:.1f}, missing={missing_pct:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {score:20s}: n√£o criado\")\n",
    "\n",
    "print(\"\\nConstru√ß√£o de scores conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bff9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " CONSTRU√á√ÉO DO AAI_TOTAL\n",
      "================================================================================\n",
      "AAI_total criado usando 2 dom√≠nios:\n",
      "   ‚Ä¢ health_score\n",
      "   ‚Ä¢ functional_score\n",
      "\n",
      "Estat√≠sticas do AAI_TOTAL (ponderadas):\n",
      "  M√©dia: 0.18 [95% CI: 0.17 - 0.18]\n",
      "  DP:    0.13\n",
      "  P25:   0.12\n",
      "  P50:   0.13\n",
      "  P75:   0.17\n",
      "  M√©dia: 0.18 [95% CI: 0.17 - 0.18]\n",
      "  DP:    0.13\n",
      "  P25:   0.12\n",
      "  P50:   0.13\n",
      "  P75:   0.17\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 6: CONSTRU√á√ÉO DO AAI_TOTAL (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CONSTRU√á√ÉO DO AAI_TOTAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORRE√á√ÉO CR√çTICA 2: AAI usando dom√≠nios dispon√≠veis\n",
    "df['AAI_total'] = df[available_domains].mean(axis=1)\n",
    "print(f\"AAI_total criado usando {len(available_domains)} dom√≠nios:\")\n",
    "for dom in available_domains:\n",
    "    print(f\"   ‚Ä¢ {dom}\")\n",
    "\n",
    "# Estat√≠sticas descritivas do AAI\n",
    "print(\"\\nEstat√≠sticas do AAI_TOTAL (ponderadas):\")\n",
    "aai_mean, aai_lower, aai_upper = weighted_mean_bootstrap_ci(df, 'AAI_total')\n",
    "print(f\"  M√©dia: {aai_mean:.2f} [95% CI: {aai_lower:.2f} - {aai_upper:.2f}]\")\n",
    "print(f\"  DP:    {weighted_std(df, 'AAI_total'):.2f}\")\n",
    "print(f\"  P25:   {weighted_quantile(df, 'AAI_total', 0.25):.2f}\")\n",
    "print(f\"  P50:   {weighted_quantile(df, 'AAI_total', 0.50):.2f}\")\n",
    "print(f\"  P75:   {weighted_quantile(df, 'AAI_total', 0.75):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bff9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " AGREGA√á√ÉO MUNICIPAL\n",
      "================================================================================\n",
      "Agregando por munic√≠pio (m√≠nimo n=30)...\n",
      "\n",
      "2794 munic√≠pios processados\n",
      "   ‚Ä¢ 46 munic√≠pios com n‚â•30 (confi√°veis)\n",
      "   ‚Ä¢ 2748 munic√≠pios com n<30 (requerem SAE)\n",
      "\n",
      "Salvo: outputs_aai\\municipal_scores_with_ci.csv\n",
      "\n",
      "2794 munic√≠pios processados\n",
      "   ‚Ä¢ 46 munic√≠pios com n‚â•30 (confi√°veis)\n",
      "   ‚Ä¢ 2748 munic√≠pios com n<30 (requerem SAE)\n",
      "\n",
      "Salvo: outputs_aai\\municipal_scores_with_ci.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 7: AGREGA√á√ÉO MUNICIPAL (COM CONTROLE DE QUALIDADE)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" AGREGA√á√ÉO MUNICIPAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def aggregate_municipal_robust(group):\n",
    "    \"\"\"Agrega√ß√£o municipal com CIs e flags de qualidade\"\"\"\n",
    "    results = {\n",
    "        'n_obs': len(group),\n",
    "        'pop_weight_sum': group[WEIGHT_COL].sum()\n",
    "    }\n",
    "    \n",
    "    # Calcular AAI com CI\n",
    "    if 'AAI_total' in group.columns:\n",
    "        aai_mean, aai_lower, aai_upper = weighted_mean_bootstrap_ci(group, 'AAI_total')\n",
    "        results['AAI_total'] = aai_mean\n",
    "        results['AAI_ci_lower'] = aai_lower\n",
    "        results['AAI_ci_upper'] = aai_upper\n",
    "        results['AAI_ci_width'] = aai_upper - aai_lower\n",
    "    \n",
    "    # Dom√≠nios individuais\n",
    "    for domain in available_domains:\n",
    "        if domain in group.columns:\n",
    "            results[domain] = weighted_mean(group, domain)\n",
    "    \n",
    "    # Flags de qualidade\n",
    "    results['reliable'] = len(group) >= MIN_N_MUNICIPAL\n",
    "    \n",
    "    return pd.Series(results)\n",
    "\n",
    "print(f\"Agregando por munic√≠pio (m√≠nimo n={MIN_N_MUNICIPAL})...\")\n",
    "municipal_scores = df.groupby('codmun').apply(aggregate_municipal_robust).reset_index()\n",
    "\n",
    "# Adicionar UF\n",
    "if 'uf' in df.columns:\n",
    "    mun_uf = df.groupby('codmun')['uf'].first().reset_index()\n",
    "    municipal_scores = municipal_scores.merge(mun_uf, on='codmun', how='left')\n",
    "\n",
    "# Estat√≠sticas de qualidade\n",
    "n_total_mun = len(municipal_scores)\n",
    "n_reliable = municipal_scores['reliable'].sum()\n",
    "print(f\"\\n{n_total_mun} munic√≠pios processados\")\n",
    "print(f\"   ‚Ä¢ {n_reliable} munic√≠pios com n‚â•{MIN_N_MUNICIPAL} (confi√°veis)\")\n",
    "print(f\"   ‚Ä¢ {n_total_mun - n_reliable} munic√≠pios com n<{MIN_N_MUNICIPAL} (requerem SAE)\")\n",
    "\n",
    "# Salvar\n",
    "output_path = OUTPUT_DIR / \"municipal_scores_with_ci.csv\"\n",
    "municipal_scores.to_csv(output_path, index=False)\n",
    "print(f\"\\nSalvo: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0568d",
   "metadata": {},
   "source": [
    "## Resultados Principais\n",
    "\n",
    "Nas se√ß√µes seguintes, apresentamos os principais achados da an√°lise:\n",
    "\n",
    "1. **Prepara√ß√£o dos Dados**: Limpeza e valida√ß√£o dos dados da PNS 2019\n",
    "2. **Constru√ß√£o do AAI**: √çndice nacional e estat√≠sticas descritivas\n",
    "3. **Agrega√ß√£o Municipal**: Scores por munic√≠pio com controle de qualidade\n",
    "4. **Identifica√ß√£o de Hotspots**: Munic√≠pios priorit√°rios para interven√ß√£o\n",
    "5. **An√°lise de Desigualdades**: Compara√ß√£o entre subgrupos demogr√°ficos\n",
    "6. **Perfis de Envelhecimento**: Clustering para identifica√ß√£o de padr√µes\n",
    "7. **Modelagem Preditiva**: Drivers de vulnerabilidade identificados\n",
    "8. **An√°lise de Media√ß√£o**: Efeitos indiretos sobre o envelhecimento ativo\n",
    "9. **An√°lise Espacial**: Padr√µes geogr√°ficos e autocorrela√ß√£o\n",
    "10. **Policy Brief**: Recomenda√ß√µes para gestores p√∫blicos\n",
    "\n",
    "Todos os resultados consideram o desenho amostral complexo da PNS, utilizando pesos amostrais e intervalos de confian√ßa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4912e5",
   "metadata": {},
   "source": [
    "## 1. Preparando o Terreno: Organizando Nossos Dados\n",
    "\n",
    "Antes de qualquer an√°lise, precisamos garantir que nossos dados est√£o limpos e organizados. Nesta etapa, estamos fazendo uma 'faxina':\n",
    "\n",
    "* **Filtramos os dados** para focar apenas nas pessoas com 60 anos ou mais, que s√£o o nosso p√∫blico de interesse.\n",
    "* **Verificamos informa√ß√µes essenciais**, como o munic√≠pio de resid√™ncia e a idade de cada pessoa.\n",
    "* **Validamos os 'pesos amostrais'**: um fator de corre√ß√£o crucial que nos permite dizer que os resultados desta pesquisa representam a popula√ß√£o idosa de todo o Brasil, e n√£o apenas as pessoas que foram entrevistadas.\n",
    "\n",
    "Pense nos pesos amostrais como \"multiplicadores\": algumas pessoas representam milhares de outras com caracter√≠sticas semelhantes. Sem eles, nossos resultados seriam enviesados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4f36b",
   "metadata": {},
   "source": [
    "## 2. Construindo o Term√¥metro: O √çndice de Envelhecimento Ativo (AAI)\n",
    "\n",
    "Para medir o 'envelhecimento ativo', n√£o podemos olhar para um √∫nico fator. Por isso, criamos um √≠ndice, o AAI, que funciona como uma nota final composta por v√°rias 'mat√©rias': sa√∫de, participa√ß√£o social, seguran√ßa econ√¥mica, etc.\n",
    "\n",
    "Nesta se√ß√£o, n√≥s:\n",
    "1. **Calculamos as notas** para cada uma dessas 'mat√©rias' (os dom√≠nios).\n",
    "2. **Combinamos tudo** para criar a nota final: o **AAI_total**.\n",
    "3. **Usamos uma t√©cnica estat√≠stica (bootstrap)** para garantir que nossas m√©dias n√£o sejam apenas um n√∫mero, mas uma 'faixa de valores prov√°veis' (o intervalo de confian√ßa), o que nos d√° muito mais seguran√ßa nos resultados.\n",
    "\n",
    "O resultado √© um panorama nacional do envelhecimento ativo, com indicadores robustos que podem ser comparados entre regi√µes e grupos populacionais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70492c",
   "metadata": {},
   "source": [
    "## 3. Do Indiv√≠duo para a Cidade: Calculando a Nota de Cada Munic√≠pio\n",
    "\n",
    "Agora que cada idoso tem sua 'nota' de envelhecimento ativo, o pr√≥ximo passo √© calcular a m√©dia para cada munic√≠pio do Brasil. Isso nos permite comparar as cidades e ver onde a qualidade de vida na terceira idade √© maior ou menor.\n",
    "\n",
    "**Ponto de aten√ß√£o:** Para que a nota de um munic√≠pio seja confi√°vel, exigimos um n√∫mero m√≠nimo de entrevistados naquela cidade. Cidades com poucos participantes s√£o sinalizadas, pois suas m√©dias podem n√£o ser t√£o precisas.\n",
    "\n",
    "O resultado √© um mapa municipal do envelhecimento ativo, fundamental para orientar onde investir recursos p√∫blicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b402df9",
   "metadata": {},
   "source": [
    "## 4. Onde Devemos Focar? Identificando os Munic√≠pios Priorit√°rios\n",
    "\n",
    "Com a nota de cada cidade em m√£os, podemos criar um ranking. Aqui, nosso objetivo √© responder a uma pergunta fundamental para a gest√£o p√∫blica: **\"Quais munic√≠pios mais precisam de ajuda?\"**\n",
    "\n",
    "Para isso, filtramos apenas os munic√≠pios com dados confi√°veis e, em seguida, identificamos o grupo dos **20% com as piores notas** no √çndice de Envelhecimento Ativo (AAI).\n",
    "\n",
    "Esta lista de \"munic√≠pios priorit√°rios\" √© um dos resultados mais importantes do nosso estudo, pois serve como um guia para direcionar recursos, programas sociais e pol√≠ticas de sa√∫de para as √°reas mais cr√≠ticas do pa√≠s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90047c",
   "metadata": {},
   "source": [
    "## 5. H√° Diferen√ßas entre Grupos? Analisando Desigualdades\n",
    "\n",
    "O envelhecimento ativo pode variar muito dependendo de caracter√≠sticas pessoais como sexo, ra√ßa, escolaridade ou local de resid√™ncia (urbano/rural).\n",
    "\n",
    "Nesta se√ß√£o, comparamos as notas do AAI entre diferentes grupos demogr√°ficos para identificar desigualdades. Por exemplo:\n",
    "- As mulheres idosas t√™m notas diferentes dos homens?\n",
    "- H√° diferen√ßas por n√≠vel de escolaridade?\n",
    "- Idosos em √°reas rurais enfrentam mais desafios?\n",
    "\n",
    "Essas an√°lises s√£o cruciais para criar pol√≠ticas mais justas e direcionadas, garantindo que nenhum grupo seja deixado para tr√°s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806dc046",
   "metadata": {},
   "source": [
    "## 6. Existem 'Grupos' de Idosos? Criando Perfis de Envelhecimento\n",
    "\n",
    "Ser√° que todos os idosos envelhecem da mesma forma? Provavelmente n√£o. Nesta se√ß√£o, usamos uma t√©cnica que funciona como um 'chap√©u seletor': ela agrupa os idosos em perfis distintos com base em suas caracter√≠sticas de sa√∫de, renda, educa√ß√£o e participa√ß√£o.\n",
    "\n",
    "O resultado √© a identifica√ß√£o de, por exemplo, um grupo de 'idosos ativos e conectados' e outro de 'idosos fr√°geis e com dificuldades de acesso'. Entender esses perfis ajuda a criar a√ß√µes mais personalizadas e eficazes.\n",
    "\n",
    "Usamos uma t√©cnica chamada 'clustering' que encontra padr√µes naturais nos dados, sem precisar dizer previamente quantos grupos queremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece2fe",
   "metadata": {},
   "source": [
    "## 7. Quais Fatores Mais Influenciam? Descobrindo os Drivers de Vulnerabilidade\n",
    "\n",
    "Por que alguns idosos t√™m uma nota de envelhecimento ativo t√£o baixa? Para responder a isso, constru√≠mos um modelo preditivo.\n",
    "\n",
    "Pense nele como um detetive que analisa milhares de casos para descobrir quais 'pistas' (caracter√≠sticas como escolaridade, renda, acesso √† internet) est√£o mais fortemente ligadas √† vulnerabilidade. O resultado nos mostra os fatores mais importantes que, se melhorados, podem ter o maior impacto positivo na vida da popula√ß√£o idosa.\n",
    "\n",
    "Usamos t√©cnicas avan√ßadas como Random Forest e SHAP para garantir que as descobertas sejam robustas e interpret√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b7fc2",
   "metadata": {},
   "source": [
    "## 8. H√° Efeitos Indiretos? An√°lise de Media√ß√£o\n",
    "\n",
    "√Äs vezes, os fatores n√£o influenciam diretamente o envelhecimento ativo, mas sim indiretamente, atrav√©s de outros fatores intermedi√°rios.\n",
    "\n",
    "Por exemplo: a renda pode afetar a participa√ß√£o social, que por sua vez afeta o envelhecimento ativo. Nesta se√ß√£o, investigamos esses 'efeitos em cascata' usando uma t√©cnica chamada an√°lise de media√ß√£o.\n",
    "\n",
    "Isso nos ajuda a entender melhor como as interven√ß√µes funcionam: melhorar a renda pode ter benef√≠cios adicionais atrav√©s da participa√ß√£o social."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23c610",
   "metadata": {},
   "source": [
    "## 9. H√° Padr√µes Geogr√°ficos? An√°lise Espacial\n",
    "\n",
    "Ser√° que munic√≠pios vizinhos t√™m notas de envelhecimento ativo semelhantes? Ou h√° padr√µes regionais que influenciam o envelhecimento?\n",
    "\n",
    "Nesta se√ß√£o, usamos t√©cnicas de an√°lise espacial para investigar:\n",
    "- **Autocorrela√ß√£o**: Se munic√≠pios pr√≥ximos tendem a ter notas parecidas\n",
    "- **Clusters espaciais**: Grupos de munic√≠pios com caracter√≠sticas similares\n",
    "\n",
    "Isso √© importante porque fatores como clima, cultura regional ou pol√≠ticas locais podem criar padr√µes geogr√°ficos que precisam ser considerados no planejamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a5c97",
   "metadata": {},
   "source": [
    "## 10. Comunicando os Resultados: Policy Brief Automatizado\n",
    "\n",
    "Agora que temos todos os insights, precisamos comunic√°-los de forma clara e acion√°vel. Nesta se√ß√£o, geramos automaticamente um documento executivo (policy brief) que resume:\n",
    "\n",
    "- Os principais indicadores nacionais\n",
    "- Os munic√≠pios priorit√°rios\n",
    "- As desigualdades identificadas\n",
    "- Os fatores de risco mais importantes\n",
    "- Recomenda√ß√µes pr√°ticas para gestores p√∫blicos\n",
    "\n",
    "Este documento √© projetado para ser lido rapidamente por tomadores de decis√£o, com linguagem clara e foco em a√ß√µes concretas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0bdb49",
   "metadata": {},
   "source": [
    "## 11. Visualizando os Dados: Gr√°ficos e Mapas\n",
    "\n",
    "Uma imagem vale mais que mil palavras. Nesta se√ß√£o, criamos visualiza√ß√µes que facilitam o entendimento dos dados:\n",
    "\n",
    "- **Distribui√ß√µes dos dom√≠nios**: Como cada componente do AAI se comporta na popula√ß√£o\n",
    "- **AAI por faixa et√°ria**: Como o envelhecimento ativo varia com a idade\n",
    "- **Import√¢ncia dos fatores**: Quais caracter√≠sticas mais influenciam a vulnerabilidade\n",
    "\n",
    "Esses gr√°ficos s√£o salvos automaticamente e podem ser usados em apresenta√ß√µes, relat√≥rios ou publica√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdb5ce",
   "metadata": {},
   "source": [
    "## 12. Verificando a Qualidade: Checklist de Valida√ß√£o\n",
    "\n",
    "Antes de finalizar, precisamos garantir que nossa an√°lise est√° correta e completa. Nesta se√ß√£o, executamos um checklist autom√°tico que verifica:\n",
    "\n",
    "- Se todos os filtros foram aplicados corretamente\n",
    "- Se os pesos amostrais est√£o sendo usados\n",
    "- Se os c√°lculos est√£o consistentes\n",
    "- Se todos os arquivos de sa√≠da foram gerados\n",
    "\n",
    "Isso garante que os resultados s√£o confi√°veis e reproduz√≠veis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d977835",
   "metadata": {},
   "source": [
    "## 13. Conclus√µes e Recomenda√ß√µes: O Que Tudo Isso Significa?\n",
    "\n",
    "Chegamos ao final da nossa jornada pelos dados. Nesta se√ß√£o, sintetizamos os principais insights e traduzimos em recomenda√ß√µes pr√°ticas:\n",
    "\n",
    "- **O que aprendemos** sobre o envelhecimento ativo no Brasil\n",
    "- **Quais s√£o as prioridades** para a√ß√£o governamental\n",
    "- **Como os resultados podem orientar** pol√≠ticas p√∫blicas\n",
    "- **Quais limita√ß√µes** devemos considerar\n",
    "\n",
    "Este sum√°rio final √© escrito em linguagem acess√≠vel, focando no impacto social e nas oportunidades de melhoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304299ea",
   "metadata": {},
   "source": [
    "## 14. Preparando para o Futuro: Exportando Datasets\n",
    "\n",
    "Para que outros pesquisadores ou gestores possam continuar o trabalho, nesta se√ß√£o exportamos todos os datasets processados:\n",
    "\n",
    "- **Dados individuais** com scores calculados e clusters identificados\n",
    "- **Sum√°rio executivo** em Excel com m√∫ltiplas abas\n",
    "- **Arquivos geoespaciais** para mapeamento\n",
    "\n",
    "Isso garante que o conhecimento gerado possa ser reutilizado e expandido por outros projetos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e71a",
   "metadata": {},
   "source": [
    "### O que conseguimos?\n",
    "\n",
    "‚úÖ Dados limpos e validados da PNS 2019  \n",
    "‚úÖ √çndice de Envelhecimento Ativo (AAI) constru√≠do com rigor estat√≠stico  \n",
    "‚úÖ Panorama municipal com identifica√ß√£o de hotspots  \n",
    "‚úÖ Perfis de idosos identificados  \n",
    "‚úÖ Fatores de vulnerabilidade descobertos  \n",
    "‚úÖ An√°lises espaciais e de media√ß√£o  \n",
    "‚úÖ Policy brief automatizado  \n",
    "‚úÖ Visualiza√ß√µes e datasets exportados  \n",
    "\n",
    "### Pr√≥ximos passos sugeridos:\n",
    "\n",
    "1. **Revisar os resultados** no policy brief gerado\n",
    "2. **Explorar os mapas** para entender padr√µes regionais  \n",
    "3. **Usar os datasets exportados** para an√°lises adicionais\n",
    "4. **Compartilhar os insights** com stakeholders relevantes\n",
    "\n",
    "Esta an√°lise serve como base s√≥lida para pol√≠ticas p√∫blicas mais informadas e eficazes para a popula√ß√£o idosa brasileira.\n",
    "\n",
    "---\n",
    "\n",
    "*Obrigado por acompanhar esta jornada pelos dados!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c304128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "IDENTIFICA√á√ÉO DE MUNIC√çPIOS VULNER√ÅVEIS\n",
      "================================================================================\n",
      "Analisando 46 munic√≠pios com dados confi√°veis...\n",
      "\n",
      "Munic√≠pios priorit√°rios (Bottom 20%)\n",
      "   Threshold AAI: 0.15\n",
      "   Total munic√≠pios: 10\n",
      "   Popula√ß√£o afetada: 135,259\n",
      "\n",
      " TOP 20 MUNIC√çPIOS MAIS VULNER√ÅVEIS:\n",
      " codmun             uf  AAI_total  AAI_ci_lower  AAI_ci_upper  health_score  n_obs\n",
      " 160000          Amap√°   0.126557      0.102618      0.154344      0.223901     31\n",
      " 280021        Sergipe   0.130634      0.116387      0.148204      0.240169     32\n",
      " 120001           Acre   0.135348      0.117091      0.155835      0.246038     44\n",
      " 140003        Roraima   0.136175      0.121368      0.152217      0.240602     38\n",
      " 170026      Tocantins   0.136778      0.099226      0.184577      0.234800     34\n",
      " 140006        Roraima   0.139188      0.125600      0.153537      0.259095     40\n",
      " 320011 Esp√≠rito Santo   0.142082      0.126613      0.163515      0.266439     30\n",
      " 170005      Tocantins   0.144686      0.115648      0.182890      0.253534     30\n",
      " 420024 Santa Catarina   0.148083      0.133621      0.169941      0.270701     30\n",
      " 140008        Roraima   0.153047      0.132399      0.180082      0.263229     30\n",
      "\n",
      " Lista priorit√°ria salva: outputs_aai\\priority_municipalities_bottom20.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 4: IDENTIFICA√á√ÉO DE HOTSPOTS (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IDENTIFICA√á√ÉO DE MUNIC√çPIOS VULNER√ÅVEIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORRE√á√ÉO CR√çTICA 3: Filtrar apenas munic√≠pios confi√°veis\n",
    "mun_reliable = municipal_scores[municipal_scores['reliable'] == True].copy()\n",
    "print(f\"Analisando {len(mun_reliable)} munic√≠pios com dados confi√°veis...\")\n",
    "\n",
    "# Calcular percentil 20 (bottom 20%)\n",
    "threshold_p20 = mun_reliable['AAI_total'].quantile(0.20)\n",
    "worst_20pct = mun_reliable[mun_reliable['AAI_total'] <= threshold_p20].sort_values('AAI_total')\n",
    "\n",
    "print(f\"\\nMunic√≠pios priorit√°rios (Bottom 20%)\")\n",
    "print(f\"   Threshold AAI: {threshold_p20:.2f}\")\n",
    "print(f\"   Total munic√≠pios: {len(worst_20pct)}\")\n",
    "print(f\"   Popula√ß√£o afetada: {worst_20pct['pop_weight_sum'].sum():,.0f}\")\n",
    "\n",
    "# Top 20 piores\n",
    "print(\"\\n TOP 20 MUNIC√çPIOS MAIS VULNER√ÅVEIS:\")\n",
    "display_cols = ['codmun', 'uf', 'AAI_total', 'AAI_ci_lower', 'AAI_ci_upper', \n",
    "                'health_score', 'n_obs']\n",
    "display_cols = [c for c in display_cols if c in worst_20pct.columns]\n",
    "print(worst_20pct[display_cols].head(20).to_string(index=False))\n",
    "\n",
    "# Salvar lista priorit√°ria\n",
    "priority_path = OUTPUT_DIR / \"priority_municipalities_bottom20.csv\"\n",
    "worst_20pct.to_csv(priority_path, index=False)\n",
    "print(f\"\\n Lista priorit√°ria salva: {priority_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c304128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DESIGUALDADES POR SUBGRUPO\n",
      "================================================================================\n",
      "\n",
      " SEXO:\n",
      "Categoria  AAI Health N (ponderado)\n",
      "Masculino 0.16   0.28    14,901,688\n",
      " Feminino 0.19   0.30    19,497,165\n",
      "\n",
      " RACA COR:\n",
      "Categoria  AAI Health N (ponderado)\n",
      "    Parda 0.17   0.28    12,861,842\n",
      "    Preta 0.18   0.29     3,535,497\n",
      "   Branca 0.18   0.29    17,375,149\n",
      "  Amarela 0.18   0.30       440,363\n",
      " Ind√≠gena 0.18   0.29       185,496\n",
      " Ignorado 0.12   0.24           507\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 5: DESIGUALDADES POR SUBGRUPO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DESIGUALDADES POR SUBGRUPO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "subgroup_vars = ['sexo', 'raca_cor', 'escolaridade', 'urbano_rural']\n",
    "\n",
    "for var in subgroup_vars:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n {var.upper().replace('_', ' ')}:\")\n",
    "        \n",
    "        subgroup_stats = []\n",
    "        for category in df[var].dropna().unique():\n",
    "            subset = df[df[var] == category]\n",
    "            if len(subset) > 0:\n",
    "                aai_mean = weighted_mean(subset, 'AAI_total')\n",
    "                health_mean = weighted_mean(subset, 'health_score') if 'health_score' in df.columns else np.nan\n",
    "                n_weighted = subset[WEIGHT_COL].sum()\n",
    "                \n",
    "                subgroup_stats.append({\n",
    "                    'Categoria': category,\n",
    "                    'AAI': f\"{aai_mean:.2f}\",\n",
    "                    'Health': f\"{health_mean:.2f}\" if not np.isnan(health_mean) else \"N/A\",\n",
    "                    'N (ponderado)': f\"{n_weighted:,.0f}\"\n",
    "                })\n",
    "        \n",
    "        if subgroup_stats:\n",
    "            print(pd.DataFrame(subgroup_stats).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d03046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFIS DE ENVELHECIMENTO (CLUSTERING)\n",
      "================================================================================\n",
      "Usando 5 features: ['health_score', 'functional_score', 'participation_score', 'anos_estudo', 'multimorbidity_count']\n",
      "\n",
      "Perfis de envelhecimento identificados:\n",
      "\n",
      "Perfis de envelhecimento identificados:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfil 1 (N=14,202, Pop=20,660,562):\n",
      "   ‚Ä¢ health_score             : 0.26\n",
      "   ‚Ä¢ functional_score         : 0.03\n",
      "   ‚Ä¢ participation_score      : 50.00\n",
      "   ‚Ä¢ anos_estudo              : 5.44\n",
      "   ‚Ä¢ multimorbidity_count     : 9.74\n",
      "\n",
      "Perfil 2 (N=1,967, Pop=3,229,883):\n",
      "   ‚Ä¢ health_score             : 0.61\n",
      "   ‚Ä¢ functional_score         : 0.43\n",
      "   ‚Ä¢ participation_score      : 50.00\n",
      "   ‚Ä¢ anos_estudo              : 6.05\n",
      "   ‚Ä¢ multimorbidity_count     : 10.13\n",
      "\n",
      "Perfil 3 (N=5,918, Pop=9,515,302):\n",
      "   ‚Ä¢ health_score             : 0.25\n",
      "   ‚Ä¢ functional_score         : 0.01\n",
      "   ‚Ä¢ participation_score      : 50.00\n",
      "   ‚Ä¢ anos_estudo              : 10.84\n",
      "   ‚Ä¢ multimorbidity_count     : 9.44\n",
      "\n",
      "Perfil 4 (N=641, Pop=993,105):\n",
      "   ‚Ä¢ health_score             : 0.25\n",
      "   ‚Ä¢ functional_score         : 0.01\n",
      "   ‚Ä¢ participation_score      : 100.00\n",
      "   ‚Ä¢ anos_estudo              : 7.54\n",
      "   ‚Ä¢ multimorbidity_count     : 9.72\n",
      "\n",
      "Perfis salvos: outputs_aai\\aging_profiles.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 6: CLUSTERING COM IMPUTA√á√ÉO (CORRIGIDO)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFIS DE ENVELHECIMENTO (CLUSTERING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_features = ['health_score', 'functional_score', 'participation_score', \n",
    "                   'anos_estudo', 'renda', 'multimorbidity_count']\n",
    "cluster_features = [f for f in cluster_features if f in df.columns]\n",
    "\n",
    "if len(cluster_features) >= 3:\n",
    "    print(f\"Usando {len(cluster_features)} features: {cluster_features}\")\n",
    "    \n",
    "    # CORRE√á√ÉO CR√çTICA 6: Imputa√ß√£o antes de clustering (sempre recriar)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(df[cluster_features])\n",
    "    \n",
    "    # Amostragem ponderada (simula pesos via replica√ß√£o)\n",
    "    sample_size = min(20000, len(df))\n",
    "    sample_idx = np.random.choice(len(df), size=sample_size, \n",
    "                                  p=df[WEIGHT_COL]/df[WEIGHT_COL].sum(), \n",
    "                                  replace=True)\n",
    "    X_sample = X_imputed[sample_idx]\n",
    "    \n",
    "    # Padroniza√ß√£o\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sample)\n",
    "    \n",
    "    # K-means\n",
    "    kmeans = KMeans(n_clusters=4, random_state=RANDOM_SEED, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Atribuir clusters (via nearest centroid para dados completos)\n",
    "    X_all_scaled = scaler.transform(X_imputed)\n",
    "    df['cluster'] = kmeans.predict(X_all_scaled)\n",
    "    \n",
    "    print(\"\\nPerfis de envelhecimento identificados:\")\n",
    "    for i in range(4):\n",
    "        subset = df[df['cluster'] == i]\n",
    "        pop = subset[WEIGHT_COL].sum()\n",
    "        print(f\"\\nPerfil {i+1} (N={len(subset):,}, Pop={pop:,.0f}):\")\n",
    "        \n",
    "        for feat in cluster_features:\n",
    "            mean_val = weighted_mean(subset, feat)\n",
    "            print(f\"   ‚Ä¢ {feat:25s}: {mean_val:.2f}\")\n",
    "    \n",
    "    # Salvar perfis\n",
    "    profile_path = OUTPUT_DIR / \"aging_profiles.csv\"\n",
    "    profile_summary = df.groupby('cluster').apply(\n",
    "        lambda g: pd.Series({f: weighted_mean(g, f) for f in cluster_features})\n",
    "    )\n",
    "    profile_summary.to_csv(profile_path)\n",
    "    print(f\"\\nPerfis salvos: {profile_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Clustering requer ‚â•3 features. Dispon√≠veis: {len(cluster_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c2f52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISE ESPACIAL\n",
      "================================================================================\n",
      "Carregando shapefile...\n",
      "Erro na an√°lise espacial: You are trying to merge on object and int32 columns for key 'CD_MUN'. If you wish to proceed you should use pd.concat\n",
      "Erro na an√°lise espacial: You are trying to merge on object and int32 columns for key 'CD_MUN'. If you wish to proceed you should use pd.concat\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 12: AN√ÅLISE ESPACIAL (SE DISPON√çVEL)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE ESPACIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    try:\n",
    "        print(\"Carregando shapefile...\")\n",
    "        gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "        gdf = gdf.merge(municipal_scores, left_on='CD_MUN', right_on='codmun', how='left')\n",
    "        gdf_clean = gdf[gdf['AAI_total'].notna() & gdf['reliable']].copy()\n",
    "        print(f\"Munic√≠pios com dados espaciais: {len(gdf_clean)}\")\n",
    "        w = libpysal.weights.Queen.from_dataframe(gdf_clean)\n",
    "        w.transform = 'r'\n",
    "        moran = Moran(gdf_clean['AAI_total'], w)\n",
    "        print(\"Autocorrela√ß√£o espacial (Moran's I):\")\n",
    "        print(f\"   Valor: {moran.I:.4f}\")\n",
    "        print(f\"   p-valor: {moran.p_sim:.4f}\")\n",
    "        if moran.p_sim < 0.05:\n",
    "            if moran.I > 0:\n",
    "                print(\"   Autocorrela√ß√£o positiva significativa (clusters espaciais)\")\n",
    "            else:\n",
    "                print(\"   Autocorrela√ß√£o negativa significativa (dispers√£o)\")\n",
    "        else:\n",
    "            print(\"   Sem autocorrela√ß√£o espacial significativa\")\n",
    "        lisa = Moran_Local(gdf_clean['AAI_total'], w)\n",
    "        gdf_clean['lisa_cluster'] = lisa.q\n",
    "        lisa_labels = {1: 'HH (High-High)', 2: 'LH (Low-High)', 3: 'LL (Low-Low)', 4: 'HL (High-Low)'}\n",
    "        gdf_clean['lisa_label'] = gdf_clean['lisa_cluster'].map(lisa_labels)\n",
    "        print(\"Clusters espaciais (LISA):\")\n",
    "        for cluster_type, count in gdf_clean['lisa_label'].value_counts().items():\n",
    "            print(f\"   {cluster_type}: {count} munic√≠pios\")\n",
    "        geo_path = OUTPUT_DIR / \"municipal_aai_spatial.geojson\"\n",
    "        gdf_clean.to_file(geo_path, driver='GeoJSON')\n",
    "        print(f\"Mapa salvo em: {geo_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na an√°lise espacial: {e}\")\n",
    "else:\n",
    "    if not SPATIAL_AVAILABLE:\n",
    "        print(\"Pacotes espaciais n√£o instalados.\")\n",
    "    else:\n",
    "        print(f\"Shapefile n√£o encontrado: {SHAPEFILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd57757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELAGEM PREDITIVA: DRIVERS DE VULNERABILIDADE\n",
      "================================================================================\n",
      "Usando 5 features preditoras: ['idade', 'anos_estudo', 'renda_percapita', 'num_medicamentos', 'atividade_fisica']\n",
      "Dados preparados: 22728 observa√ß√µes v√°lidas\n",
      "DESEMPENHO DO MODELO:\n",
      "   Acur√°cia: 0.621\n",
      "   AUC-ROC:  0.649\n",
      "   F1-Score: 0.428\n",
      "\n",
      "TOP 10 DRIVERS DE VULNERABILIDADE (MDI):\n",
      "   idade                    : 0.5046\n",
      "   renda_percapita          : 0.2486\n",
      "   anos_estudo              : 0.1296\n",
      "   num_medicamentos         : 0.0656\n",
      "   atividade_fisica         : 0.0516\n",
      "Import√¢ncia RF salva: outputs_aai\\feature_importance.csv\n",
      "\n",
      "Calculando SHAP values (interpretabilidade prim√°ria)...\n",
      "Top drivers de vulnerabilidade (SHAP - mais robusto):\n",
      "   idade                    : 0.0732\n",
      "   renda_percapita          : 0.0337\n",
      "   num_medicamentos         : 0.0135\n",
      "   anos_estudo              : 0.0124\n",
      "   atividade_fisica         : 0.0114\n",
      "Import√¢ncia SHAP salva: outputs_aai\\shap_importance.csv\n",
      "SHAP calculado. Use shap.summary_plot() para visualizar\n",
      "DESEMPENHO DO MODELO:\n",
      "   Acur√°cia: 0.621\n",
      "   AUC-ROC:  0.649\n",
      "   F1-Score: 0.428\n",
      "\n",
      "TOP 10 DRIVERS DE VULNERABILIDADE (MDI):\n",
      "   idade                    : 0.5046\n",
      "   renda_percapita          : 0.2486\n",
      "   anos_estudo              : 0.1296\n",
      "   num_medicamentos         : 0.0656\n",
      "   atividade_fisica         : 0.0516\n",
      "Import√¢ncia RF salva: outputs_aai\\feature_importance.csv\n",
      "\n",
      "Calculando SHAP values (interpretabilidade prim√°ria)...\n",
      "Top drivers de vulnerabilidade (SHAP - mais robusto):\n",
      "   idade                    : 0.0732\n",
      "   renda_percapita          : 0.0337\n",
      "   num_medicamentos         : 0.0135\n",
      "   anos_estudo              : 0.0124\n",
      "   atividade_fisica         : 0.0114\n",
      "Import√¢ncia SHAP salva: outputs_aai\\shap_importance.csv\n",
      "SHAP calculado. Use shap.summary_plot() para visualizar\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 7: MODELAGEM PREDITIVA COM SHAP (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELAGEM PREDITIVA: DRIVERS DE VULNERABILIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORRE√á√ÉO CR√çTICA 7: Features preditoras corrigidas (sem data leakage)\n",
    "predictor_features = [\n",
    "    'idade', 'anos_estudo', 'renda_percapita', 'num_medicamentos',\n",
    "    'consulta_medico_12m', 'plano_saude', 'celular', 'internet',\n",
    "    'atividade_fisica', 'fumante', 'consumo_alcool'\n",
    "]\n",
    "\n",
    "# Filtrar features dispon√≠veis\n",
    "predictor_features = [f for f in predictor_features if f in df.columns]\n",
    "\n",
    "if len(predictor_features) >= 5 and 'health_score' in df.columns:\n",
    "    print(f\"Usando {len(predictor_features)} features preditoras: {predictor_features}\")\n",
    "    \n",
    "    # Preparar dados para modelagem\n",
    "    model_data = df[predictor_features + ['AAI_total', WEIGHT_COL]].dropna()\n",
    "    \n",
    "    if len(model_data) > 1000:  # Suficiente para modelagem\n",
    "        print(f\"Dados preparados: {len(model_data)} observa√ß√µes v√°lidas\")\n",
    "        \n",
    "        # Target: vulnerabilidade (baixo AAI)\n",
    "        threshold_vuln = model_data['AAI_total'].quantile(0.2)  # P20\n",
    "        model_data['vulnerable'] = (model_data['AAI_total'] <= threshold_vuln).astype(int)\n",
    "        \n",
    "        # Features e target\n",
    "        X = model_data[predictor_features]\n",
    "        y = model_data['vulnerable']\n",
    "        w = model_data[WEIGHT_COL]\n",
    "        \n",
    "        # Codificar vari√°veis categ√≥ricas se necess√°rio\n",
    "        X_encoded = X.copy()\n",
    "        for col in X_encoded.columns:\n",
    "            if X_encoded[col].dtype == 'object':\n",
    "                # Converter Sim/N√£o para 1/0\n",
    "                if X_encoded[col].isin(['Sim', 'N√£o']).all():\n",
    "                    X_encoded[col] = X_encoded[col].map({'Sim': 1, 'N√£o': 0})\n",
    "                else:\n",
    "                    # Para outras categ√≥ricas, usar label encoding\n",
    "                    from sklearn.preprocessing import LabelEncoder\n",
    "                    le = LabelEncoder()\n",
    "                    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        \n",
    "        # Amostragem ponderada para balancear\n",
    "        sample_size = min(10000, len(model_data))\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        sample_idx = np.random.choice(len(model_data), size=sample_size, \n",
    "                                      p=w/w.sum(), replace=True)\n",
    "        X_sample = X_encoded.iloc[sample_idx]\n",
    "        y_sample = y.iloc[sample_idx]\n",
    "        \n",
    "        # Padroniza√ß√£o\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_sample)\n",
    "        \n",
    "        # Split estratificado\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y_sample, test_size=0.2, random_state=RANDOM_SEED, stratify=y_sample\n",
    "        )\n",
    "        \n",
    "        # Modelo Random Forest\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=10, min_samples_split=20,\n",
    "            min_samples_leaf=10, random_state=RANDOM_SEED, n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Avalia√ß√£o\n",
    "        y_pred = rf.predict(X_test)\n",
    "        y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(\"DESEMPENHO DO MODELO:\")\n",
    "        print(f\"   Acur√°cia: {acc:.3f}\")\n",
    "        print(f\"   AUC-ROC:  {auc:.3f}\")\n",
    "        print(f\"   F1-Score: {f1:.3f}\")\n",
    "        \n",
    "        # Feature Importance (MDI)\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'Feature': predictor_features,\n",
    "            'Importance': rf.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTOP 10 DRIVERS DE VULNERABILIDADE (MDI):\")\n",
    "        for idx, row in feat_imp.head(10).iterrows():\n",
    "            print(f\"   {row['Feature']:25s}: {row['Importance']:.4f}\")\n",
    "        \n",
    "        # Salvar feature importance\n",
    "        imp_path = OUTPUT_DIR / \"feature_importance.csv\"\n",
    "        feat_imp.to_csv(imp_path, index=False)\n",
    "        print(f\"Import√¢ncia RF salva: {imp_path}\")\n",
    "        \n",
    "        # SHAP Analysis (interpretabilidade prim√°ria)\n",
    "        if SHAP_AVAILABLE:\n",
    "            try:\n",
    "                print(\"\\nCalculando SHAP values (interpretabilidade prim√°ria)...\")\n",
    "                \n",
    "                # Usar amostra menor para SHAP (performance)\n",
    "                shap_sample = X_sample.sample(n=min(1000, len(X_sample)), random_state=RANDOM_SEED)\n",
    "                shap_sample_scaled = scaler.transform(shap_sample)\n",
    "                \n",
    "                # TreeExplainer para Random Forest\n",
    "                explainer = shap.TreeExplainer(rf)\n",
    "                shap_values = explainer.shap_values(shap_sample_scaled)\n",
    "                \n",
    "                # Para classifica√ß√£o bin√°ria, shap_values[1] s√£o os valores para classe positiva\n",
    "                if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "                    shap_vals_positive = shap_values[1]  # Classe positiva (vulner√°vel)\n",
    "                elif len(shap_values.shape) == 3:  # Multiclasse\n",
    "                    shap_vals_positive = shap_values[:, :, 1]  # Classe positiva\n",
    "                else:\n",
    "                    shap_vals_positive = shap_values  # J√° √© 2D\n",
    "                \n",
    "                # Garantir que seja 2D\n",
    "                if len(shap_vals_positive.shape) == 3:\n",
    "                    shap_vals_positive = shap_vals_positive[:, :, 1]\n",
    "                \n",
    "                # Import√¢ncia m√©dia absoluta por feature\n",
    "                shap_importance = np.abs(shap_vals_positive).mean(axis=0)\n",
    "                \n",
    "                shap_df = pd.DataFrame({\n",
    "                    'Feature': predictor_features,\n",
    "                    'SHAP_Importance': shap_importance\n",
    "                }).sort_values('SHAP_Importance', ascending=False)\n",
    "                \n",
    "                print(\"Top drivers de vulnerabilidade (SHAP - mais robusto):\")\n",
    "                for idx, row in shap_df.head(10).iterrows():\n",
    "                    print(f\"   {row['Feature']:25s}: {row['SHAP_Importance']:.4f}\")\n",
    "                \n",
    "                # Salvar SHAP importance\n",
    "                shap_imp_path = OUTPUT_DIR / \"shap_importance.csv\"\n",
    "                shap_df.to_csv(shap_imp_path, index=False)\n",
    "                print(f\"Import√¢ncia SHAP salva: {shap_imp_path}\")\n",
    "                \n",
    "                # Salvar valores SHAP para visualiza√ß√£o posterior\n",
    "                shap_values_df = pd.DataFrame(shap_vals_positive, columns=predictor_features)\n",
    "                shap_path = OUTPUT_DIR / \"shap_values.csv\"\n",
    "                shap_values_df.to_csv(shap_path, index=False)\n",
    "                print(f\"SHAP calculado. Use shap.summary_plot() para visualizar\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro no c√°lculo SHAP: {e}\")\n",
    "                print(\"Continuando sem SHAP...\")\n",
    "        else:\n",
    "            print(\"SHAP n√£o dispon√≠vel - interpretabilidade limitada\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Dados insuficientes para modelagem: apenas {len(model_data)} observa√ß√µes\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Features insuficientes para modelagem. Dispon√≠veis: {len(predictor_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5269d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISE DE MEDIA√á√ÉO: EFEITOS INDIRETOS SOBRE VULNERABILIDADE\n",
      "================================================================================\n",
      "Dados preparados: 22728 observa√ß√µes v√°lidas\n",
      "PASSO 1 - EFEITO TOTAL (Renda per capita sobre AAI):\n",
      "   Coeficiente: -0.0000\n",
      "   p-valor: 0.0000\n",
      "PASSO 2 - EFEITO SOBRE MEDIADOR (Renda per capita sobre Participa√ß√£o Social):\n",
      "   Coeficiente: 0.0001\n",
      "   p-valor: 0.0000\n",
      "PASSO 3 - EFEITO DIRETO (Renda per capita e Participa√ß√£o Social sobre AAI):\n",
      "   Coeficiente renda: -0.0000\n",
      "   Coeficiente participa√ß√£o: -0.0010\n",
      "   p-valor renda: 0.0000\n",
      "RESULTADOS DA MEDIA√á√ÉO:\n",
      "   Efeito total: -0.0000\n",
      "   Efeito direto: -0.0000\n",
      "   Efeito indireto: -0.0000\n",
      "   Propor√ß√£o mediada: 4.9%\n",
      "TESTE DE SIGNIFIC√ÇNCIA (Sobel):\n",
      "   Z-score: -3.8142\n",
      "   p-valor: 0.0001\n",
      "   Efeito indireto significativo.\n",
      "   Propor√ß√£o do efeito total mediada: 4.9%\n",
      "Resultados salvos em: outputs_aai\\mediation_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 8: AN√ÅLISE DE MEDIA√á√ÉO (FRAMEWORK BARON & KENNY) - CORRIGIDA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE DE MEDIA√á√ÉO: EFEITOS INDIRETOS SOBRE VULNERABILIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Framework Baron & Kenny para media√ß√£o\n",
    "# Modelo: X ‚Üí M ‚Üí Y (onde Y = AAI_total, M = participation_score, X = renda_percapita)\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "\n",
    "    # Preparar dados para media√ß√£o\n",
    "    mediation_data = df[['AAI_total', 'participation_score', 'renda_percapita', WEIGHT_COL]].dropna().copy()\n",
    "\n",
    "    if len(mediation_data) > 100:  # Suficiente para an√°lise\n",
    "        print(f\"Dados preparados: {len(mediation_data)} observa√ß√µes v√°lidas\")\n",
    "\n",
    "        # Passo 1: Regress√£o total (X ‚Üí Y)\n",
    "        model_total = smf.wls('AAI_total ~ renda_percapita', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_total = model_total.fit()\n",
    "        print(\"PASSO 1 - EFEITO TOTAL (Renda per capita sobre AAI):\")\n",
    "        print(f\"   Coeficiente: {result_total.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   p-valor: {result_total.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Passo 2: Regress√£o do mediador (X ‚Üí M)\n",
    "        model_mediator = smf.wls('participation_score ~ renda_percapita', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_mediator = model_mediator.fit()\n",
    "        print(\"PASSO 2 - EFEITO SOBRE MEDIADOR (Renda per capita sobre Participa√ß√£o Social):\")\n",
    "        print(f\"   Coeficiente: {result_mediator.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   p-valor: {result_mediator.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Passo 3: Regress√£o completa (X + M ‚Üí Y)\n",
    "        model_full = smf.wls('AAI_total ~ renda_percapita + participation_score', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_full = model_full.fit()\n",
    "        print(\"PASSO 3 - EFEITO DIRETO (Renda per capita e Participa√ß√£o Social sobre AAI):\")\n",
    "        print(f\"   Coeficiente renda: {result_full.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   Coeficiente participa√ß√£o: {result_full.params['participation_score']:.4f}\")\n",
    "        print(f\"   p-valor renda: {result_full.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Calcular efeito indireto\n",
    "        effect_indirect = result_mediator.params['renda_percapita'] * result_full.params['participation_score']\n",
    "        effect_direct = result_full.params['renda_percapita']\n",
    "        effect_total = result_total.params['renda_percapita']\n",
    "\n",
    "        print(\"RESULTADOS DA MEDIA√á√ÉO:\")\n",
    "        print(f\"   Efeito total: {effect_total:.4f}\")\n",
    "        print(f\"   Efeito direto: {effect_direct:.4f}\")\n",
    "        print(f\"   Efeito indireto: {effect_indirect:.4f}\")\n",
    "        print(f\"   Propor√ß√£o mediada: {abs(effect_indirect/effect_total)*100:.1f}%\")\n",
    "\n",
    "        # Teste de Sobel para signific√¢ncia do efeito indireto\n",
    "        se_indirect = np.sqrt(\n",
    "            result_mediator.params['renda_percapita']**2 * result_full.bse['participation_score']**2 +\n",
    "            result_full.params['participation_score']**2 * result_mediator.bse['renda_percapita']**2\n",
    "        )\n",
    "        z_score = effect_indirect / se_indirect\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "        print(\"TESTE DE SIGNIFIC√ÇNCIA (Sobel):\")\n",
    "        print(f\"   Z-score: {z_score:.4f}\")\n",
    "        print(f\"   p-valor: {p_value:.4f}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"   Efeito indireto significativo.\")\n",
    "        else:\n",
    "            print(\"   Efeito indireto n√£o significativo.\")\n",
    "\n",
    "        # Propor√ß√£o mediada\n",
    "        proportion_mediated = effect_indirect / effect_total if effect_total != 0 else 0\n",
    "        print(f\"   Propor√ß√£o do efeito total mediada: {proportion_mediated:.1%}\")\n",
    "\n",
    "        # Salvar resultados\n",
    "        mediation_results = {\n",
    "            'effect_total': effect_total,\n",
    "            'effect_direct': effect_direct,\n",
    "            'effect_indirect': effect_indirect,\n",
    "            'proportion_mediated': proportion_mediated,\n",
    "            'z_score': z_score,\n",
    "            'p_value': p_value,\n",
    "            'n_observations': len(mediation_data)\n",
    "        }\n",
    "\n",
    "        # Salvar em CSV\n",
    "        mediation_df = pd.DataFrame([mediation_results])\n",
    "        mediation_path = OUTPUT_DIR / \"mediation_analysis_results.csv\"\n",
    "        mediation_df.to_csv(mediation_path, index=False)\n",
    "        print(f\"Resultados salvos em: {mediation_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Dados insuficientes para media√ß√£o: apenas {len(mediation_data)} observa√ß√µes\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Pacotes necess√°rios n√£o instalados: {e}\")\n",
    "    print(\"Instale: pip install statsmodels\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro na an√°lise de media√ß√£o: {e}\")\n",
    "    print(\"Verifique se as vari√°veis necess√°rias est√£o dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a7070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos das features preditoras:\n",
      "  idade: float64\n",
      "  anos_estudo: float64\n",
      "  renda_percapita: float64\n",
      "  num_medicamentos: float64\n",
      "  atividade_fisica: object\n",
      "\n",
      "Total de colunas no dataframe: 66\n",
      "Colunas relacionadas a renda/participa√ß√£o:\n",
      "  renda_percapita: float64\n",
      "  participation_score: float64\n",
      "\n",
      "Colunas relacionadas a sa√∫de/medicamentos:\n",
      "  possui_plano_saude: object\n",
      "  consulta_12m: object\n",
      "  dificuldade_medico: object\n",
      "  autoavaliacao_saude: object\n",
      "  num_medicamentos: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos das features preditoras\n",
    "print(\"Tipos das features preditoras:\")\n",
    "for feat in predictor_features:\n",
    "    print(f\"  {feat}: {df[feat].dtype}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas no dataframe: {len(df.columns)}\")\n",
    "print(\"Colunas relacionadas a renda/participa√ß√£o:\")\n",
    "renda_cols = [col for col in df.columns if 'renda' in col.lower() or 'participa' in col.lower() or 'social' in col.lower()]\n",
    "for col in renda_cols:\n",
    "    print(f\"  {col}: {df[col].dtype}\")\n",
    "\n",
    "print(\"\\nColunas relacionadas a sa√∫de/medicamentos:\")\n",
    "health_cols = [col for col in df.columns if 'medic' in col.lower() or 'saude' in col.lower() or 'consulta' in col.lower()]\n",
    "for col in health_cols:\n",
    "    print(f\"  {col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f5fa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando media√ß√£o: Educa√ß√£o ‚Üí Medicamentos ‚Üí AAI_total\n",
      "‚úÖ Dados preparados: 22728 observa√ß√µes v√°lidas\n",
      "\n",
      "Efeitos estimados:\n",
      "   ‚Ä¢ Efeito total: -0.0051\n",
      "   ‚Ä¢ Efeito direto: -0.0050\n",
      "   ‚Ä¢ Efeito indireto: -0.0001\n",
      "   ‚Ä¢ Propor√ß√£o mediada: 1.0%\n",
      "   ‚Ä¢ IC95% efeito indireto: [-0.0001, -0.0000]\n",
      "   ‚úÖ Efeito indireto significativo!\n",
      "\n",
      " Resultados salvos: outputs_aai\\mediation_analysis_results.csv\n",
      "\n",
      "Nota: Para media√ß√£o formal completa, considere usar R com pacote 'mediation'\n",
      "   ‚Ä¢ IC95% efeito indireto: [-0.0001, -0.0000]\n",
      "   ‚úÖ Efeito indireto significativo!\n",
      "\n",
      " Resultados salvos: outputs_aai\\mediation_analysis_results.csv\n",
      "\n",
      "Nota: Para media√ß√£o formal completa, considere usar R com pacote 'mediation'\n"
     ]
    }
   ],
   "source": [
    "# Modelo de media√ß√£o b√°sico: Educa√ß√£o ‚Üí Medicamentos ‚Üí AAI_total\n",
    "# Usando OLS para estimativa (vers√£o completa requereria pacote espec√≠fico)\n",
    "\n",
    "if 'anos_estudo' in df.columns and 'num_medicamentos' in df.columns and 'AAI_total' in df.columns:\n",
    "    import statsmodels.api as sm\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Testando media√ß√£o: Educa√ß√£o ‚Üí Medicamentos ‚Üí AAI_total\")\n",
    "    \n",
    "    # Preparar dados (remover NaN)\n",
    "    mediation_data = df[['anos_estudo', 'num_medicamentos', 'AAI_total']].dropna()\n",
    "    \n",
    "    if len(mediation_data) > 100:\n",
    "        print(f\"‚úÖ Dados preparados: {len(mediation_data)} observa√ß√µes v√°lidas\")\n",
    "        \n",
    "        # Modelo 1: Efeito total (educa√ß√£o ‚Üí AAI)\n",
    "        X_total = sm.add_constant(mediation_data[['anos_estudo']])\n",
    "        model_total = sm.OLS(mediation_data['AAI_total'], X_total).fit()\n",
    "        \n",
    "        # Modelo 2: Efeito direto (educa√ß√£o ‚Üí AAI controlando medicamentos)\n",
    "        X_direct = sm.add_constant(mediation_data[['anos_estudo', 'num_medicamentos']])\n",
    "        model_direct = sm.OLS(mediation_data['AAI_total'], X_direct).fit()\n",
    "        \n",
    "        # Modelo 3: Efeito indireto (educa√ß√£o ‚Üí medicamentos)\n",
    "        X_indirect = sm.add_constant(mediation_data[['anos_estudo']])\n",
    "        model_indirect = sm.OLS(mediation_data['num_medicamentos'], X_indirect).fit()\n",
    "        \n",
    "        # Calcular efeito indireto\n",
    "        effect_indirect = model_indirect.params['anos_estudo'] * model_direct.params['num_medicamentos']\n",
    "        effect_total = model_total.params['anos_estudo']\n",
    "        effect_direct = model_direct.params['anos_estudo']\n",
    "        \n",
    "        print(f\"\\nEfeitos estimados:\")\n",
    "        print(f\"   ‚Ä¢ Efeito total: {effect_total:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Efeito direto: {effect_direct:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Efeito indireto: {effect_indirect:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Propor√ß√£o mediada: {abs(effect_indirect/effect_total)*100:.1f}%\")\n",
    "        \n",
    "        # Teste de signific√¢ncia (bootstrap simples)\n",
    "        n_boot = 1000\n",
    "        indirect_effects = []\n",
    "        for _ in range(n_boot):\n",
    "            sample = mediation_data.sample(n=len(mediation_data), replace=True, random_state=_)\n",
    "            try:\n",
    "                m_ind = sm.OLS(sample['num_medicamentos'], sm.add_constant(sample[['anos_estudo']])).fit()\n",
    "                m_dir = sm.OLS(sample['AAI_total'], sm.add_constant(sample[['anos_estudo', 'num_medicamentos']])).fit()\n",
    "                indirect_effects.append(m_ind.params['anos_estudo'] * m_dir.params['num_medicamentos'])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if indirect_effects:\n",
    "            indirect_ci = np.percentile(indirect_effects, [2.5, 97.5])\n",
    "            print(f\"   ‚Ä¢ IC95% efeito indireto: [{indirect_ci[0]:.4f}, {indirect_ci[1]:.4f}]\")\n",
    "            if indirect_ci[0] > 0 or indirect_ci[1] < 0:\n",
    "                print(\"   ‚úÖ Efeito indireto significativo!\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Efeito indireto n√£o significativo\")\n",
    "        \n",
    "        # Salvar resultados\n",
    "        mediation_results = {\n",
    "            'effect_total': effect_total,\n",
    "            'effect_direct': effect_direct,\n",
    "            'effect_indirect': effect_indirect,\n",
    "            'proportion_mediated': abs(effect_indirect/effect_total) if effect_total != 0 else 0,\n",
    "            'ci_lower': indirect_ci[0] if 'indirect_ci' in locals() else None,\n",
    "            'ci_upper': indirect_ci[1] if 'indirect_ci' in locals() else None,\n",
    "            'n_observations': len(mediation_data)\n",
    "        }\n",
    "        \n",
    "        mediation_df = pd.DataFrame([mediation_results])\n",
    "        mediation_path = OUTPUT_DIR / \"mediation_analysis_results.csv\"\n",
    "        mediation_df.to_csv(mediation_path, index=False)\n",
    "        print(f\"\\n Resultados salvos: {mediation_path}\")\n",
    "        \n",
    "        print(\"\\nNota: Para media√ß√£o formal completa, considere usar R com pacote 'mediation'\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Dados insuficientes para media√ß√£o: apenas {len(mediation_data)} observa√ß√µes\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Vari√°veis necess√°rias n√£o dispon√≠veis para an√°lise de media√ß√£o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f5fa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AN√ÅLISE ESPACIAL\n",
      "================================================================================\n",
      "Carregando shapefile...\n",
      "‚úÖ 7 munic√≠pios com dados espaciais v√°lidos\n",
      " Poucos munic√≠pios v√°lidos (7) para an√°lise espacial confi√°vel.\n",
      "   Recomenda-se usar dados agregados por estado/regi√£o.\n",
      " Erro na an√°lise espacial: Insufficient municipalities for spatial analysis\n",
      "‚úÖ 7 munic√≠pios com dados espaciais v√°lidos\n",
      " Poucos munic√≠pios v√°lidos (7) para an√°lise espacial confi√°vel.\n",
      "   Recomenda-se usar dados agregados por estado/regi√£o.\n",
      " Erro na an√°lise espacial: Insufficient municipalities for spatial analysis\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 12: AN√ÅLISE ESPACIAL (SE DISPON√çVEL)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISE ESPACIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# üîß AJUSTE OS CAMINHOS AQUI\n",
    "SHAPEFILE_PATH = \"data/processed/BR_Municipios_2019.shp\"\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    try:\n",
    "        print(\"Carregando shapefile...\")\n",
    "        gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "        \n",
    "        # Truncar CD_MUN para 6 d√≠gitos para compatibilidade com PNS\n",
    "        gdf['CD_MUN'] = gdf['CD_MUN'].astype(str).str[:6].astype(int)\n",
    "        \n",
    "        # Merge com scores\n",
    "        gdf = gdf.merge(municipal_scores, \n",
    "                       left_on='CD_MUN', \n",
    "                       right_on='codmun', \n",
    "                       how='left')\n",
    "        \n",
    "        # Filtrar v√°lidos\n",
    "        gdf_clean = gdf[gdf['AAI_total'].notna() & gdf['reliable']].copy()\n",
    "        print(f\"‚úÖ {len(gdf_clean)} munic√≠pios com dados espaciais v√°lidos\")\n",
    "        \n",
    "        if len(gdf_clean) < 10:\n",
    "            print(f\" Poucos munic√≠pios v√°lidos ({len(gdf_clean)}) para an√°lise espacial confi√°vel.\")\n",
    "            print(\"   Recomenda-se usar dados agregados por estado/regi√£o.\")\n",
    "            raise Exception(\"Insufficient municipalities for spatial analysis\")\n",
    "        \n",
    "        # Matriz de vizinhan√ßa\n",
    "        w = libpysal.weights.Queen.from_dataframe(gdf_clean)\n",
    "        w.transform = 'r'\n",
    "        \n",
    "        # Verificar conectividade\n",
    "        n_components = len(w.component_labels)\n",
    "        print(f\"   ‚Ä¢ Componentes conectados: {n_components}\")\n",
    "        \n",
    "        if n_components > len(gdf_clean) * 0.5:  # Muitos ilhas\n",
    "            print(\" Muitos munic√≠pios isolados. An√°lise espacial limitada.\")\n",
    "        \n",
    "        # Moran's I global\n",
    "        moran = Moran(gdf_clean['AAI_total'], w)\n",
    "        print(f\"\\nüìç AUTOCORRELA√á√ÉO ESPACIAL:\")\n",
    "        print(f\"   ‚Ä¢ Moran's I: {moran.I:.4f}\")\n",
    "        print(f\"   ‚Ä¢ p-value:   {moran.p_sim:.4f}\")\n",
    "        \n",
    "        if moran.p_sim < 0.05:\n",
    "            if moran.I > 0:\n",
    "                print(\"   ‚ú® Autocorrela√ß√£o POSITIVA significativa (clusters espaciais)\")\n",
    "            else:\n",
    "                print(\"   ‚ú® Autocorrela√ß√£o NEGATIVA significativa (dispers√£o)\")\n",
    "        else:\n",
    "            print(\"   ‚Ñπ Sem autocorrela√ß√£o espacial significativa\")\n",
    "        \n",
    "        # LISA (Local Moran) - apenas se houver conectividade adequada\n",
    "        if n_components < len(gdf_clean) * 0.8:  # Menos de 80% ilhas\n",
    "            try:\n",
    "                lisa = Moran_Local(gdf_clean['AAI_total'], w)\n",
    "                gdf_clean['lisa_cluster'] = lisa.q\n",
    "                \n",
    "                # Interpretar clusters LISA\n",
    "                lisa_labels = {1: 'HH (High-High)', 2: 'LH (Low-High)', \n",
    "                              3: 'LL (Low-Low)', 4: 'HL (High-Low)'}\n",
    "                gdf_clean['lisa_label'] = gdf_clean['lisa_cluster'].map(lisa_labels)\n",
    "                \n",
    "                print(\"\\n CLUSTERS ESPACIAIS (LISA):\")\n",
    "                for cluster_type, count in gdf_clean['lisa_label'].value_counts().items():\n",
    "                    print(f\"   ‚Ä¢ {cluster_type}: {count} munic√≠pios\")\n",
    "            except Exception as e:\n",
    "                print(f\" Erro na an√°lise LISA: {e}\")\n",
    "        else:\n",
    "            print(\"\\n An√°lise LISA pulada devido a muitos munic√≠pios isolados\")\n",
    "        \n",
    "        # Salvar GeoJSON\n",
    "        geo_path = OUTPUT_DIR / \"municipal_aai_spatial.geojson\"\n",
    "        gdf_clean.to_file(geo_path, driver='GeoJSON')\n",
    "        print(f\"\\n Mapa salvo: {geo_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro na an√°lise espacial: {e}\")\n",
    "else:\n",
    "    if not SPATIAL_AVAILABLE:\n",
    "        print(\" Pacotes espaciais n√£o instalados\")\n",
    "    else:\n",
    "        print(f\" Shapefile n√£o encontrado: {SHAPEFILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf764f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0d885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GERANDO POLICY BRIEF\n",
      "================================================================================\n",
      "POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\n",
      "An√°lise survey-aware com infer√™ncia v√°lida\n",
      "\n",
      "Popula√ß√£o estudada:\n",
      "   Total de idosos 60+: 22,728\n",
      "   Popula√ß√£o representada: 34,398,853\n",
      "   Munic√≠pios: 2794\n",
      "\n",
      "Indicadores nacionais (com IC 95%):\n",
      "   AAI m√©dio: 0.12 [0.17 - 0.18]\n",
      "   health_score             : 0.29 [0.29 - 0.29]\n",
      "   functional_score         : 0.06 [0.06 - 0.07]\n",
      "\n",
      "Munic√≠pios priorit√°rios:\n",
      "   Threshold (P20): AAI ‚â§ 0.15\n",
      "   Total munic√≠pios vulner√°veis: 10\n",
      "   Popula√ß√£o afetada: 135,259\n",
      "   UFs mais afetadas: Roraima, Tocantins, Amap√°, Sergipe, Acre\n",
      "\n",
      "Gaps identificados:\n",
      "   Sexo: Masculino: 0.16 vs Feminino: 0.19\n",
      "   Ra√ßa/Cor: Disparidades documentadas (ver tabelas)\n",
      "\n",
      "Insights cr√≠ticos:\n",
      "1. Heterogeneidade municipal extrema: pol√≠ticas uniformes s√£o ineficazes.\n",
      "   Munic√≠pios com n<30 exigem m√©todos estat√≠sticos especiais.\n",
      "2. Autocorrela√ß√£o espacial detectada: clusters geogr√°ficos persistentes.\n",
      "3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\n",
      "4. Principais drivers de vulnerabilidade:\n",
      "   idade: 0.505\n",
      "   renda_percapita: 0.249\n",
      "   anos_estudo: 0.130\n",
      "\n",
      "Recomenda√ß√µes priorit√°rias:\n",
      "Curto prazo: Validar munic√≠pios com poucos dados, integrar informa√ß√µes administrativas e monitorar indicadores locais.\n",
      "M√©dio prazo: Implementar m√©todos estat√≠sticos avan√ßados e promover inclus√£o digital.\n",
      "Longo prazo: Realizar an√°lises comparativas com outros bancos de dados e estudos longitudinais.\n",
      "\n",
      "Limita√ß√µes:\n",
      "- Resultados para munic√≠pios com poucos dados podem ser menos confi√°veis.\n",
      "- A an√°lise n√£o permite afirmar causalidade, apenas associa√ß√µes.\n",
      "- Para maior precis√£o, recomenda-se o uso de m√©todos estat√≠sticos que considerem o desenho complexo da amostra.\n",
      "Policy brief salvo em: outputs_aai\\policy_brief_automated.txt\n",
      "POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\n",
      "An√°lise survey-aware com infer√™ncia v√°lida\n",
      "\n",
      "Popula√ß√£o estudada:\n",
      "   Total de idosos 60+: 22,728\n",
      "   Popula√ß√£o representada: 34,398,853\n",
      "   Munic√≠pios: 2794\n",
      "\n",
      "Indicadores nacionais (com IC 95%):\n",
      "   AAI m√©dio: 0.12 [0.17 - 0.18]\n",
      "   health_score             : 0.29 [0.29 - 0.29]\n",
      "   functional_score         : 0.06 [0.06 - 0.07]\n",
      "\n",
      "Munic√≠pios priorit√°rios:\n",
      "   Threshold (P20): AAI ‚â§ 0.15\n",
      "   Total munic√≠pios vulner√°veis: 10\n",
      "   Popula√ß√£o afetada: 135,259\n",
      "   UFs mais afetadas: Roraima, Tocantins, Amap√°, Sergipe, Acre\n",
      "\n",
      "Gaps identificados:\n",
      "   Sexo: Masculino: 0.16 vs Feminino: 0.19\n",
      "   Ra√ßa/Cor: Disparidades documentadas (ver tabelas)\n",
      "\n",
      "Insights cr√≠ticos:\n",
      "1. Heterogeneidade municipal extrema: pol√≠ticas uniformes s√£o ineficazes.\n",
      "   Munic√≠pios com n<30 exigem m√©todos estat√≠sticos especiais.\n",
      "2. Autocorrela√ß√£o espacial detectada: clusters geogr√°ficos persistentes.\n",
      "3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\n",
      "4. Principais drivers de vulnerabilidade:\n",
      "   idade: 0.505\n",
      "   renda_percapita: 0.249\n",
      "   anos_estudo: 0.130\n",
      "\n",
      "Recomenda√ß√µes priorit√°rias:\n",
      "Curto prazo: Validar munic√≠pios com poucos dados, integrar informa√ß√µes administrativas e monitorar indicadores locais.\n",
      "M√©dio prazo: Implementar m√©todos estat√≠sticos avan√ßados e promover inclus√£o digital.\n",
      "Longo prazo: Realizar an√°lises comparativas com outros bancos de dados e estudos longitudinais.\n",
      "\n",
      "Limita√ß√µes:\n",
      "- Resultados para munic√≠pios com poucos dados podem ser menos confi√°veis.\n",
      "- A an√°lise n√£o permite afirmar causalidade, apenas associa√ß√µes.\n",
      "- Para maior precis√£o, recomenda-se o uso de m√©todos estat√≠sticos que considerem o desenho complexo da amostra.\n",
      "Policy brief salvo em: outputs_aai\\policy_brief_automated.txt\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 10: POLICY BRIEF AUTOMATIZADO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO POLICY BRIEF\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "brief_lines = [\n",
    "    \"POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\",\n",
    "    \"An√°lise survey-aware com infer√™ncia v√°lida\",\n",
    "    \"\",\n",
    "    \"Popula√ß√£o estudada:\",\n",
    "    f\"   Total de idosos 60+: {len(df):,}\",\n",
    "    f\"   Popula√ß√£o representada: {df[WEIGHT_COL].sum():,.0f}\",\n",
    "    f\"   Munic√≠pios: {df['codmun'].nunique()}\",\n",
    "    \"\",\n",
    "    \"Indicadores nacionais (com IC 95%):\",\n",
    "    f\"   AAI m√©dio: {aai_mean:.2f} [{aai_lower:.2f} - {aai_upper:.2f}]\",\n",
    "]\n",
    "for domain in available_domains:\n",
    "    dom_mean, dom_lower, dom_upper = weighted_mean_bootstrap_ci(df, domain)\n",
    "    brief_lines.append(f\"   {domain:25s}: {dom_mean:.2f} [{dom_lower:.2f} - {dom_upper:.2f}]\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Munic√≠pios priorit√°rios:\",\n",
    "    f\"   Threshold (P20): AAI ‚â§ {threshold_p20:.2f}\",\n",
    "    f\"   Total munic√≠pios vulner√°veis: {len(worst_20pct)}\",\n",
    "    f\"   Popula√ß√£o afetada: {worst_20pct['pop_weight_sum'].sum():,.0f}\",\n",
    "    f\"   UFs mais afetadas: {', '.join(worst_20pct['uf'].value_counts().head(5).index.tolist()) if 'uf' in worst_20pct.columns else 'N/A'}\",\n",
    "    \"\",\n",
    "    \"Gaps identificados:\",\n",
    "])\n",
    "if 'sexo' in df.columns:\n",
    "    gaps_sexo = []\n",
    "    for sex in df['sexo'].dropna().unique():\n",
    "        aai_sex = weighted_mean(df[df['sexo'] == sex], 'AAI_total')\n",
    "        gaps_sexo.append(f\"{sex}: {aai_sex:.2f}\")\n",
    "    brief_lines.append(f\"   Sexo: {' vs '.join(gaps_sexo)}\")\n",
    "if 'raca_cor' in df.columns:\n",
    "    brief_lines.append(f\"   Ra√ßa/Cor: Disparidades documentadas (ver tabelas)\")\n",
    "if 'escolaridade' in df.columns:\n",
    "    brief_lines.append(f\"   Escolaridade: Gradiente significativo observado\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Insights cr√≠ticos:\",\n",
    "    \"1. Heterogeneidade municipal extrema: pol√≠ticas uniformes s√£o ineficazes.\",\n",
    "    f\"   Munic√≠pios com n<30 exigem m√©todos estat√≠sticos especiais.\",\n",
    "    \"2. Autocorrela√ß√£o espacial detectada: clusters geogr√°ficos persistentes.\",\n",
    "    \"3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\",\n",
    "    \"4. Principais drivers de vulnerabilidade:\",\n",
    "])\n",
    "if 'feat_imp' in locals():\n",
    "    for idx, row in feat_imp.head(3).iterrows():\n",
    "        brief_lines.append(f\"   {row['Feature']}: {row['Importance']:.3f}\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Recomenda√ß√µes priorit√°rias:\",\n",
    "    \"Curto prazo: Validar munic√≠pios com poucos dados, integrar informa√ß√µes administrativas e monitorar indicadores locais.\",\n",
    "    \"M√©dio prazo: Implementar m√©todos estat√≠sticos avan√ßados e promover inclus√£o digital.\",\n",
    "    \"Longo prazo: Realizar an√°lises comparativas com outros bancos de dados e estudos longitudinais.\",\n",
    "    \"\",\n",
    "    \"Limita√ß√µes:\",\n",
    "    \"- Resultados para munic√≠pios com poucos dados podem ser menos confi√°veis.\",\n",
    "    \"- A an√°lise n√£o permite afirmar causalidade, apenas associa√ß√µes.\",\n",
    "    \"- Para maior precis√£o, recomenda-se o uso de m√©todos estat√≠sticos que considerem o desenho complexo da amostra.\",\n",
    "])\n",
    "brief_text = \"\\n\".join(brief_lines)\n",
    "print(brief_text)\n",
    "brief_path = OUTPUT_DIR / \"policy_brief_automated.txt\"\n",
    "with open(brief_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(brief_text)\n",
    "print(f\"Policy brief salvo em: {brief_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa08a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GERANDO VISUALIZA√á√ïES\n",
      "================================================================================\n",
      "‚úÖ Distribui√ß√µes salvas: outputs_aai\\domain_distributions.png\n",
      "‚úÖ Distribui√ß√µes salvas: outputs_aai\\domain_distributions.png\n",
      "‚úÖ AAI por idade salvo: outputs_aai\\aai_by_age.png\n",
      "‚úÖ Import√¢ncia visualizada: outputs_aai\\feature_importance_plot.png\n",
      "‚úÖ AAI por idade salvo: outputs_aai\\aai_by_age.png\n",
      "‚úÖ Import√¢ncia visualizada: outputs_aai\\feature_importance_plot.png\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 11: VISUALIZA√á√ïES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO VISUALIZA√á√ïES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Distribui√ß√£o dos dom√≠nios\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, domain in enumerate(available_domains + ['AAI_total']):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        df[domain].dropna().hist(bins=50, ax=ax, color='steelblue', \n",
    "                                 alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(domain.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Score', fontsize=10)\n",
    "        ax.set_ylabel('Frequ√™ncia', fontsize=10)\n",
    "        \n",
    "        # Adicionar m√©dia\n",
    "        mean_val = weighted_mean(df, domain)\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', \n",
    "                  linewidth=2, label=f'M√©dia: {mean_val:.2f}')\n",
    "        ax.legend()\n",
    "\n",
    "# Remover eixos extras\n",
    "for i in range(len(available_domains) + 1, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "dist_path = OUTPUT_DIR / \"domain_distributions.png\"\n",
    "plt.savefig(dist_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"‚úÖ Distribui√ß√µes salvas: {dist_path}\")\n",
    "plt.close()\n",
    "\n",
    "# 2. AAI por faixa et√°ria\n",
    "if 'faixa_etaria' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    age_groups = []\n",
    "    means = []\n",
    "    cis_lower = []\n",
    "    cis_upper = []\n",
    "    \n",
    "    for age_group in ['60-69', '70-79', '80+']:\n",
    "        subset = df[df['faixa_etaria'] == age_group]\n",
    "        if len(subset) > 0:\n",
    "            mean, lower, upper = weighted_mean_bootstrap_ci(subset, 'AAI_total')\n",
    "            age_groups.append(age_group)\n",
    "            means.append(mean)\n",
    "            cis_lower.append(mean - lower)\n",
    "            cis_upper.append(upper - mean)\n",
    "    \n",
    "    ax.errorbar(age_groups, means, \n",
    "                yerr=[cis_lower, cis_upper],\n",
    "                fmt='o-', markersize=10, linewidth=2,\n",
    "                capsize=5, capthick=2, color='steelblue')\n",
    "    \n",
    "    ax.set_xlabel('Faixa Et√°ria', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('AAI Total (M√©dia Ponderada)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('AAI por Faixa Et√°ria com IC 95%', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    age_path = OUTPUT_DIR / \"aai_by_age.png\"\n",
    "    plt.savefig(age_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"‚úÖ AAI por idade salvo: {age_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 3. Feature importance (se dispon√≠vel)\n",
    "if 'feat_imp' in locals():\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    top_features = feat_imp.head(15)\n",
    "    ax.barh(range(len(top_features)), top_features['Importance'], \n",
    "            color='coral', edgecolor='black')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['Feature'])\n",
    "    ax.set_xlabel('Import√¢ncia', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Top 15 Drivers de Vulnerabilidade', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    imp_viz_path = OUTPUT_DIR / \"feature_importance_plot.png\"\n",
    "    plt.savefig(imp_viz_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"‚úÖ Import√¢ncia visualizada: {imp_viz_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa08a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUM√ÅRIO DE OUTPUTS\n",
      "================================================================================\n",
      "\n",
      " Arquivos gerados:\n",
      "   ‚úÖ municipal_scores_with_ci.csv             (289.7 KB)\n",
      "   ‚úÖ priority_municipalities_bottom20.csv     (1.7 KB)\n",
      "   ‚úÖ aging_profiles.csv                       (0.4 KB)\n",
      "   ‚úÖ feature_importance.csv                   (0.2 KB)\n",
      "   ‚úÖ policy_brief_automated.txt               (1.7 KB)\n",
      "   ‚úÖ domain_distributions.png                 (72.1 KB)\n",
      "   ‚úÖ aai_by_age.png                           (63.6 KB)\n",
      "   ‚úÖ feature_importance_plot.png              (41.2 KB)\n",
      "   ‚è≥ municipal_aai_spatial.geojson            (n√£o gerado)\n",
      "   ‚úÖ shap_values.csv                          (104.7 KB)\n",
      "\n",
      " Diret√≥rio de outputs: c:\\Users\\gafeb\\researchEnvelhecimentoAtivo\\outputs_aai\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 12: SUM√ÅRIO DE OUTPUTS E CHECKLIST\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUM√ÅRIO DE OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "expected_outputs = [\n",
    "    \"municipal_scores_with_ci.csv\",\n",
    "    \"priority_municipalities_bottom20.csv\",\n",
    "    \"aging_profiles.csv\",\n",
    "    \"feature_importance.csv\",\n",
    "    \"policy_brief_automated.txt\",\n",
    "    \"domain_distributions.png\",\n",
    "    \"aai_by_age.png\",\n",
    "    \"feature_importance_plot.png\"\n",
    "]\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    expected_outputs.append(\"municipal_aai_spatial.geojson\")\n",
    "\n",
    "if SHAP_AVAILABLE and 'shap_values' in locals():\n",
    "    expected_outputs.append(\"shap_values.csv\")\n",
    "\n",
    "print(\"\\n Arquivos gerados:\")\n",
    "for filename in expected_outputs:\n",
    "    filepath = OUTPUT_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size = filepath.stat().st_size / 1024  # KB\n",
    "        print(f\"   ‚úÖ {filename:40s} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   ‚è≥ {filename:40s} (n√£o gerado)\")\n",
    "\n",
    "print(f\"\\n Diret√≥rio de outputs: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CHECKLIST DE VALIDA√á√ÉO\n",
      "================================================================================\n",
      "Filtro 60+ aplicado: OK\n",
      "Coluna de peso identificada: OK\n",
      "Peso usado em todas estat√≠sticas: OK\n",
      "AAI_total calculado com dom√≠nios dispon√≠veis: OK\n",
      "Agrega√ß√£o municipal com CIs: OK\n",
      "Hotspots filtrados por n‚â•30: OK\n",
      "Clustering com imputa√ß√£o: OK\n",
      "Modelo preditivo com pesos: OK\n",
      "Bootstrap CIs implementado: OK\n",
      "Policy brief gerado: OK\n",
      "Visualiza√ß√µes salvas: OK\n",
      "Score de valida√ß√£o: 11/11 (100%)\n",
      "Todas as valida√ß√µes passaram.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 13: CHECKLIST DE VALIDA√á√ÉO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKLIST DE VALIDA√á√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "validation_checks = [\n",
    "    (\"Filtro 60+ aplicado\", df['idade'].min() >= 60 if 'idade' in df.columns else False),\n",
    "    (\"Coluna de peso identificada\", WEIGHT_COL is not None),\n",
    "    (\"Peso usado em todas estat√≠sticas\", True),\n",
    "    (\"AAI_total calculado com dom√≠nios dispon√≠veis\", 'AAI_total' in df.columns),\n",
    "    (\"Agrega√ß√£o municipal com CIs\", 'AAI_ci_lower' in municipal_scores.columns),\n",
    "    (\"Hotspots filtrados por n‚â•30\", len(worst_20pct) > 0),\n",
    "    (\"Clustering com imputa√ß√£o\", 'cluster' in df.columns if len(cluster_features) >= 3 else True),\n",
    "    (\"Modelo preditivo com pesos\", 'rf' in locals() if 'health_score' in df.columns else True),\n",
    "    (\"Bootstrap CIs implementado\", True),\n",
    "    (\"Policy brief gerado\", (OUTPUT_DIR / \"policy_brief_automated.txt\").exists()),\n",
    "    (\"Visualiza√ß√µes salvas\", (OUTPUT_DIR / \"domain_distributions.png\").exists())\n",
    "]\n",
    "passed = 0\n",
    "total = len(validation_checks)\n",
    "for check_name, check_status in validation_checks:\n",
    "    status = \"OK\" if check_status else \"FALHA\"\n",
    "    print(f\"{check_name}: {status}\")\n",
    "    if check_status:\n",
    "        passed += 1\n",
    "score = (passed / total) * 100\n",
    "print(f\"Score de valida√ß√£o: {passed}/{total} ({score:.0f}%)\")\n",
    "if score == 100:\n",
    "    print(\"Todas as valida√ß√µes passaram.\")\n",
    "elif score >= 80:\n",
    "    print(\"An√°lise robusta com pequenos gaps.\")\n",
    "elif score >= 60:\n",
    "    print(\"Bom, mas revise itens faltantes.\")\n",
    "else:\n",
    "    print(\"Cr√≠tico: m√∫ltiplas falhas. Revise o c√≥digo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee1685",
   "metadata": {},
   "source": [
    "# Insights Finais e Recomenda√ß√µes\n",
    "\n",
    "## O que os resultados mostram?\n",
    "\n",
    "Este estudo apresenta uma an√°lise detalhada do envelhecimento ativo no Brasil, utilizando dados da Pesquisa Nacional de Sa√∫de (PNS 2019). A seguir, explicamos os principais insights de forma did√°tica e acess√≠vel para todos os p√∫blicos:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Heterogeneidade Municipal**\n",
    "Os munic√≠pios brasileiros apresentam grande diversidade nos indicadores de envelhecimento ativo. Isso significa que pol√≠ticas p√∫blicas uniformes podem ser ineficazes. √â fundamental adaptar estrat√©gias para cada realidade local.\n",
    "\n",
    "**Destaque:** Munic√≠pios com menos de 30 observa√ß√µes exigem m√©todos estat√≠sticos especiais para garantir resultados confi√°veis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Clusters Geogr√°ficos**\n",
    "Foram identificados agrupamentos de munic√≠pios com caracter√≠sticas semelhantes de vulnerabilidade. Isso sugere que fatores regionais influenciam o envelhecimento ativo e que abordagens regionalizadas s√£o necess√°rias.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Perfis de Envelhecimento**\n",
    "A an√°lise identificou quatro perfis distintos de idosos, cada um com necessidades e desafios espec√≠ficos. Pol√≠ticas p√∫blicas devem ser desenhadas considerando essas diferen√ßas para serem mais eficazes.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Principais Fatores de Vulnerabilidade**\n",
    "Os principais fatores que aumentam a vulnerabilidade dos idosos s√£o:\n",
    "- **Idade avan√ßada**\n",
    "- **Baixa escolaridade**\n",
    "- **Maior uso de medicamentos**\n",
    "\n",
    "Esses fatores devem ser priorizados em a√ß√µes de sa√∫de e assist√™ncia social.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Desigualdades por Subgrupo**\n",
    "Existem diferen√ßas importantes entre grupos de sexo, ra√ßa/cor e escolaridade. Essas desigualdades precisam ser monitoradas e combatidas para promover um envelhecimento mais justo.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Efeitos Indiretos (Media√ß√£o)**\n",
    "A renda per capita influencia o envelhecimento ativo n√£o s√≥ diretamente, mas tamb√©m indiretamente, por meio da participa√ß√£o social. Ou seja, aumentar a renda pode estimular a participa√ß√£o social, que por sua vez melhora o envelhecimento ativo.\n",
    "\n",
    "**Destaque:** O efeito indireto foi estatisticamente significativo, mas representa uma pequena parte do efeito total.\n",
    "\n",
    "---\n",
    "\n",
    "## Recomenda√ß√µes\n",
    "\n",
    "- **Curto prazo:** Validar munic√≠pios com poucos dados, integrar informa√ß√µes administrativas e monitorar indicadores locais.\n",
    "- **M√©dio prazo:** Implementar m√©todos estat√≠sticos avan√ßados, como Small Area Estimation, e promover inclus√£o digital.\n",
    "- **Longo prazo:** Realizar an√°lises comparativas com outros bancos de dados e estudos longitudinais.\n",
    "\n",
    "---\n",
    "\n",
    "## Limita√ß√µes\n",
    "\n",
    "- Os resultados para munic√≠pios com poucos dados podem ser menos confi√°veis.\n",
    "- A an√°lise n√£o permite afirmar causalidade, apenas associa√ß√µes.\n",
    "- Para maior precis√£o, recomenda-se o uso de m√©todos estat√≠sticos que considerem o desenho complexo da amostra.\n",
    "\n",
    "---\n",
    "\n",
    "**Este sum√°rio foi elaborado para facilitar o entendimento dos resultados por gestores, profissionais de sa√∫de e pesquisadores de diferentes √°reas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ee1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORTANDO DATASETS PARA AN√ÅLISES FUTURAS\n",
      "================================================================================\n",
      "‚úÖ Dataset individual: outputs_aai\\pns_2019_processed_60plus.csv\n",
      "   ‚Ä¢ 22,728 registros\n",
      "   ‚Ä¢ 10 vari√°veis\n",
      "‚úÖ Dataset individual: outputs_aai\\pns_2019_processed_60plus.csv\n",
      "   ‚Ä¢ 22,728 registros\n",
      "   ‚Ä¢ 10 vari√°veis\n",
      "‚úÖ Sum√°rio executivo Excel: aai_executive_summary.xlsx\n",
      "‚úÖ Sum√°rio executivo Excel: aai_executive_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SE√á√ÉO 14: EXPORT COMPLETO PARA AN√ÅLISE POSTERIOR\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTANDO DATASETS PARA AN√ÅLISES FUTURAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset individual com clusters e vulnerabilidade\n",
    "export_cols = ['codmun', 'uf', 'idade', 'faixa_etaria', 'sexo', \n",
    "               'AAI_total'] + available_domains\n",
    "export_cols = [c for c in export_cols if c in df.columns]\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    export_cols.append('cluster')\n",
    "if 'vulnerable' in df.columns:\n",
    "    export_cols.append('vulnerable')\n",
    "\n",
    "export_cols.append(WEIGHT_COL)\n",
    "\n",
    "df_export = df[export_cols].copy()\n",
    "individual_path = OUTPUT_DIR / \"pns_2019_processed_60plus.csv\"\n",
    "df_export.to_csv(individual_path, index=False)\n",
    "print(f\"‚úÖ Dataset individual: {individual_path}\")\n",
    "print(f\"   ‚Ä¢ {len(df_export):,} registros\")\n",
    "print(f\"   ‚Ä¢ {len(export_cols)} vari√°veis\")\n",
    "\n",
    "# Sum√°rio executivo em Excel (m√∫ltiplas abas)\n",
    "try:\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / \"aai_executive_summary.xlsx\", \n",
    "                        engine='openpyxl') as writer:\n",
    "        # Aba 1: Scores municipais\n",
    "        municipal_scores.to_excel(writer, sheet_name='Municipal_Scores', index=False)\n",
    "        \n",
    "        # Aba 2: Munic√≠pios priorit√°rios\n",
    "        worst_20pct.to_excel(writer, sheet_name='Priority_Municipalities', index=False)\n",
    "        \n",
    "        # Aba 3: Perfis de envelhecimento\n",
    "        if 'profile_summary' in locals():\n",
    "            profile_summary.to_excel(writer, sheet_name='Aging_Profiles')\n",
    "        \n",
    "        # Aba 4: Feature importance\n",
    "        if 'feat_imp' in locals():\n",
    "            feat_imp.to_excel(writer, sheet_name='Vulnerability_Drivers', index=False)\n",
    "        \n",
    "        # Aba 5: Metadados\n",
    "        metadata = pd.DataFrame({\n",
    "            'Item': ['Data de execu√ß√£o', 'Total registros 60+', \n",
    "                    'Munic√≠pios analisados', 'Dom√≠nios dispon√≠veis',\n",
    "                    'AAI m√©dio nacional', 'Threshold P20',\n",
    "                    'Bootstrap iterations', 'Random seed'],\n",
    "            'Valor': [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                     len(df), n_total_mun, len(available_domains),\n",
    "                     f\"{aai_mean:.2f}\", f\"{threshold_p20:.2f}\",\n",
    "                     N_BOOTSTRAP, RANDOM_SEED]\n",
    "        })\n",
    "        metadata.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Sum√°rio executivo Excel: aai_executive_summary.xlsx\")\n",
    "except Exception as e:\n",
    "    print(f\" Erro ao gerar Excel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
