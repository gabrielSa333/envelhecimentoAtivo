{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb3ce5b",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados: Envelhecimento Ativo no Brasil\n",
    "\n",
    "## O que é este notebook?\n",
    "\n",
    "Este documento apresenta uma análise completa sobre o **envelhecimento ativo** no Brasil, utilizando dados da Pesquisa Nacional de Saúde (PNS 2019). Aqui, transformamos dados complexos em insights práticos para orientar políticas públicas e ações sociais.\n",
    "\n",
    "### Por que isso importa?\n",
    "\n",
    "O Brasil está envelhecendo rapidamente. Em 2019, havia mais de 30 milhões de pessoas com 60 anos ou mais. Garantir que esses idosos tenham uma vida digna, saudável e participativa é um desafio nacional que exige dados precisos e ações direcionadas.\n",
    "\n",
    "### O que vamos descobrir?\n",
    "\n",
    "Ao longo desta análise, responderemos perguntas como:\n",
    "- Como está a qualidade de vida dos idosos brasileiros?\n",
    "- Quais municípios mais precisam de atenção?\n",
    "- Quais fatores influenciam o envelhecimento saudável?\n",
    "- Existem grupos diferentes de idosos com necessidades distintas?\n",
    "\n",
    "### Como funciona o Índice de Envelhecimento Ativo (AAI)?\n",
    "\n",
    "Criamos um \"termômetro\" chamado AAI que mede o envelhecimento ativo combinando quatro pilares principais:\n",
    "1. **Saúde**: Capacidade funcional e controle de doenças crônicas\n",
    "2. **Participação Social**: Engajamento comunitário e acesso a redes de apoio\n",
    "3. **Segurança Econômica**: Renda adequada e proteção social\n",
    "4. **Educação e Acesso**: Conhecimento e conectividade digital\n",
    "\n",
    "Cada pilar recebe uma nota de 0 a 1, e o AAI final é a média desses pilares.\n",
    "\n",
    "### Nossa abordagem rigorosa\n",
    "\n",
    "Usamos técnicas estatísticas avançadas para garantir que os resultados representem toda a população idosa brasileira, não apenas as pessoas entrevistadas. Isso inclui:\n",
    "- **Pesos amostrais**: Para corrigir diferenças na probabilidade de seleção\n",
    "- **Intervalos de confiança**: Para mostrar a precisão das nossas estimativas\n",
    "- **Bootstrap**: Para validar a robustez dos resultados\n",
    "\n",
    "---\n",
    "\n",
    "*Este notebook foi desenvolvido para ser acessível a gestores públicos, profissionais de saúde, pesquisadores e qualquer pessoa interessada em melhorar a qualidade de vida dos idosos brasileiros.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f20bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>estrato</th>\n",
       "      <th>upa</th>\n",
       "      <th>id_domicilio</th>\n",
       "      <th>num_pessoas_domicilio</th>\n",
       "      <th>area_metropolitana</th>\n",
       "      <th>mora_sozinho</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>raca_cor</th>\n",
       "      <th>...</th>\n",
       "      <th>iadl_score</th>\n",
       "      <th>functional_raw</th>\n",
       "      <th>functional_score</th>\n",
       "      <th>dependencia_SUS</th>\n",
       "      <th>cobertura_influenza</th>\n",
       "      <th>autoav_z</th>\n",
       "      <th>multimorb_z</th>\n",
       "      <th>functional_z</th>\n",
       "      <th>health_score_raw</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cônjuge ou companheiro(a)</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Outro morador</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.522010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>1.200084</td>\n",
       "      <td>3.196276</td>\n",
       "      <td>3.167954</td>\n",
       "      <td>0.744213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>-0.146557</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.856293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uf  estrato        upa  id_domicilio  num_pessoas_domicilio  \\\n",
       "0  Rondônia  1110011  110000016             1                      1   \n",
       "1  Rondônia  1110011  110000016             1                      1   \n",
       "2  Rondônia  1110011  110000016             1                      1   \n",
       "3  Rondônia  1110011  110000016             1                      1   \n",
       "4  Rondônia  1110011  110000016             1                      1   \n",
       "\n",
       "   area_metropolitana               mora_sozinho       sexo  idade raca_cor  \\\n",
       "0                   1  Cônjuge ou companheiro(a)  Masculino   69.0    Parda   \n",
       "1                   1              Outro morador   Feminino   78.0    Parda   \n",
       "2                   1       Pessoa de referência  Masculino   81.0    Parda   \n",
       "3                   1       Pessoa de referência  Masculino   81.0    Parda   \n",
       "4                   1       Pessoa de referência   Feminino   72.0    Parda   \n",
       "\n",
       "   ... iadl_score  functional_raw  functional_score dependencia_SUS  \\\n",
       "0  ...          7              18              0.10               0   \n",
       "1  ...          5              17              0.15               0   \n",
       "2  ...          2               9              0.55               0   \n",
       "3  ...          7              19              0.05               0   \n",
       "4  ...          7              16              0.20               0   \n",
       "\n",
       "  cobertura_influenza  autoav_z multimorb_z functional_z health_score_raw  \\\n",
       "0                   0       NaN   -1.027069     0.187726              NaN   \n",
       "1                   0       NaN   -1.027069     0.522010              NaN   \n",
       "2                   2 -0.344963    1.200084     3.196276         3.167954   \n",
       "3                   2 -0.344963    0.795147    -0.146557        -0.559990   \n",
       "4                   0       NaN   -1.027069     0.856293              NaN   \n",
       "\n",
       "  health_score  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2     0.744213  \n",
       "3     0.305083  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/processed/pns_2019_pandas.csv\")    \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adcc9f",
   "metadata": {},
   "source": [
    "# Análise Avançada do Índice de Envelhecimento Ativo (AAI) - PNS 2019\n",
    "\n",
    "Este notebook realiza uma análise completa dos dados da Pesquisa Nacional de Saúde (PNS 2019) para construir e validar o Índice de Envelhecimento Ativo (AAI) no Brasil. \n",
    "\n",
    "**Objetivos principais:**\n",
    "- Construir um índice multidimensional de envelhecimento ativo\n",
    "- Identificar municípios prioritários para intervenções\n",
    "- Analisar desigualdades por subgrupos populacionais\n",
    "- Desenvolver modelos preditivos de vulnerabilidade\n",
    "\n",
    "**Metodologia:**\n",
    "- Análise survey-aware com pesos amostrais\n",
    "- Intervalos de confiança via bootstrap\n",
    "- Agregação municipal com controle de qualidade\n",
    "- Modelagem preditiva com validação cruzada\n",
    "\n",
    "**Outputs esperados:**\n",
    "- Scores municipais com intervalos de confiança\n",
    "- Lista de municípios prioritários\n",
    "- Perfis de envelhecimento via clustering\n",
    "- Drivers de vulnerabilidade identificados\n",
    "- Policy brief automatizado\n",
    "- Visualizações e datasets processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b30d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis no df:\n",
      "['uf', 'estrato', 'upa', 'id_domicilio', 'num_pessoas_domicilio', 'area_metropolitana', 'mora_sozinho', 'sexo', 'idade', 'raca_cor', 'situacao_ocupacional', 'anos_estudo', 'renda_percapita', 'possui_plano_saude', 'consulta_12m', 'internacoes_12m', 'atendimento_sus', 'dificuldade_alimentar', 'dificuldade_banho', 'dificuldade_vestir', 'ajuda_adl', 'dificuldade_compras', 'dificuldade_medico', 'ajuda_iadl', 'queda_12m', 'usa_internet', 'usa_celular', 'depressao_diag', 'vacina_influenza', 'autoavaliacao_saude', 'peso_real', 'altura', 'atividade_fisica', 'fumante_atual', 'hipertensao', 'diabetes', 'doenca_cardiaca', 'avc', 'doenca_respiratoria', 'cancer', 'num_medicamentos', 'id_individuo', 'area_urbana', 'peso_amostral', 'regiao', 'imc', 'multimorbidity_count', 'multimorb_cat', 'adl_score', 'iadl_score', 'functional_raw', 'functional_score', 'dependencia_SUS', 'cobertura_influenza', 'autoav_z', 'multimorb_z', 'functional_z', 'health_score_raw', 'health_score']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colunas disponíveis no df:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca89c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>estrato</th>\n",
       "      <th>upa</th>\n",
       "      <th>id_domicilio</th>\n",
       "      <th>num_pessoas_domicilio</th>\n",
       "      <th>area_metropolitana</th>\n",
       "      <th>mora_sozinho</th>\n",
       "      <th>sexo</th>\n",
       "      <th>idade</th>\n",
       "      <th>raca_cor</th>\n",
       "      <th>situacao_ocupacional</th>\n",
       "      <th>anos_estudo</th>\n",
       "      <th>renda_percapita</th>\n",
       "      <th>possui_plano_saude</th>\n",
       "      <th>consulta_12m</th>\n",
       "      <th>internacoes_12m</th>\n",
       "      <th>atendimento_sus</th>\n",
       "      <th>dificuldade_alimentar</th>\n",
       "      <th>dificuldade_banho</th>\n",
       "      <th>dificuldade_vestir</th>\n",
       "      <th>ajuda_adl</th>\n",
       "      <th>dificuldade_compras</th>\n",
       "      <th>dificuldade_medico</th>\n",
       "      <th>ajuda_iadl</th>\n",
       "      <th>queda_12m</th>\n",
       "      <th>usa_internet</th>\n",
       "      <th>usa_celular</th>\n",
       "      <th>depressao_diag</th>\n",
       "      <th>vacina_influenza</th>\n",
       "      <th>autoavaliacao_saude</th>\n",
       "      <th>peso_real</th>\n",
       "      <th>altura</th>\n",
       "      <th>atividade_fisica</th>\n",
       "      <th>fumante_atual</th>\n",
       "      <th>hipertensao</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>doenca_cardiaca</th>\n",
       "      <th>avc</th>\n",
       "      <th>doenca_respiratoria</th>\n",
       "      <th>cancer</th>\n",
       "      <th>num_medicamentos</th>\n",
       "      <th>id_individuo</th>\n",
       "      <th>area_urbana</th>\n",
       "      <th>peso_amostral</th>\n",
       "      <th>regiao</th>\n",
       "      <th>imc</th>\n",
       "      <th>multimorbidity_count</th>\n",
       "      <th>multimorb_cat</th>\n",
       "      <th>adl_score</th>\n",
       "      <th>iadl_score</th>\n",
       "      <th>functional_raw</th>\n",
       "      <th>functional_score</th>\n",
       "      <th>dependencia_SUS</th>\n",
       "      <th>cobertura_influenza</th>\n",
       "      <th>autoav_z</th>\n",
       "      <th>multimorb_z</th>\n",
       "      <th>functional_z</th>\n",
       "      <th>health_score_raw</th>\n",
       "      <th>health_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cônjuge ou companheiro(a)</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Ocupado</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Outro morador</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não aplicável</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.522010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não aplicável</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Nenhuma dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Muito boa</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não, mas já fumou</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>0</td>\n",
       "      <td>117.758255</td>\n",
       "      <td>Norte</td>\n",
       "      <td>123.456790</td>\n",
       "      <td>11</td>\n",
       "      <td>3+</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>1.200084</td>\n",
       "      <td>3.196276</td>\n",
       "      <td>3.167954</td>\n",
       "      <td>0.744213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Desocupado</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Muito boa</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não, mas já fumou</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>0</td>\n",
       "      <td>117.758255</td>\n",
       "      <td>Norte</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>3+</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.344963</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>-0.146557</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rondônia</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110000016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pessoa de referência</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Fora da força de trabalho</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não consegue de modo algum</td>\n",
       "      <td>Muita dificuldade</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>Não sabe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.589085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.253731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.027069</td>\n",
       "      <td>0.856293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uf  estrato        upa  id_domicilio  num_pessoas_domicilio  \\\n",
       "0  Rondônia  1110011  110000016             1                      1   \n",
       "1  Rondônia  1110011  110000016             1                      1   \n",
       "2  Rondônia  1110011  110000016             1                      1   \n",
       "3  Rondônia  1110011  110000016             1                      1   \n",
       "4  Rondônia  1110011  110000016             1                      1   \n",
       "\n",
       "   area_metropolitana               mora_sozinho       sexo  idade raca_cor  \\\n",
       "0                   1  Cônjuge ou companheiro(a)  Masculino   69.0    Parda   \n",
       "1                   1              Outro morador   Feminino   78.0    Parda   \n",
       "2                   1       Pessoa de referência  Masculino   81.0    Parda   \n",
       "3                   1       Pessoa de referência  Masculino   81.0    Parda   \n",
       "4                   1       Pessoa de referência   Feminino   72.0    Parda   \n",
       "\n",
       "        situacao_ocupacional  anos_estudo  renda_percapita possui_plano_saude  \\\n",
       "0                    Ocupado          6.0           1200.0                Não   \n",
       "1              Não aplicável          6.0           1200.0                Não   \n",
       "2              Não aplicável          5.0           1200.0                Não   \n",
       "3                 Desocupado          5.0           1200.0                Não   \n",
       "4  Fora da força de trabalho          6.0           1200.0                Não   \n",
       "\n",
       "    consulta_12m  internacoes_12m atendimento_sus       dificuldade_alimentar  \\\n",
       "0  Não se aplica                1             Não  Não consegue de modo algum   \n",
       "1  Não se aplica                1             Não  Não consegue de modo algum   \n",
       "2       Não sabe                1             Não         Nenhuma dificuldade   \n",
       "3  Não se aplica                1             Não  Não consegue de modo algum   \n",
       "4  Não se aplica                1             Não           Muita dificuldade   \n",
       "\n",
       "            dificuldade_banho          dificuldade_vestir ajuda_adl  \\\n",
       "0  Não consegue de modo algum           Muita dificuldade       Não   \n",
       "1  Não consegue de modo algum  Não consegue de modo algum       Não   \n",
       "2           Muita dificuldade           Muita dificuldade       Sim   \n",
       "3  Não consegue de modo algum  Não consegue de modo algum       NaN   \n",
       "4           Muita dificuldade           Muita dificuldade       Não   \n",
       "\n",
       "          dificuldade_compras   dificuldade_medico ajuda_iadl queda_12m  \\\n",
       "0  Não consegue de modo algum    Muita dificuldade        Não       Não   \n",
       "1  Não consegue de modo algum  Nenhuma dificuldade        Sim       Sim   \n",
       "2         Nenhuma dificuldade  Nenhuma dificuldade        Sim       Sim   \n",
       "3  Não consegue de modo algum    Muita dificuldade        Não       Não   \n",
       "4  Não consegue de modo algum    Muita dificuldade        Sim       Não   \n",
       "\n",
       "  usa_internet usa_celular depressao_diag vacina_influenza  \\\n",
       "0          Não         Não       Não sabe         Não sabe   \n",
       "1          Não         Não       Não sabe         Não sabe   \n",
       "2          Sim         Não       Não sabe              Não   \n",
       "3          Sim         Não       Não sabe              Não   \n",
       "4          Não         Não       Não sabe         Não sabe   \n",
       "\n",
       "  autoavaliacao_saude  peso_real  altura atividade_fisica      fumante_atual  \\\n",
       "0                 NaN        NaN     NaN         Não sabe                Não   \n",
       "1                 NaN        NaN     NaN         Não sabe                Não   \n",
       "2           Muito boa       81.0    0.81              Não  Não, mas já fumou   \n",
       "3           Muito boa       75.0    0.75              Não  Não, mas já fumou   \n",
       "4                 NaN        NaN     NaN         Não sabe                Não   \n",
       "\n",
       "  hipertensao  diabetes doenca_cardiaca       avc doenca_respiratoria  \\\n",
       "0    Não sabe  Não sabe        Não sabe  Não sabe            Não sabe   \n",
       "1    Não sabe  Não sabe        Não sabe  Não sabe            Não sabe   \n",
       "2         Sim       Não             Não  Não sabe                 Não   \n",
       "3         Sim       Sim             Não  Não sabe                 Não   \n",
       "4    Não sabe  Não sabe        Não sabe  Não sabe            Não sabe   \n",
       "\n",
       "     cancer  num_medicamentos  id_individuo area_urbana  peso_amostral regiao  \\\n",
       "0  Não sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "1  Não sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "2  Não sabe               2.0     85.589085           0     117.758255  Norte   \n",
       "3  Não sabe               2.0     85.589085           0     117.758255  Norte   \n",
       "4  Não sabe               2.0     85.589085         NaN            NaN    NaN   \n",
       "\n",
       "          imc  multimorbidity_count multimorb_cat  adl_score  iadl_score  \\\n",
       "0  149.253731                     0             0         11           7   \n",
       "1  149.253731                     0             0         12           5   \n",
       "2  123.456790                    11            3+          7           2   \n",
       "3  133.333333                     9            3+         12           7   \n",
       "4  149.253731                     0             0          9           7   \n",
       "\n",
       "   functional_raw  functional_score  dependencia_SUS  cobertura_influenza  \\\n",
       "0              18              0.10                0                    0   \n",
       "1              17              0.15                0                    0   \n",
       "2               9              0.55                0                    2   \n",
       "3              19              0.05                0                    2   \n",
       "4              16              0.20                0                    0   \n",
       "\n",
       "   autoav_z  multimorb_z  functional_z  health_score_raw  health_score  \n",
       "0       NaN    -1.027069      0.187726               NaN           NaN  \n",
       "1       NaN    -1.027069      0.522010               NaN           NaN  \n",
       "2 -0.344963     1.200084      3.196276          3.167954      0.744213  \n",
       "3 -0.344963     0.795147     -0.146557         -0.559990      0.305083  \n",
       "4       NaN    -1.027069      0.856293               NaN           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quero ver todas as colunas sem supressao visual\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca89c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BIBLIOTECAS CARREGADAS COM SUCESSO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ANÁLISE AVANÇADA DO ÍNDICE DE ENVELHECIMENTO ATIVO (AAI)\n",
    "# PNS 2019 - Versão Corrigida e Metodologicamente Robusta\n",
    "# ===============================================================================\n",
    "# Autor: Análise Senior - Metodologia Survey-Aware\n",
    "# Data: Outubro 2024\n",
    "# Objetivo: AAI municipal com inferência válida e intervenções acionáveis\n",
    "# ===============================================================================\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pacotes opcionais\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from esda.moran import Moran, Moran_Local\n",
    "    import libpysal\n",
    "    SPATIAL_AVAILABLE = True\n",
    "except:\n",
    "    SPATIAL_AVAILABLE = False\n",
    "    print(\" Pacotes espaciais não disponíveis (instale: geopandas, esda, libpysal)\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\" SHAP não disponível (instale: shap)\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BIBLIOTECAS CARREGADAS COM SUCESSO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69ee4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados de: data/processed/pns_2019_pandas.csv\n",
      "Dataset carregado: 43,554 linhas × 59 colunas\n",
      "Dataset carregado: 43,554 linhas × 59 colunas\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 1: CONFIGURAÇÃO E CARREGAMENTO\n",
    "# ===============================================================================\n",
    "\n",
    "# 🔧 AJUSTE OS CAMINHOS AQUI\n",
    "DATA_PATH = \"data/processed/pns_2019_pandas.csv\"\n",
    "SHAPEFILE_PATH = \"data/processed/BR_municipios_2019.shp\"\n",
    "DATASUS_PATH = \"data/processed/datasus_facilities.csv\"\n",
    "OUTPUT_DIR = Path(\"./outputs_aai\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configurações metodológicas\n",
    "MIN_N_MUNICIPAL = 30  # Mínimo de observações para estimativas municipais confiáveis\n",
    "N_BOOTSTRAP = 500     # Iterações para CIs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"\\nCarregando dados de: {DATA_PATH}\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "    print(f\"Dataset carregado: {df.shape[0]:,} linhas × {df.shape[1]} colunas\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivo não encontrado. Ajuste DATA_PATH\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9424a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " PADRONIZAÇÃO DE VARIÁVEIS\n",
      "================================================================================\n",
      "Coluna de peso identificada: 'peso_amostral'\n",
      "\n",
      "Validação de variáveis essenciais:\n",
      "  ✓ idade        - Idade do indivíduo\n",
      "  ✗ codmun       - Código do município [FALTANDO]\n",
      "  ✓ uf           - Unidade Federativa\n",
      "  ✓ estrato      - Estrato amostral\n",
      "\n",
      "Atenção: Variáveis ausentes podem limitar análises: ['codmun']\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 2: PADRONIZAÇÃO DE VARIÁVEIS CRÍTICAS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PADRONIZAÇÃO DE VARIÁVEIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col_name in ['peso', 'peso_amostral', 'peso_exp', 'weight']:\n",
    "    if col_name in df.columns:\n",
    "        WEIGHT_COL = col_name\n",
    "        print(f\"Coluna de peso identificada: '{WEIGHT_COL}'\")\n",
    "        break\n",
    "\n",
    "if WEIGHT_COL is None:\n",
    "    raise SystemExit(\"Erro critico: Coluna de peso não encontrada. Estimativas não-ponderadas são invalidas.\")\n",
    "\n",
    "# Validar variáveis essenciais\n",
    "essential_vars = {\n",
    "    'idade': 'Idade do indivíduo',\n",
    "    'codmun': 'Código do município',\n",
    "    'uf': 'Unidade Federativa',\n",
    "    'estrato': 'Estrato amostral'\n",
    "}\n",
    "\n",
    "print(\"\\nValidação de variáveis essenciais:\")\n",
    "missing_essentials = []\n",
    "for var, desc in essential_vars.items():\n",
    "    if var in df.columns:\n",
    "        print(f\"  ✓ {var:12s} - {desc}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {var:12s} - {desc} [FALTANDO]\")\n",
    "        missing_essentials.append(var)\n",
    "\n",
    "if missing_essentials:\n",
    "    print(f\"\\nAtenção: Variáveis ausentes podem limitar análises: {missing_essentials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539baede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Coluna 'codmun' derivada de 'upa'\n"
     ]
    }
   ],
   "source": [
    "# Derivar codmun se não existir\n",
    "if 'codmun' not in df.columns:\n",
    "    if 'upa' in df.columns:\n",
    "        df['codmun'] = df['upa'].astype(str).str[:6].astype(int)\n",
    "        print(\" Coluna 'codmun' derivada de 'upa'\")\n",
    "    else:\n",
    "        raise SystemExit(\" ERRO: Não é possível derivar 'codmun'. Coluna 'upa' não encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0caa642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " APLICANDO FILTROS\n",
      "================================================================================\n",
      "Registros originais: 43,554\n",
      "Apos filtro 60+: 43,554 registros (100.0%)\n",
      "Removendo 20826 registros com peso missing\n",
      "\n",
      "Distribuição etária (ponderada):\n",
      "  60-69: 20,778,673 (60.4%)\n",
      "  70-79: 9,720,855 (28.3%)\n",
      "  80+: 3,899,325 (11.3%)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 3: FILTROS E PREPARAÇÃO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" APLICANDO FILTROS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_original = len(df)\n",
    "print(f\"Registros originais: {n_original:,}\")\n",
    "\n",
    "# Filtro 60+\n",
    "if 'idade' in df.columns:\n",
    "    df = df[df['idade'] >= 60].copy()\n",
    "    print(f\"Apos filtro 60+: {len(df):,} registros ({len(df)/n_original*100:.1f}%)\")\n",
    "else:\n",
    "    raise SystemExit(\"Erro: Coluna 'idade' não encontrada\")\n",
    "\n",
    "# Verificar pesos válidos\n",
    "invalid_weights = df[WEIGHT_COL].isnull().sum()\n",
    "if invalid_weights > 0:\n",
    "    print(f\"Removendo {invalid_weights} registros com peso missing\")\n",
    "    df = df[df[WEIGHT_COL].notna()].copy()\n",
    "\n",
    "# Criar faixa etária\n",
    "df['faixa_etaria'] = pd.cut(df['idade'], \n",
    "                             bins=[60, 70, 80, 120], \n",
    "                             labels=['60-69', '70-79', '80+'],\n",
    "                             include_lowest=True)\n",
    "\n",
    "print(f\"\\nDistribuição etária (ponderada):\")\n",
    "for age_group in ['60-69', '70-79', '80+']:\n",
    "    pop = df[df['faixa_etaria'] == age_group][WEIGHT_COL].sum()\n",
    "    pct = pop / df[WEIGHT_COL].sum() * 100\n",
    "    print(f\"  {age_group}: {pop:,.0f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce075b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " DEFININDO FUNÇÕES ESTATÍSTICAS SURVEY-AWARE\n",
      "================================================================================\n",
      "Funções definidas com bootstrap para CIs\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 4: FUNÇÕES PONDERADAS COM BOOTSTRAP\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DEFININDO FUNÇÕES ESTATÍSTICAS SURVEY-AWARE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def weighted_mean(data, col, weight_col=WEIGHT_COL):\n",
    "    \"\"\"Média ponderada com tratamento de missing\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna()\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    return (valid[col] * valid[weight_col]).sum() / valid[weight_col].sum()\n",
    "\n",
    "def weighted_std(data, col, weight_col=WEIGHT_COL):\n",
    "    \"\"\"Desvio padrão ponderado\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna()\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    mean = weighted_mean(data, col, weight_col)\n",
    "    variance = ((valid[col] - mean)**2 * valid[weight_col]).sum() / valid[weight_col].sum()\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "def weighted_quantile(data, col, q, weight_col=WEIGHT_COL):\n",
    "    \"\"\"Quantil ponderado\"\"\"\n",
    "    valid = data[[col, weight_col]].dropna().sort_values(col)\n",
    "    if len(valid) == 0:\n",
    "        return np.nan\n",
    "    cumsum = valid[weight_col].cumsum()\n",
    "    cutoff = valid[weight_col].sum() * q\n",
    "    return valid[col].iloc[(cumsum >= cutoff).argmax()]\n",
    "\n",
    "def weighted_mean_bootstrap_ci(data, col, weight_col=WEIGHT_COL, n_boot=N_BOOTSTRAP, ci=95):\n",
    "    \"\"\"\n",
    "    CORREÇÃO CRÍTICA: Bootstrap para intervalos de confiança\n",
    "    Respeita estrutura de pesos amostrais\n",
    "    \"\"\"\n",
    "    valid = data[[col, weight_col]].dropna().reset_index(drop=True)\n",
    "    if len(valid) < 10:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    estimates = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = np.random.choice(len(valid), size=len(valid), replace=True)\n",
    "        boot_data = valid.iloc[idx]\n",
    "        boot_mean = (boot_data[col] * boot_data[weight_col]).sum() / boot_data[weight_col].sum()\n",
    "        estimates.append(boot_mean)\n",
    "    \n",
    "    point_est = weighted_mean(data, col, weight_col)\n",
    "    lower = np.percentile(estimates, (100-ci)/2)\n",
    "    upper = np.percentile(estimates, 100-(100-ci)/2)\n",
    "    \n",
    "    return point_est, lower, upper\n",
    "\n",
    "print(\"Funções definidas com bootstrap para CIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d4b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " ANÁLISE DE DADOS FALTANTES\n",
      "================================================================================\n",
      "\n",
      "Disponibilidade de domínios:\n",
      "  ✓ health_score              - 0.0% missing\n",
      "  ✓ functional_score          - 0.0% missing\n",
      "  ✗ participation_score       - NÃO DISPONÍVEL\n",
      "  ✗ econ_score                - NÃO DISPONÍVEL\n",
      "  ✗ access_score              - NÃO DISPONÍVEL\n",
      "\n",
      "Total de domínios disponíveis: 2/5\n",
      "\n",
      "Padrão de missing por idade (potencial viés):\n",
      "Faixa       60-69 70-79   80+\n",
      "Variável                     \n",
      "anos_estudo  0.0%  0.0%  0.0%\n",
      "\n",
      "================================================================================\n",
      "CONSTRUÇÃO DOS SCORES FALTANTES\n",
      "================================================================================\n",
      "\n",
      "Construindo participation_score...\n",
      "   ✓ Internet access incluído\n",
      "   ✓ Celular access incluído\n",
      "   → participation_score criado (média de 2 indicadores)\n",
      "\n",
      "Construindo econ_score...\n",
      "   ✓ Educação incluída\n",
      "   → econ_score criado (média de 1 indicadores)\n",
      "\n",
      "Construindo access_score...\n",
      "   ✓ Plano de saúde incluído\n",
      "   ✓ Consulta médica incluída\n",
      "   → access_score criado (média de 2 indicadores)\n",
      "\n",
      "Validação dos scores criados:\n",
      "   ✓ participation_score : média=51.4, missing=0.0%\n",
      "   ✓ econ_score          : média=42.5, missing=0.0%\n",
      "   ✓ access_score        : média=7.7, missing=0.0%\n",
      "\n",
      "Construção de scores concluída!\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 5: ANÁLISE DE MISSINGNESS\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ANÁLISE DE DADOS FALTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identificar domínios disponíveis\n",
    "ALL_DOMAINS = ['health_score', 'functional_score', 'participation_score', \n",
    "               'econ_score', 'access_score']\n",
    "\n",
    "print(\"\\nDisponibilidade de domínios:\")\n",
    "available_domains = []\n",
    "for domain in ALL_DOMAINS:\n",
    "    if domain in df.columns:\n",
    "        missing_pct = df[domain].isnull().mean() * 100\n",
    "        print(f\"  ✓ {domain:25s} - {missing_pct:.1f}% missing\")\n",
    "        available_domains.append(domain)\n",
    "    else:\n",
    "        print(f\"  ✗ {domain:25s} - NÃO DISPONÍVEL\")\n",
    "\n",
    "if len(available_domains) == 0:\n",
    "    raise SystemExit(\"Erro critico: Nenhum domínio encontrado. Verifique nomes das colunas.\")\n",
    "\n",
    "print(f\"\\nTotal de domínios disponíveis: {len(available_domains)}/{len(ALL_DOMAINS)}\")\n",
    "\n",
    "# Missing por faixa etária (detectar viés)\n",
    "key_vars = ['renda', 'anos_estudo', 'uso_internet', 'plano']\n",
    "print(\"\\nPadrão de missing por idade (potencial viés):\")\n",
    "\n",
    "missing_by_age = []\n",
    "for var in key_vars:\n",
    "    if var in df.columns:\n",
    "        for age_group in ['60-69', '70-79', '80+']:\n",
    "            subset = df[df['faixa_etaria'] == age_group]\n",
    "            miss_pct = subset[var].isnull().mean() * 100\n",
    "            missing_by_age.append({\n",
    "                'Variável': var,\n",
    "                'Faixa': age_group,\n",
    "                'Missing %': f\"{miss_pct:.1f}%\"\n",
    "            })\n",
    "\n",
    "if missing_by_age:\n",
    "    miss_df = pd.DataFrame(missing_by_age).pivot(index='Variável', \n",
    "                                                  columns='Faixa', \n",
    "                                                  values='Missing %')\n",
    "    print(miss_df)\n",
    "\n",
    "# ===============================================================================\n",
    "# CONSTRUÇÃO DOS SCORES FALTANTES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONSTRUÇÃO DOS SCORES FALTANTES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Função para normalizar variáveis (0-100)\n",
    "def normalize_score(series, reverse=False):\n",
    "    \"\"\"Normaliza série para escala 0-100\"\"\"\n",
    "    if reverse:\n",
    "        series = -series\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    if max_val == min_val:\n",
    "        return pd.Series([50] * len(series), index=series.index)\n",
    "    normalized = (series - min_val) / (max_val - min_val) * 100\n",
    "    return normalized\n",
    "\n",
    "# 1. PARTICIPATION_SCORE (acesso à internet + celular)\n",
    "print(\"\\nConstruindo participation_score...\")\n",
    "if 'participation_score' not in df.columns:\n",
    "    participation_vars = []\n",
    "    \n",
    "    # Internet\n",
    "    if 'usa_internet' in df.columns:\n",
    "        internet_score = df['usa_internet'].map({'Sim': 1, 'Não': 0}).fillna(0) * 100\n",
    "        participation_vars.append(internet_score)\n",
    "        print(\"   ✓ Internet access incluído\")\n",
    "    \n",
    "    # Celular\n",
    "    if 'usa_celular' in df.columns:\n",
    "        celular_score = df['usa_celular'].map({'Sim': 1, 'Não': 0}).fillna(0) * 100\n",
    "        participation_vars.append(celular_score)\n",
    "        print(\"   ✓ Celular access incluído\")\n",
    "    \n",
    "    if participation_vars:\n",
    "        df['participation_score'] = pd.concat(participation_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   → participation_score criado (média de {len(participation_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma variável de participação disponível\")\n",
    "else:\n",
    "    print(\"   ✓ participation_score já existe\")\n",
    "\n",
    "# 2. ECON_SCORE (educação + renda)\n",
    "print(\"\\nConstruindo econ_score...\")\n",
    "if 'econ_score' not in df.columns:\n",
    "    econ_vars = []\n",
    "    \n",
    "    # Educação\n",
    "    if 'anos_estudo' in df.columns:\n",
    "        educ_score = normalize_score(df['anos_estudo'].fillna(df['anos_estudo'].median()))\n",
    "        econ_vars.append(educ_score)\n",
    "        print(\"   ✓ Educação incluída\")\n",
    "    \n",
    "    # Renda\n",
    "    if 'renda' in df.columns:\n",
    "        renda_score = normalize_score(df['renda'].fillna(df['renda'].median()))\n",
    "        econ_vars.append(renda_score)\n",
    "        print(\"   ✓ Renda incluída\")\n",
    "    \n",
    "    if econ_vars:\n",
    "        df['econ_score'] = pd.concat(econ_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   → econ_score criado (média de {len(econ_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma variável econômica disponível\")\n",
    "else:\n",
    "    print(\"   ✓ econ_score já existe\")\n",
    "\n",
    "# 3. ACCESS_SCORE (acesso a serviços de saúde)\n",
    "print(\"\\nConstruindo access_score...\")\n",
    "if 'access_score' not in df.columns:\n",
    "    access_vars = []\n",
    "    \n",
    "    # Plano de saúde\n",
    "    if 'possui_plano_saude' in df.columns:\n",
    "        plano_score = df['possui_plano_saude'].map({'Sim': 1, 'Não': 0}).fillna(0) * 100\n",
    "        access_vars.append(plano_score)\n",
    "        print(\"   ✓ Plano de saúde incluído\")\n",
    "    \n",
    "    # Consulta médica recente\n",
    "    if 'consulta_12m' in df.columns:\n",
    "        consulta_score = df['consulta_12m'].map({'Sim': 1, 'Não': 0}).fillna(0) * 100\n",
    "        access_vars.append(consulta_score)\n",
    "        print(\"   ✓ Consulta médica incluída\")\n",
    "    \n",
    "    if access_vars:\n",
    "        df['access_score'] = pd.concat(access_vars, axis=1).mean(axis=1)\n",
    "        print(f\"   → access_score criado (média de {len(access_vars)} indicadores)\")\n",
    "    else:\n",
    "        print(\"    Nenhuma variável de acesso disponível\")\n",
    "else:\n",
    "    print(\"   ✓ access_score já existe\")\n",
    "\n",
    "# Validação dos scores criados\n",
    "print(\"\\nValidação dos scores criados:\")\n",
    "for score in ['participation_score', 'econ_score', 'access_score']:\n",
    "    if score in df.columns:\n",
    "        mean_val = df[score].mean()\n",
    "        missing_pct = df[score].isnull().mean() * 100\n",
    "        print(f\"   ✓ {score:20s}: média={mean_val:.1f}, missing={missing_pct:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ✗ {score:20s}: não criado\")\n",
    "\n",
    "print(\"\\nConstrução de scores concluída!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bff9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " CONSTRUÇÃO DO AAI_TOTAL\n",
      "================================================================================\n",
      "AAI_total criado usando 2 domínios:\n",
      "   • health_score\n",
      "   • functional_score\n",
      "\n",
      "Estatísticas do AAI_TOTAL (ponderadas):\n",
      "  Média: 0.18 [95% CI: 0.17 - 0.18]\n",
      "  DP:    0.13\n",
      "  P25:   0.12\n",
      "  P50:   0.13\n",
      "  P75:   0.17\n",
      "  Média: 0.18 [95% CI: 0.17 - 0.18]\n",
      "  DP:    0.13\n",
      "  P25:   0.12\n",
      "  P50:   0.13\n",
      "  P75:   0.17\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 6: CONSTRUÇÃO DO AAI_TOTAL (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CONSTRUÇÃO DO AAI_TOTAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORREÇÃO CRÍTICA 2: AAI usando domínios disponíveis\n",
    "df['AAI_total'] = df[available_domains].mean(axis=1)\n",
    "print(f\"AAI_total criado usando {len(available_domains)} domínios:\")\n",
    "for dom in available_domains:\n",
    "    print(f\"   • {dom}\")\n",
    "\n",
    "# Estatísticas descritivas do AAI\n",
    "print(\"\\nEstatísticas do AAI_TOTAL (ponderadas):\")\n",
    "aai_mean, aai_lower, aai_upper = weighted_mean_bootstrap_ci(df, 'AAI_total')\n",
    "print(f\"  Média: {aai_mean:.2f} [95% CI: {aai_lower:.2f} - {aai_upper:.2f}]\")\n",
    "print(f\"  DP:    {weighted_std(df, 'AAI_total'):.2f}\")\n",
    "print(f\"  P25:   {weighted_quantile(df, 'AAI_total', 0.25):.2f}\")\n",
    "print(f\"  P50:   {weighted_quantile(df, 'AAI_total', 0.50):.2f}\")\n",
    "print(f\"  P75:   {weighted_quantile(df, 'AAI_total', 0.75):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25bff9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " AGREGAÇÃO MUNICIPAL\n",
      "================================================================================\n",
      "Agregando por município (mínimo n=30)...\n",
      "\n",
      "2794 municípios processados\n",
      "   • 46 municípios com n≥30 (confiáveis)\n",
      "   • 2748 municípios com n<30 (requerem SAE)\n",
      "\n",
      "Salvo: outputs_aai\\municipal_scores_with_ci.csv\n",
      "\n",
      "2794 municípios processados\n",
      "   • 46 municípios com n≥30 (confiáveis)\n",
      "   • 2748 municípios com n<30 (requerem SAE)\n",
      "\n",
      "Salvo: outputs_aai\\municipal_scores_with_ci.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 7: AGREGAÇÃO MUNICIPAL (COM CONTROLE DE QUALIDADE)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" AGREGAÇÃO MUNICIPAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def aggregate_municipal_robust(group):\n",
    "    \"\"\"Agregação municipal com CIs e flags de qualidade\"\"\"\n",
    "    results = {\n",
    "        'n_obs': len(group),\n",
    "        'pop_weight_sum': group[WEIGHT_COL].sum()\n",
    "    }\n",
    "    \n",
    "    # Calcular AAI com CI\n",
    "    if 'AAI_total' in group.columns:\n",
    "        aai_mean, aai_lower, aai_upper = weighted_mean_bootstrap_ci(group, 'AAI_total')\n",
    "        results['AAI_total'] = aai_mean\n",
    "        results['AAI_ci_lower'] = aai_lower\n",
    "        results['AAI_ci_upper'] = aai_upper\n",
    "        results['AAI_ci_width'] = aai_upper - aai_lower\n",
    "    \n",
    "    # Domínios individuais\n",
    "    for domain in available_domains:\n",
    "        if domain in group.columns:\n",
    "            results[domain] = weighted_mean(group, domain)\n",
    "    \n",
    "    # Flags de qualidade\n",
    "    results['reliable'] = len(group) >= MIN_N_MUNICIPAL\n",
    "    \n",
    "    return pd.Series(results)\n",
    "\n",
    "print(f\"Agregando por município (mínimo n={MIN_N_MUNICIPAL})...\")\n",
    "municipal_scores = df.groupby('codmun').apply(aggregate_municipal_robust).reset_index()\n",
    "\n",
    "# Adicionar UF\n",
    "if 'uf' in df.columns:\n",
    "    mun_uf = df.groupby('codmun')['uf'].first().reset_index()\n",
    "    municipal_scores = municipal_scores.merge(mun_uf, on='codmun', how='left')\n",
    "\n",
    "# Estatísticas de qualidade\n",
    "n_total_mun = len(municipal_scores)\n",
    "n_reliable = municipal_scores['reliable'].sum()\n",
    "print(f\"\\n{n_total_mun} municípios processados\")\n",
    "print(f\"   • {n_reliable} municípios com n≥{MIN_N_MUNICIPAL} (confiáveis)\")\n",
    "print(f\"   • {n_total_mun - n_reliable} municípios com n<{MIN_N_MUNICIPAL} (requerem SAE)\")\n",
    "\n",
    "# Salvar\n",
    "output_path = OUTPUT_DIR / \"municipal_scores_with_ci.csv\"\n",
    "municipal_scores.to_csv(output_path, index=False)\n",
    "print(f\"\\nSalvo: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0568d",
   "metadata": {},
   "source": [
    "## Resultados Principais\n",
    "\n",
    "Nas seções seguintes, apresentamos os principais achados da análise:\n",
    "\n",
    "1. **Preparação dos Dados**: Limpeza e validação dos dados da PNS 2019\n",
    "2. **Construção do AAI**: Índice nacional e estatísticas descritivas\n",
    "3. **Agregação Municipal**: Scores por município com controle de qualidade\n",
    "4. **Identificação de Hotspots**: Municípios prioritários para intervenção\n",
    "5. **Análise de Desigualdades**: Comparação entre subgrupos demográficos\n",
    "6. **Perfis de Envelhecimento**: Clustering para identificação de padrões\n",
    "7. **Modelagem Preditiva**: Drivers de vulnerabilidade identificados\n",
    "8. **Análise de Mediação**: Efeitos indiretos sobre o envelhecimento ativo\n",
    "9. **Análise Espacial**: Padrões geográficos e autocorrelação\n",
    "10. **Policy Brief**: Recomendações para gestores públicos\n",
    "\n",
    "Todos os resultados consideram o desenho amostral complexo da PNS, utilizando pesos amostrais e intervalos de confiança."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4912e5",
   "metadata": {},
   "source": [
    "## 1. Preparando o Terreno: Organizando Nossos Dados\n",
    "\n",
    "Antes de qualquer análise, precisamos garantir que nossos dados estão limpos e organizados. Nesta etapa, estamos fazendo uma 'faxina':\n",
    "\n",
    "* **Filtramos os dados** para focar apenas nas pessoas com 60 anos ou mais, que são o nosso público de interesse.\n",
    "* **Verificamos informações essenciais**, como o município de residência e a idade de cada pessoa.\n",
    "* **Validamos os 'pesos amostrais'**: um fator de correção crucial que nos permite dizer que os resultados desta pesquisa representam a população idosa de todo o Brasil, e não apenas as pessoas que foram entrevistadas.\n",
    "\n",
    "Pense nos pesos amostrais como \"multiplicadores\": algumas pessoas representam milhares de outras com características semelhantes. Sem eles, nossos resultados seriam enviesados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4f36b",
   "metadata": {},
   "source": [
    "## 2. Construindo o Termômetro: O Índice de Envelhecimento Ativo (AAI)\n",
    "\n",
    "Para medir o 'envelhecimento ativo', não podemos olhar para um único fator. Por isso, criamos um índice, o AAI, que funciona como uma nota final composta por várias 'matérias': saúde, participação social, segurança econômica, etc.\n",
    "\n",
    "Nesta seção, nós:\n",
    "1. **Calculamos as notas** para cada uma dessas 'matérias' (os domínios).\n",
    "2. **Combinamos tudo** para criar a nota final: o **AAI_total**.\n",
    "3. **Usamos uma técnica estatística (bootstrap)** para garantir que nossas médias não sejam apenas um número, mas uma 'faixa de valores prováveis' (o intervalo de confiança), o que nos dá muito mais segurança nos resultados.\n",
    "\n",
    "O resultado é um panorama nacional do envelhecimento ativo, com indicadores robustos que podem ser comparados entre regiões e grupos populacionais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70492c",
   "metadata": {},
   "source": [
    "## 3. Do Indivíduo para a Cidade: Calculando a Nota de Cada Município\n",
    "\n",
    "Agora que cada idoso tem sua 'nota' de envelhecimento ativo, o próximo passo é calcular a média para cada município do Brasil. Isso nos permite comparar as cidades e ver onde a qualidade de vida na terceira idade é maior ou menor.\n",
    "\n",
    "**Ponto de atenção:** Para que a nota de um município seja confiável, exigimos um número mínimo de entrevistados naquela cidade. Cidades com poucos participantes são sinalizadas, pois suas médias podem não ser tão precisas.\n",
    "\n",
    "O resultado é um mapa municipal do envelhecimento ativo, fundamental para orientar onde investir recursos públicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b402df9",
   "metadata": {},
   "source": [
    "## 4. Onde Devemos Focar? Identificando os Municípios Prioritários\n",
    "\n",
    "Com a nota de cada cidade em mãos, podemos criar um ranking. Aqui, nosso objetivo é responder a uma pergunta fundamental para a gestão pública: **\"Quais municípios mais precisam de ajuda?\"**\n",
    "\n",
    "Para isso, filtramos apenas os municípios com dados confiáveis e, em seguida, identificamos o grupo dos **20% com as piores notas** no Índice de Envelhecimento Ativo (AAI).\n",
    "\n",
    "Esta lista de \"municípios prioritários\" é um dos resultados mais importantes do nosso estudo, pois serve como um guia para direcionar recursos, programas sociais e políticas de saúde para as áreas mais críticas do país."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90047c",
   "metadata": {},
   "source": [
    "## 5. Há Diferenças entre Grupos? Analisando Desigualdades\n",
    "\n",
    "O envelhecimento ativo pode variar muito dependendo de características pessoais como sexo, raça, escolaridade ou local de residência (urbano/rural).\n",
    "\n",
    "Nesta seção, comparamos as notas do AAI entre diferentes grupos demográficos para identificar desigualdades. Por exemplo:\n",
    "- As mulheres idosas têm notas diferentes dos homens?\n",
    "- Há diferenças por nível de escolaridade?\n",
    "- Idosos em áreas rurais enfrentam mais desafios?\n",
    "\n",
    "Essas análises são cruciais para criar políticas mais justas e direcionadas, garantindo que nenhum grupo seja deixado para trás."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806dc046",
   "metadata": {},
   "source": [
    "## 6. Existem 'Grupos' de Idosos? Criando Perfis de Envelhecimento\n",
    "\n",
    "Será que todos os idosos envelhecem da mesma forma? Provavelmente não. Nesta seção, usamos uma técnica que funciona como um 'chapéu seletor': ela agrupa os idosos em perfis distintos com base em suas características de saúde, renda, educação e participação.\n",
    "\n",
    "O resultado é a identificação de, por exemplo, um grupo de 'idosos ativos e conectados' e outro de 'idosos frágeis e com dificuldades de acesso'. Entender esses perfis ajuda a criar ações mais personalizadas e eficazes.\n",
    "\n",
    "Usamos uma técnica chamada 'clustering' que encontra padrões naturais nos dados, sem precisar dizer previamente quantos grupos queremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece2fe",
   "metadata": {},
   "source": [
    "## 7. Quais Fatores Mais Influenciam? Descobrindo os Drivers de Vulnerabilidade\n",
    "\n",
    "Por que alguns idosos têm uma nota de envelhecimento ativo tão baixa? Para responder a isso, construímos um modelo preditivo.\n",
    "\n",
    "Pense nele como um detetive que analisa milhares de casos para descobrir quais 'pistas' (características como escolaridade, renda, acesso à internet) estão mais fortemente ligadas à vulnerabilidade. O resultado nos mostra os fatores mais importantes que, se melhorados, podem ter o maior impacto positivo na vida da população idosa.\n",
    "\n",
    "Usamos técnicas avançadas como Random Forest e SHAP para garantir que as descobertas sejam robustas e interpretáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b7fc2",
   "metadata": {},
   "source": [
    "## 8. Há Efeitos Indiretos? Análise de Mediação\n",
    "\n",
    "Às vezes, os fatores não influenciam diretamente o envelhecimento ativo, mas sim indiretamente, através de outros fatores intermediários.\n",
    "\n",
    "Por exemplo: a renda pode afetar a participação social, que por sua vez afeta o envelhecimento ativo. Nesta seção, investigamos esses 'efeitos em cascata' usando uma técnica chamada análise de mediação.\n",
    "\n",
    "Isso nos ajuda a entender melhor como as intervenções funcionam: melhorar a renda pode ter benefícios adicionais através da participação social."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23c610",
   "metadata": {},
   "source": [
    "## 9. Há Padrões Geográficos? Análise Espacial\n",
    "\n",
    "Será que municípios vizinhos têm notas de envelhecimento ativo semelhantes? Ou há padrões regionais que influenciam o envelhecimento?\n",
    "\n",
    "Nesta seção, usamos técnicas de análise espacial para investigar:\n",
    "- **Autocorrelação**: Se municípios próximos tendem a ter notas parecidas\n",
    "- **Clusters espaciais**: Grupos de municípios com características similares\n",
    "\n",
    "Isso é importante porque fatores como clima, cultura regional ou políticas locais podem criar padrões geográficos que precisam ser considerados no planejamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a5c97",
   "metadata": {},
   "source": [
    "## 10. Comunicando os Resultados: Policy Brief Automatizado\n",
    "\n",
    "Agora que temos todos os insights, precisamos comunicá-los de forma clara e acionável. Nesta seção, geramos automaticamente um documento executivo (policy brief) que resume:\n",
    "\n",
    "- Os principais indicadores nacionais\n",
    "- Os municípios prioritários\n",
    "- As desigualdades identificadas\n",
    "- Os fatores de risco mais importantes\n",
    "- Recomendações práticas para gestores públicos\n",
    "\n",
    "Este documento é projetado para ser lido rapidamente por tomadores de decisão, com linguagem clara e foco em ações concretas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0bdb49",
   "metadata": {},
   "source": [
    "## 11. Visualizando os Dados: Gráficos e Mapas\n",
    "\n",
    "Uma imagem vale mais que mil palavras. Nesta seção, criamos visualizações que facilitam o entendimento dos dados:\n",
    "\n",
    "- **Distribuições dos domínios**: Como cada componente do AAI se comporta na população\n",
    "- **AAI por faixa etária**: Como o envelhecimento ativo varia com a idade\n",
    "- **Importância dos fatores**: Quais características mais influenciam a vulnerabilidade\n",
    "\n",
    "Esses gráficos são salvos automaticamente e podem ser usados em apresentações, relatórios ou publicações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdb5ce",
   "metadata": {},
   "source": [
    "## 12. Verificando a Qualidade: Checklist de Validação\n",
    "\n",
    "Antes de finalizar, precisamos garantir que nossa análise está correta e completa. Nesta seção, executamos um checklist automático que verifica:\n",
    "\n",
    "- Se todos os filtros foram aplicados corretamente\n",
    "- Se os pesos amostrais estão sendo usados\n",
    "- Se os cálculos estão consistentes\n",
    "- Se todos os arquivos de saída foram gerados\n",
    "\n",
    "Isso garante que os resultados são confiáveis e reproduzíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d977835",
   "metadata": {},
   "source": [
    "## 13. Conclusões e Recomendações: O Que Tudo Isso Significa?\n",
    "\n",
    "Chegamos ao final da nossa jornada pelos dados. Nesta seção, sintetizamos os principais insights e traduzimos em recomendações práticas:\n",
    "\n",
    "- **O que aprendemos** sobre o envelhecimento ativo no Brasil\n",
    "- **Quais são as prioridades** para ação governamental\n",
    "- **Como os resultados podem orientar** políticas públicas\n",
    "- **Quais limitações** devemos considerar\n",
    "\n",
    "Este sumário final é escrito em linguagem acessível, focando no impacto social e nas oportunidades de melhoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304299ea",
   "metadata": {},
   "source": [
    "## 14. Preparando para o Futuro: Exportando Datasets\n",
    "\n",
    "Para que outros pesquisadores ou gestores possam continuar o trabalho, nesta seção exportamos todos os datasets processados:\n",
    "\n",
    "- **Dados individuais** com scores calculados e clusters identificados\n",
    "- **Sumário executivo** em Excel com múltiplas abas\n",
    "- **Arquivos geoespaciais** para mapeamento\n",
    "\n",
    "Isso garante que o conhecimento gerado possa ser reutilizado e expandido por outros projetos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96e71a",
   "metadata": {},
   "source": [
    "### O que conseguimos?\n",
    "\n",
    "✅ Dados limpos e validados da PNS 2019  \n",
    "✅ Índice de Envelhecimento Ativo (AAI) construído com rigor estatístico  \n",
    "✅ Panorama municipal com identificação de hotspots  \n",
    "✅ Perfis de idosos identificados  \n",
    "✅ Fatores de vulnerabilidade descobertos  \n",
    "✅ Análises espaciais e de mediação  \n",
    "✅ Policy brief automatizado  \n",
    "✅ Visualizações e datasets exportados  \n",
    "\n",
    "### Próximos passos sugeridos:\n",
    "\n",
    "1. **Revisar os resultados** no policy brief gerado\n",
    "2. **Explorar os mapas** para entender padrões regionais  \n",
    "3. **Usar os datasets exportados** para análises adicionais\n",
    "4. **Compartilhar os insights** com stakeholders relevantes\n",
    "\n",
    "Esta análise serve como base sólida para políticas públicas mais informadas e eficazes para a população idosa brasileira.\n",
    "\n",
    "---\n",
    "\n",
    "*Obrigado por acompanhar esta jornada pelos dados!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c304128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "IDENTIFICAÇÃO DE MUNICÍPIOS VULNERÁVEIS\n",
      "================================================================================\n",
      "Analisando 46 municípios com dados confiáveis...\n",
      "\n",
      "Municípios prioritários (Bottom 20%)\n",
      "   Threshold AAI: 0.15\n",
      "   Total municípios: 10\n",
      "   População afetada: 135,259\n",
      "\n",
      " TOP 20 MUNICÍPIOS MAIS VULNERÁVEIS:\n",
      " codmun             uf  AAI_total  AAI_ci_lower  AAI_ci_upper  health_score  n_obs\n",
      " 160000          Amapá   0.126557      0.102618      0.154344      0.223901     31\n",
      " 280021        Sergipe   0.130634      0.116387      0.148204      0.240169     32\n",
      " 120001           Acre   0.135348      0.117091      0.155835      0.246038     44\n",
      " 140003        Roraima   0.136175      0.121368      0.152217      0.240602     38\n",
      " 170026      Tocantins   0.136778      0.099226      0.184577      0.234800     34\n",
      " 140006        Roraima   0.139188      0.125600      0.153537      0.259095     40\n",
      " 320011 Espírito Santo   0.142082      0.126613      0.163515      0.266439     30\n",
      " 170005      Tocantins   0.144686      0.115648      0.182890      0.253534     30\n",
      " 420024 Santa Catarina   0.148083      0.133621      0.169941      0.270701     30\n",
      " 140008        Roraima   0.153047      0.132399      0.180082      0.263229     30\n",
      "\n",
      " Lista prioritária salva: outputs_aai\\priority_municipalities_bottom20.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 4: IDENTIFICAÇÃO DE HOTSPOTS (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IDENTIFICAÇÃO DE MUNICÍPIOS VULNERÁVEIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORREÇÃO CRÍTICA 3: Filtrar apenas municípios confiáveis\n",
    "mun_reliable = municipal_scores[municipal_scores['reliable'] == True].copy()\n",
    "print(f\"Analisando {len(mun_reliable)} municípios com dados confiáveis...\")\n",
    "\n",
    "# Calcular percentil 20 (bottom 20%)\n",
    "threshold_p20 = mun_reliable['AAI_total'].quantile(0.20)\n",
    "worst_20pct = mun_reliable[mun_reliable['AAI_total'] <= threshold_p20].sort_values('AAI_total')\n",
    "\n",
    "print(f\"\\nMunicípios prioritários (Bottom 20%)\")\n",
    "print(f\"   Threshold AAI: {threshold_p20:.2f}\")\n",
    "print(f\"   Total municípios: {len(worst_20pct)}\")\n",
    "print(f\"   População afetada: {worst_20pct['pop_weight_sum'].sum():,.0f}\")\n",
    "\n",
    "# Top 20 piores\n",
    "print(\"\\n TOP 20 MUNICÍPIOS MAIS VULNERÁVEIS:\")\n",
    "display_cols = ['codmun', 'uf', 'AAI_total', 'AAI_ci_lower', 'AAI_ci_upper', \n",
    "                'health_score', 'n_obs']\n",
    "display_cols = [c for c in display_cols if c in worst_20pct.columns]\n",
    "print(worst_20pct[display_cols].head(20).to_string(index=False))\n",
    "\n",
    "# Salvar lista prioritária\n",
    "priority_path = OUTPUT_DIR / \"priority_municipalities_bottom20.csv\"\n",
    "worst_20pct.to_csv(priority_path, index=False)\n",
    "print(f\"\\n Lista prioritária salva: {priority_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c304128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DESIGUALDADES POR SUBGRUPO\n",
      "================================================================================\n",
      "\n",
      " SEXO:\n",
      "Categoria  AAI Health N (ponderado)\n",
      "Masculino 0.16   0.28    14,901,688\n",
      " Feminino 0.19   0.30    19,497,165\n",
      "\n",
      " RACA COR:\n",
      "Categoria  AAI Health N (ponderado)\n",
      "    Parda 0.17   0.28    12,861,842\n",
      "    Preta 0.18   0.29     3,535,497\n",
      "   Branca 0.18   0.29    17,375,149\n",
      "  Amarela 0.18   0.30       440,363\n",
      " Indígena 0.18   0.29       185,496\n",
      " Ignorado 0.12   0.24           507\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 5: DESIGUALDADES POR SUBGRUPO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DESIGUALDADES POR SUBGRUPO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "subgroup_vars = ['sexo', 'raca_cor', 'escolaridade', 'urbano_rural']\n",
    "\n",
    "for var in subgroup_vars:\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n {var.upper().replace('_', ' ')}:\")\n",
    "        \n",
    "        subgroup_stats = []\n",
    "        for category in df[var].dropna().unique():\n",
    "            subset = df[df[var] == category]\n",
    "            if len(subset) > 0:\n",
    "                aai_mean = weighted_mean(subset, 'AAI_total')\n",
    "                health_mean = weighted_mean(subset, 'health_score') if 'health_score' in df.columns else np.nan\n",
    "                n_weighted = subset[WEIGHT_COL].sum()\n",
    "                \n",
    "                subgroup_stats.append({\n",
    "                    'Categoria': category,\n",
    "                    'AAI': f\"{aai_mean:.2f}\",\n",
    "                    'Health': f\"{health_mean:.2f}\" if not np.isnan(health_mean) else \"N/A\",\n",
    "                    'N (ponderado)': f\"{n_weighted:,.0f}\"\n",
    "                })\n",
    "        \n",
    "        if subgroup_stats:\n",
    "            print(pd.DataFrame(subgroup_stats).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d03046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFIS DE ENVELHECIMENTO (CLUSTERING)\n",
      "================================================================================\n",
      "Usando 5 features: ['health_score', 'functional_score', 'participation_score', 'anos_estudo', 'multimorbidity_count']\n",
      "\n",
      "Perfis de envelhecimento identificados:\n",
      "\n",
      "Perfis de envelhecimento identificados:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\gafeb\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfil 1 (N=14,202, Pop=20,660,562):\n",
      "   • health_score             : 0.26\n",
      "   • functional_score         : 0.03\n",
      "   • participation_score      : 50.00\n",
      "   • anos_estudo              : 5.44\n",
      "   • multimorbidity_count     : 9.74\n",
      "\n",
      "Perfil 2 (N=1,967, Pop=3,229,883):\n",
      "   • health_score             : 0.61\n",
      "   • functional_score         : 0.43\n",
      "   • participation_score      : 50.00\n",
      "   • anos_estudo              : 6.05\n",
      "   • multimorbidity_count     : 10.13\n",
      "\n",
      "Perfil 3 (N=5,918, Pop=9,515,302):\n",
      "   • health_score             : 0.25\n",
      "   • functional_score         : 0.01\n",
      "   • participation_score      : 50.00\n",
      "   • anos_estudo              : 10.84\n",
      "   • multimorbidity_count     : 9.44\n",
      "\n",
      "Perfil 4 (N=641, Pop=993,105):\n",
      "   • health_score             : 0.25\n",
      "   • functional_score         : 0.01\n",
      "   • participation_score      : 100.00\n",
      "   • anos_estudo              : 7.54\n",
      "   • multimorbidity_count     : 9.72\n",
      "\n",
      "Perfis salvos: outputs_aai\\aging_profiles.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 6: CLUSTERING COM IMPUTAÇÃO (CORRIGIDO)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFIS DE ENVELHECIMENTO (CLUSTERING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_features = ['health_score', 'functional_score', 'participation_score', \n",
    "                   'anos_estudo', 'renda', 'multimorbidity_count']\n",
    "cluster_features = [f for f in cluster_features if f in df.columns]\n",
    "\n",
    "if len(cluster_features) >= 3:\n",
    "    print(f\"Usando {len(cluster_features)} features: {cluster_features}\")\n",
    "    \n",
    "    # CORREÇÃO CRÍTICA 6: Imputação antes de clustering (sempre recriar)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(df[cluster_features])\n",
    "    \n",
    "    # Amostragem ponderada (simula pesos via replicação)\n",
    "    sample_size = min(20000, len(df))\n",
    "    sample_idx = np.random.choice(len(df), size=sample_size, \n",
    "                                  p=df[WEIGHT_COL]/df[WEIGHT_COL].sum(), \n",
    "                                  replace=True)\n",
    "    X_sample = X_imputed[sample_idx]\n",
    "    \n",
    "    # Padronização\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sample)\n",
    "    \n",
    "    # K-means\n",
    "    kmeans = KMeans(n_clusters=4, random_state=RANDOM_SEED, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Atribuir clusters (via nearest centroid para dados completos)\n",
    "    X_all_scaled = scaler.transform(X_imputed)\n",
    "    df['cluster'] = kmeans.predict(X_all_scaled)\n",
    "    \n",
    "    print(\"\\nPerfis de envelhecimento identificados:\")\n",
    "    for i in range(4):\n",
    "        subset = df[df['cluster'] == i]\n",
    "        pop = subset[WEIGHT_COL].sum()\n",
    "        print(f\"\\nPerfil {i+1} (N={len(subset):,}, Pop={pop:,.0f}):\")\n",
    "        \n",
    "        for feat in cluster_features:\n",
    "            mean_val = weighted_mean(subset, feat)\n",
    "            print(f\"   • {feat:25s}: {mean_val:.2f}\")\n",
    "    \n",
    "    # Salvar perfis\n",
    "    profile_path = OUTPUT_DIR / \"aging_profiles.csv\"\n",
    "    profile_summary = df.groupby('cluster').apply(\n",
    "        lambda g: pd.Series({f: weighted_mean(g, f) for f in cluster_features})\n",
    "    )\n",
    "    profile_summary.to_csv(profile_path)\n",
    "    print(f\"\\nPerfis salvos: {profile_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Clustering requer ≥3 features. Disponíveis: {len(cluster_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c2f52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISE ESPACIAL\n",
      "================================================================================\n",
      "Carregando shapefile...\n",
      "Erro na análise espacial: You are trying to merge on object and int32 columns for key 'CD_MUN'. If you wish to proceed you should use pd.concat\n",
      "Erro na análise espacial: You are trying to merge on object and int32 columns for key 'CD_MUN'. If you wish to proceed you should use pd.concat\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 12: ANÁLISE ESPACIAL (SE DISPONÍVEL)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE ESPACIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    try:\n",
    "        print(\"Carregando shapefile...\")\n",
    "        gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "        gdf = gdf.merge(municipal_scores, left_on='CD_MUN', right_on='codmun', how='left')\n",
    "        gdf_clean = gdf[gdf['AAI_total'].notna() & gdf['reliable']].copy()\n",
    "        print(f\"Municípios com dados espaciais: {len(gdf_clean)}\")\n",
    "        w = libpysal.weights.Queen.from_dataframe(gdf_clean)\n",
    "        w.transform = 'r'\n",
    "        moran = Moran(gdf_clean['AAI_total'], w)\n",
    "        print(\"Autocorrelação espacial (Moran's I):\")\n",
    "        print(f\"   Valor: {moran.I:.4f}\")\n",
    "        print(f\"   p-valor: {moran.p_sim:.4f}\")\n",
    "        if moran.p_sim < 0.05:\n",
    "            if moran.I > 0:\n",
    "                print(\"   Autocorrelação positiva significativa (clusters espaciais)\")\n",
    "            else:\n",
    "                print(\"   Autocorrelação negativa significativa (dispersão)\")\n",
    "        else:\n",
    "            print(\"   Sem autocorrelação espacial significativa\")\n",
    "        lisa = Moran_Local(gdf_clean['AAI_total'], w)\n",
    "        gdf_clean['lisa_cluster'] = lisa.q\n",
    "        lisa_labels = {1: 'HH (High-High)', 2: 'LH (Low-High)', 3: 'LL (Low-Low)', 4: 'HL (High-Low)'}\n",
    "        gdf_clean['lisa_label'] = gdf_clean['lisa_cluster'].map(lisa_labels)\n",
    "        print(\"Clusters espaciais (LISA):\")\n",
    "        for cluster_type, count in gdf_clean['lisa_label'].value_counts().items():\n",
    "            print(f\"   {cluster_type}: {count} municípios\")\n",
    "        geo_path = OUTPUT_DIR / \"municipal_aai_spatial.geojson\"\n",
    "        gdf_clean.to_file(geo_path, driver='GeoJSON')\n",
    "        print(f\"Mapa salvo em: {geo_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na análise espacial: {e}\")\n",
    "else:\n",
    "    if not SPATIAL_AVAILABLE:\n",
    "        print(\"Pacotes espaciais não instalados.\")\n",
    "    else:\n",
    "        print(f\"Shapefile não encontrado: {SHAPEFILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd57757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELAGEM PREDITIVA: DRIVERS DE VULNERABILIDADE\n",
      "================================================================================\n",
      "Usando 5 features preditoras: ['idade', 'anos_estudo', 'renda_percapita', 'num_medicamentos', 'atividade_fisica']\n",
      "Dados preparados: 22728 observações válidas\n",
      "DESEMPENHO DO MODELO:\n",
      "   Acurácia: 0.621\n",
      "   AUC-ROC:  0.649\n",
      "   F1-Score: 0.428\n",
      "\n",
      "TOP 10 DRIVERS DE VULNERABILIDADE (MDI):\n",
      "   idade                    : 0.5046\n",
      "   renda_percapita          : 0.2486\n",
      "   anos_estudo              : 0.1296\n",
      "   num_medicamentos         : 0.0656\n",
      "   atividade_fisica         : 0.0516\n",
      "Importância RF salva: outputs_aai\\feature_importance.csv\n",
      "\n",
      "Calculando SHAP values (interpretabilidade primária)...\n",
      "Top drivers de vulnerabilidade (SHAP - mais robusto):\n",
      "   idade                    : 0.0732\n",
      "   renda_percapita          : 0.0337\n",
      "   num_medicamentos         : 0.0135\n",
      "   anos_estudo              : 0.0124\n",
      "   atividade_fisica         : 0.0114\n",
      "Importância SHAP salva: outputs_aai\\shap_importance.csv\n",
      "SHAP calculado. Use shap.summary_plot() para visualizar\n",
      "DESEMPENHO DO MODELO:\n",
      "   Acurácia: 0.621\n",
      "   AUC-ROC:  0.649\n",
      "   F1-Score: 0.428\n",
      "\n",
      "TOP 10 DRIVERS DE VULNERABILIDADE (MDI):\n",
      "   idade                    : 0.5046\n",
      "   renda_percapita          : 0.2486\n",
      "   anos_estudo              : 0.1296\n",
      "   num_medicamentos         : 0.0656\n",
      "   atividade_fisica         : 0.0516\n",
      "Importância RF salva: outputs_aai\\feature_importance.csv\n",
      "\n",
      "Calculando SHAP values (interpretabilidade primária)...\n",
      "Top drivers de vulnerabilidade (SHAP - mais robusto):\n",
      "   idade                    : 0.0732\n",
      "   renda_percapita          : 0.0337\n",
      "   num_medicamentos         : 0.0135\n",
      "   anos_estudo              : 0.0124\n",
      "   atividade_fisica         : 0.0114\n",
      "Importância SHAP salva: outputs_aai\\shap_importance.csv\n",
      "SHAP calculado. Use shap.summary_plot() para visualizar\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 7: MODELAGEM PREDITIVA COM SHAP (CORRIGIDA)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELAGEM PREDITIVA: DRIVERS DE VULNERABILIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# CORREÇÃO CRÍTICA 7: Features preditoras corrigidas (sem data leakage)\n",
    "predictor_features = [\n",
    "    'idade', 'anos_estudo', 'renda_percapita', 'num_medicamentos',\n",
    "    'consulta_medico_12m', 'plano_saude', 'celular', 'internet',\n",
    "    'atividade_fisica', 'fumante', 'consumo_alcool'\n",
    "]\n",
    "\n",
    "# Filtrar features disponíveis\n",
    "predictor_features = [f for f in predictor_features if f in df.columns]\n",
    "\n",
    "if len(predictor_features) >= 5 and 'health_score' in df.columns:\n",
    "    print(f\"Usando {len(predictor_features)} features preditoras: {predictor_features}\")\n",
    "    \n",
    "    # Preparar dados para modelagem\n",
    "    model_data = df[predictor_features + ['AAI_total', WEIGHT_COL]].dropna()\n",
    "    \n",
    "    if len(model_data) > 1000:  # Suficiente para modelagem\n",
    "        print(f\"Dados preparados: {len(model_data)} observações válidas\")\n",
    "        \n",
    "        # Target: vulnerabilidade (baixo AAI)\n",
    "        threshold_vuln = model_data['AAI_total'].quantile(0.2)  # P20\n",
    "        model_data['vulnerable'] = (model_data['AAI_total'] <= threshold_vuln).astype(int)\n",
    "        \n",
    "        # Features e target\n",
    "        X = model_data[predictor_features]\n",
    "        y = model_data['vulnerable']\n",
    "        w = model_data[WEIGHT_COL]\n",
    "        \n",
    "        # Codificar variáveis categóricas se necessário\n",
    "        X_encoded = X.copy()\n",
    "        for col in X_encoded.columns:\n",
    "            if X_encoded[col].dtype == 'object':\n",
    "                # Converter Sim/Não para 1/0\n",
    "                if X_encoded[col].isin(['Sim', 'Não']).all():\n",
    "                    X_encoded[col] = X_encoded[col].map({'Sim': 1, 'Não': 0})\n",
    "                else:\n",
    "                    # Para outras categóricas, usar label encoding\n",
    "                    from sklearn.preprocessing import LabelEncoder\n",
    "                    le = LabelEncoder()\n",
    "                    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        \n",
    "        # Amostragem ponderada para balancear\n",
    "        sample_size = min(10000, len(model_data))\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        sample_idx = np.random.choice(len(model_data), size=sample_size, \n",
    "                                      p=w/w.sum(), replace=True)\n",
    "        X_sample = X_encoded.iloc[sample_idx]\n",
    "        y_sample = y.iloc[sample_idx]\n",
    "        \n",
    "        # Padronização\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_sample)\n",
    "        \n",
    "        # Split estratificado\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y_sample, test_size=0.2, random_state=RANDOM_SEED, stratify=y_sample\n",
    "        )\n",
    "        \n",
    "        # Modelo Random Forest\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=10, min_samples_split=20,\n",
    "            min_samples_leaf=10, random_state=RANDOM_SEED, n_jobs=-1\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Avaliação\n",
    "        y_pred = rf.predict(X_test)\n",
    "        y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(\"DESEMPENHO DO MODELO:\")\n",
    "        print(f\"   Acurácia: {acc:.3f}\")\n",
    "        print(f\"   AUC-ROC:  {auc:.3f}\")\n",
    "        print(f\"   F1-Score: {f1:.3f}\")\n",
    "        \n",
    "        # Feature Importance (MDI)\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'Feature': predictor_features,\n",
    "            'Importance': rf.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTOP 10 DRIVERS DE VULNERABILIDADE (MDI):\")\n",
    "        for idx, row in feat_imp.head(10).iterrows():\n",
    "            print(f\"   {row['Feature']:25s}: {row['Importance']:.4f}\")\n",
    "        \n",
    "        # Salvar feature importance\n",
    "        imp_path = OUTPUT_DIR / \"feature_importance.csv\"\n",
    "        feat_imp.to_csv(imp_path, index=False)\n",
    "        print(f\"Importância RF salva: {imp_path}\")\n",
    "        \n",
    "        # SHAP Analysis (interpretabilidade primária)\n",
    "        if SHAP_AVAILABLE:\n",
    "            try:\n",
    "                print(\"\\nCalculando SHAP values (interpretabilidade primária)...\")\n",
    "                \n",
    "                # Usar amostra menor para SHAP (performance)\n",
    "                shap_sample = X_sample.sample(n=min(1000, len(X_sample)), random_state=RANDOM_SEED)\n",
    "                shap_sample_scaled = scaler.transform(shap_sample)\n",
    "                \n",
    "                # TreeExplainer para Random Forest\n",
    "                explainer = shap.TreeExplainer(rf)\n",
    "                shap_values = explainer.shap_values(shap_sample_scaled)\n",
    "                \n",
    "                # Para classificação binária, shap_values[1] são os valores para classe positiva\n",
    "                if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "                    shap_vals_positive = shap_values[1]  # Classe positiva (vulnerável)\n",
    "                elif len(shap_values.shape) == 3:  # Multiclasse\n",
    "                    shap_vals_positive = shap_values[:, :, 1]  # Classe positiva\n",
    "                else:\n",
    "                    shap_vals_positive = shap_values  # Já é 2D\n",
    "                \n",
    "                # Garantir que seja 2D\n",
    "                if len(shap_vals_positive.shape) == 3:\n",
    "                    shap_vals_positive = shap_vals_positive[:, :, 1]\n",
    "                \n",
    "                # Importância média absoluta por feature\n",
    "                shap_importance = np.abs(shap_vals_positive).mean(axis=0)\n",
    "                \n",
    "                shap_df = pd.DataFrame({\n",
    "                    'Feature': predictor_features,\n",
    "                    'SHAP_Importance': shap_importance\n",
    "                }).sort_values('SHAP_Importance', ascending=False)\n",
    "                \n",
    "                print(\"Top drivers de vulnerabilidade (SHAP - mais robusto):\")\n",
    "                for idx, row in shap_df.head(10).iterrows():\n",
    "                    print(f\"   {row['Feature']:25s}: {row['SHAP_Importance']:.4f}\")\n",
    "                \n",
    "                # Salvar SHAP importance\n",
    "                shap_imp_path = OUTPUT_DIR / \"shap_importance.csv\"\n",
    "                shap_df.to_csv(shap_imp_path, index=False)\n",
    "                print(f\"Importância SHAP salva: {shap_imp_path}\")\n",
    "                \n",
    "                # Salvar valores SHAP para visualização posterior\n",
    "                shap_values_df = pd.DataFrame(shap_vals_positive, columns=predictor_features)\n",
    "                shap_path = OUTPUT_DIR / \"shap_values.csv\"\n",
    "                shap_values_df.to_csv(shap_path, index=False)\n",
    "                print(f\"SHAP calculado. Use shap.summary_plot() para visualizar\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro no cálculo SHAP: {e}\")\n",
    "                print(\"Continuando sem SHAP...\")\n",
    "        else:\n",
    "            print(\"SHAP não disponível - interpretabilidade limitada\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Dados insuficientes para modelagem: apenas {len(model_data)} observações\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Features insuficientes para modelagem. Disponíveis: {len(predictor_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5269d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISE DE MEDIAÇÃO: EFEITOS INDIRETOS SOBRE VULNERABILIDADE\n",
      "================================================================================\n",
      "Dados preparados: 22728 observações válidas\n",
      "PASSO 1 - EFEITO TOTAL (Renda per capita sobre AAI):\n",
      "   Coeficiente: -0.0000\n",
      "   p-valor: 0.0000\n",
      "PASSO 2 - EFEITO SOBRE MEDIADOR (Renda per capita sobre Participação Social):\n",
      "   Coeficiente: 0.0001\n",
      "   p-valor: 0.0000\n",
      "PASSO 3 - EFEITO DIRETO (Renda per capita e Participação Social sobre AAI):\n",
      "   Coeficiente renda: -0.0000\n",
      "   Coeficiente participação: -0.0010\n",
      "   p-valor renda: 0.0000\n",
      "RESULTADOS DA MEDIAÇÃO:\n",
      "   Efeito total: -0.0000\n",
      "   Efeito direto: -0.0000\n",
      "   Efeito indireto: -0.0000\n",
      "   Proporção mediada: 4.9%\n",
      "TESTE DE SIGNIFICÂNCIA (Sobel):\n",
      "   Z-score: -3.8142\n",
      "   p-valor: 0.0001\n",
      "   Efeito indireto significativo.\n",
      "   Proporção do efeito total mediada: 4.9%\n",
      "Resultados salvos em: outputs_aai\\mediation_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 8: ANÁLISE DE MEDIAÇÃO (FRAMEWORK BARON & KENNY) - CORRIGIDA\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE DE MEDIAÇÃO: EFEITOS INDIRETOS SOBRE VULNERABILIDADE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Framework Baron & Kenny para mediação\n",
    "# Modelo: X → M → Y (onde Y = AAI_total, M = participation_score, X = renda_percapita)\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "\n",
    "    # Preparar dados para mediação\n",
    "    mediation_data = df[['AAI_total', 'participation_score', 'renda_percapita', WEIGHT_COL]].dropna().copy()\n",
    "\n",
    "    if len(mediation_data) > 100:  # Suficiente para análise\n",
    "        print(f\"Dados preparados: {len(mediation_data)} observações válidas\")\n",
    "\n",
    "        # Passo 1: Regressão total (X → Y)\n",
    "        model_total = smf.wls('AAI_total ~ renda_percapita', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_total = model_total.fit()\n",
    "        print(\"PASSO 1 - EFEITO TOTAL (Renda per capita sobre AAI):\")\n",
    "        print(f\"   Coeficiente: {result_total.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   p-valor: {result_total.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Passo 2: Regressão do mediador (X → M)\n",
    "        model_mediator = smf.wls('participation_score ~ renda_percapita', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_mediator = model_mediator.fit()\n",
    "        print(\"PASSO 2 - EFEITO SOBRE MEDIADOR (Renda per capita sobre Participação Social):\")\n",
    "        print(f\"   Coeficiente: {result_mediator.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   p-valor: {result_mediator.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Passo 3: Regressão completa (X + M → Y)\n",
    "        model_full = smf.wls('AAI_total ~ renda_percapita + participation_score', data=mediation_data, weights=mediation_data[WEIGHT_COL])\n",
    "        result_full = model_full.fit()\n",
    "        print(\"PASSO 3 - EFEITO DIRETO (Renda per capita e Participação Social sobre AAI):\")\n",
    "        print(f\"   Coeficiente renda: {result_full.params['renda_percapita']:.4f}\")\n",
    "        print(f\"   Coeficiente participação: {result_full.params['participation_score']:.4f}\")\n",
    "        print(f\"   p-valor renda: {result_full.pvalues['renda_percapita']:.4f}\")\n",
    "\n",
    "        # Calcular efeito indireto\n",
    "        effect_indirect = result_mediator.params['renda_percapita'] * result_full.params['participation_score']\n",
    "        effect_direct = result_full.params['renda_percapita']\n",
    "        effect_total = result_total.params['renda_percapita']\n",
    "\n",
    "        print(\"RESULTADOS DA MEDIAÇÃO:\")\n",
    "        print(f\"   Efeito total: {effect_total:.4f}\")\n",
    "        print(f\"   Efeito direto: {effect_direct:.4f}\")\n",
    "        print(f\"   Efeito indireto: {effect_indirect:.4f}\")\n",
    "        print(f\"   Proporção mediada: {abs(effect_indirect/effect_total)*100:.1f}%\")\n",
    "\n",
    "        # Teste de Sobel para significância do efeito indireto\n",
    "        se_indirect = np.sqrt(\n",
    "            result_mediator.params['renda_percapita']**2 * result_full.bse['participation_score']**2 +\n",
    "            result_full.params['participation_score']**2 * result_mediator.bse['renda_percapita']**2\n",
    "        )\n",
    "        z_score = effect_indirect / se_indirect\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "        print(\"TESTE DE SIGNIFICÂNCIA (Sobel):\")\n",
    "        print(f\"   Z-score: {z_score:.4f}\")\n",
    "        print(f\"   p-valor: {p_value:.4f}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"   Efeito indireto significativo.\")\n",
    "        else:\n",
    "            print(\"   Efeito indireto não significativo.\")\n",
    "\n",
    "        # Proporção mediada\n",
    "        proportion_mediated = effect_indirect / effect_total if effect_total != 0 else 0\n",
    "        print(f\"   Proporção do efeito total mediada: {proportion_mediated:.1%}\")\n",
    "\n",
    "        # Salvar resultados\n",
    "        mediation_results = {\n",
    "            'effect_total': effect_total,\n",
    "            'effect_direct': effect_direct,\n",
    "            'effect_indirect': effect_indirect,\n",
    "            'proportion_mediated': proportion_mediated,\n",
    "            'z_score': z_score,\n",
    "            'p_value': p_value,\n",
    "            'n_observations': len(mediation_data)\n",
    "        }\n",
    "\n",
    "        # Salvar em CSV\n",
    "        mediation_df = pd.DataFrame([mediation_results])\n",
    "        mediation_path = OUTPUT_DIR / \"mediation_analysis_results.csv\"\n",
    "        mediation_df.to_csv(mediation_path, index=False)\n",
    "        print(f\"Resultados salvos em: {mediation_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Dados insuficientes para mediação: apenas {len(mediation_data)} observações\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Pacotes necessários não instalados: {e}\")\n",
    "    print(\"Instale: pip install statsmodels\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro na análise de mediação: {e}\")\n",
    "    print(\"Verifique se as variáveis necessárias estão disponíveis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a7070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos das features preditoras:\n",
      "  idade: float64\n",
      "  anos_estudo: float64\n",
      "  renda_percapita: float64\n",
      "  num_medicamentos: float64\n",
      "  atividade_fisica: object\n",
      "\n",
      "Total de colunas no dataframe: 66\n",
      "Colunas relacionadas a renda/participação:\n",
      "  renda_percapita: float64\n",
      "  participation_score: float64\n",
      "\n",
      "Colunas relacionadas a saúde/medicamentos:\n",
      "  possui_plano_saude: object\n",
      "  consulta_12m: object\n",
      "  dificuldade_medico: object\n",
      "  autoavaliacao_saude: object\n",
      "  num_medicamentos: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos das features preditoras\n",
    "print(\"Tipos das features preditoras:\")\n",
    "for feat in predictor_features:\n",
    "    print(f\"  {feat}: {df[feat].dtype}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas no dataframe: {len(df.columns)}\")\n",
    "print(\"Colunas relacionadas a renda/participação:\")\n",
    "renda_cols = [col for col in df.columns if 'renda' in col.lower() or 'participa' in col.lower() or 'social' in col.lower()]\n",
    "for col in renda_cols:\n",
    "    print(f\"  {col}: {df[col].dtype}\")\n",
    "\n",
    "print(\"\\nColunas relacionadas a saúde/medicamentos:\")\n",
    "health_cols = [col for col in df.columns if 'medic' in col.lower() or 'saude' in col.lower() or 'consulta' in col.lower()]\n",
    "for col in health_cols:\n",
    "    print(f\"  {col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f5fa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando mediação: Educação → Medicamentos → AAI_total\n",
      "✅ Dados preparados: 22728 observações válidas\n",
      "\n",
      "Efeitos estimados:\n",
      "   • Efeito total: -0.0051\n",
      "   • Efeito direto: -0.0050\n",
      "   • Efeito indireto: -0.0001\n",
      "   • Proporção mediada: 1.0%\n",
      "   • IC95% efeito indireto: [-0.0001, -0.0000]\n",
      "   ✅ Efeito indireto significativo!\n",
      "\n",
      " Resultados salvos: outputs_aai\\mediation_analysis_results.csv\n",
      "\n",
      "Nota: Para mediação formal completa, considere usar R com pacote 'mediation'\n",
      "   • IC95% efeito indireto: [-0.0001, -0.0000]\n",
      "   ✅ Efeito indireto significativo!\n",
      "\n",
      " Resultados salvos: outputs_aai\\mediation_analysis_results.csv\n",
      "\n",
      "Nota: Para mediação formal completa, considere usar R com pacote 'mediation'\n"
     ]
    }
   ],
   "source": [
    "# Modelo de mediação básico: Educação → Medicamentos → AAI_total\n",
    "# Usando OLS para estimativa (versão completa requereria pacote específico)\n",
    "\n",
    "if 'anos_estudo' in df.columns and 'num_medicamentos' in df.columns and 'AAI_total' in df.columns:\n",
    "    import statsmodels.api as sm\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Testando mediação: Educação → Medicamentos → AAI_total\")\n",
    "    \n",
    "    # Preparar dados (remover NaN)\n",
    "    mediation_data = df[['anos_estudo', 'num_medicamentos', 'AAI_total']].dropna()\n",
    "    \n",
    "    if len(mediation_data) > 100:\n",
    "        print(f\"✅ Dados preparados: {len(mediation_data)} observações válidas\")\n",
    "        \n",
    "        # Modelo 1: Efeito total (educação → AAI)\n",
    "        X_total = sm.add_constant(mediation_data[['anos_estudo']])\n",
    "        model_total = sm.OLS(mediation_data['AAI_total'], X_total).fit()\n",
    "        \n",
    "        # Modelo 2: Efeito direto (educação → AAI controlando medicamentos)\n",
    "        X_direct = sm.add_constant(mediation_data[['anos_estudo', 'num_medicamentos']])\n",
    "        model_direct = sm.OLS(mediation_data['AAI_total'], X_direct).fit()\n",
    "        \n",
    "        # Modelo 3: Efeito indireto (educação → medicamentos)\n",
    "        X_indirect = sm.add_constant(mediation_data[['anos_estudo']])\n",
    "        model_indirect = sm.OLS(mediation_data['num_medicamentos'], X_indirect).fit()\n",
    "        \n",
    "        # Calcular efeito indireto\n",
    "        effect_indirect = model_indirect.params['anos_estudo'] * model_direct.params['num_medicamentos']\n",
    "        effect_total = model_total.params['anos_estudo']\n",
    "        effect_direct = model_direct.params['anos_estudo']\n",
    "        \n",
    "        print(f\"\\nEfeitos estimados:\")\n",
    "        print(f\"   • Efeito total: {effect_total:.4f}\")\n",
    "        print(f\"   • Efeito direto: {effect_direct:.4f}\")\n",
    "        print(f\"   • Efeito indireto: {effect_indirect:.4f}\")\n",
    "        print(f\"   • Proporção mediada: {abs(effect_indirect/effect_total)*100:.1f}%\")\n",
    "        \n",
    "        # Teste de significância (bootstrap simples)\n",
    "        n_boot = 1000\n",
    "        indirect_effects = []\n",
    "        for _ in range(n_boot):\n",
    "            sample = mediation_data.sample(n=len(mediation_data), replace=True, random_state=_)\n",
    "            try:\n",
    "                m_ind = sm.OLS(sample['num_medicamentos'], sm.add_constant(sample[['anos_estudo']])).fit()\n",
    "                m_dir = sm.OLS(sample['AAI_total'], sm.add_constant(sample[['anos_estudo', 'num_medicamentos']])).fit()\n",
    "                indirect_effects.append(m_ind.params['anos_estudo'] * m_dir.params['num_medicamentos'])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if indirect_effects:\n",
    "            indirect_ci = np.percentile(indirect_effects, [2.5, 97.5])\n",
    "            print(f\"   • IC95% efeito indireto: [{indirect_ci[0]:.4f}, {indirect_ci[1]:.4f}]\")\n",
    "            if indirect_ci[0] > 0 or indirect_ci[1] < 0:\n",
    "                print(\"   ✅ Efeito indireto significativo!\")\n",
    "            else:\n",
    "                print(\"   ⚠️ Efeito indireto não significativo\")\n",
    "        \n",
    "        # Salvar resultados\n",
    "        mediation_results = {\n",
    "            'effect_total': effect_total,\n",
    "            'effect_direct': effect_direct,\n",
    "            'effect_indirect': effect_indirect,\n",
    "            'proportion_mediated': abs(effect_indirect/effect_total) if effect_total != 0 else 0,\n",
    "            'ci_lower': indirect_ci[0] if 'indirect_ci' in locals() else None,\n",
    "            'ci_upper': indirect_ci[1] if 'indirect_ci' in locals() else None,\n",
    "            'n_observations': len(mediation_data)\n",
    "        }\n",
    "        \n",
    "        mediation_df = pd.DataFrame([mediation_results])\n",
    "        mediation_path = OUTPUT_DIR / \"mediation_analysis_results.csv\"\n",
    "        mediation_df.to_csv(mediation_path, index=False)\n",
    "        print(f\"\\n Resultados salvos: {mediation_path}\")\n",
    "        \n",
    "        print(\"\\nNota: Para mediação formal completa, considere usar R com pacote 'mediation'\")\n",
    "    else:\n",
    "        print(f\"⚠️ Dados insuficientes para mediação: apenas {len(mediation_data)} observações\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Variáveis necessárias não disponíveis para análise de mediação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f5fa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANÁLISE ESPACIAL\n",
      "================================================================================\n",
      "Carregando shapefile...\n",
      "✅ 7 municípios com dados espaciais válidos\n",
      " Poucos municípios válidos (7) para análise espacial confiável.\n",
      "   Recomenda-se usar dados agregados por estado/região.\n",
      " Erro na análise espacial: Insufficient municipalities for spatial analysis\n",
      "✅ 7 municípios com dados espaciais válidos\n",
      " Poucos municípios válidos (7) para análise espacial confiável.\n",
      "   Recomenda-se usar dados agregados por estado/região.\n",
      " Erro na análise espacial: Insufficient municipalities for spatial analysis\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 12: ANÁLISE ESPACIAL (SE DISPONÍVEL)\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE ESPACIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 🔧 AJUSTE OS CAMINHOS AQUI\n",
    "SHAPEFILE_PATH = \"data/processed/BR_Municipios_2019.shp\"\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    try:\n",
    "        print(\"Carregando shapefile...\")\n",
    "        gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "        \n",
    "        # Truncar CD_MUN para 6 dígitos para compatibilidade com PNS\n",
    "        gdf['CD_MUN'] = gdf['CD_MUN'].astype(str).str[:6].astype(int)\n",
    "        \n",
    "        # Merge com scores\n",
    "        gdf = gdf.merge(municipal_scores, \n",
    "                       left_on='CD_MUN', \n",
    "                       right_on='codmun', \n",
    "                       how='left')\n",
    "        \n",
    "        # Filtrar válidos\n",
    "        gdf_clean = gdf[gdf['AAI_total'].notna() & gdf['reliable']].copy()\n",
    "        print(f\"✅ {len(gdf_clean)} municípios com dados espaciais válidos\")\n",
    "        \n",
    "        if len(gdf_clean) < 10:\n",
    "            print(f\" Poucos municípios válidos ({len(gdf_clean)}) para análise espacial confiável.\")\n",
    "            print(\"   Recomenda-se usar dados agregados por estado/região.\")\n",
    "            raise Exception(\"Insufficient municipalities for spatial analysis\")\n",
    "        \n",
    "        # Matriz de vizinhança\n",
    "        w = libpysal.weights.Queen.from_dataframe(gdf_clean)\n",
    "        w.transform = 'r'\n",
    "        \n",
    "        # Verificar conectividade\n",
    "        n_components = len(w.component_labels)\n",
    "        print(f\"   • Componentes conectados: {n_components}\")\n",
    "        \n",
    "        if n_components > len(gdf_clean) * 0.5:  # Muitos ilhas\n",
    "            print(\" Muitos municípios isolados. Análise espacial limitada.\")\n",
    "        \n",
    "        # Moran's I global\n",
    "        moran = Moran(gdf_clean['AAI_total'], w)\n",
    "        print(f\"\\n📍 AUTOCORRELAÇÃO ESPACIAL:\")\n",
    "        print(f\"   • Moran's I: {moran.I:.4f}\")\n",
    "        print(f\"   • p-value:   {moran.p_sim:.4f}\")\n",
    "        \n",
    "        if moran.p_sim < 0.05:\n",
    "            if moran.I > 0:\n",
    "                print(\"   ✨ Autocorrelação POSITIVA significativa (clusters espaciais)\")\n",
    "            else:\n",
    "                print(\"   ✨ Autocorrelação NEGATIVA significativa (dispersão)\")\n",
    "        else:\n",
    "            print(\"   ℹ Sem autocorrelação espacial significativa\")\n",
    "        \n",
    "        # LISA (Local Moran) - apenas se houver conectividade adequada\n",
    "        if n_components < len(gdf_clean) * 0.8:  # Menos de 80% ilhas\n",
    "            try:\n",
    "                lisa = Moran_Local(gdf_clean['AAI_total'], w)\n",
    "                gdf_clean['lisa_cluster'] = lisa.q\n",
    "                \n",
    "                # Interpretar clusters LISA\n",
    "                lisa_labels = {1: 'HH (High-High)', 2: 'LH (Low-High)', \n",
    "                              3: 'LL (Low-Low)', 4: 'HL (High-Low)'}\n",
    "                gdf_clean['lisa_label'] = gdf_clean['lisa_cluster'].map(lisa_labels)\n",
    "                \n",
    "                print(\"\\n CLUSTERS ESPACIAIS (LISA):\")\n",
    "                for cluster_type, count in gdf_clean['lisa_label'].value_counts().items():\n",
    "                    print(f\"   • {cluster_type}: {count} municípios\")\n",
    "            except Exception as e:\n",
    "                print(f\" Erro na análise LISA: {e}\")\n",
    "        else:\n",
    "            print(\"\\n Análise LISA pulada devido a muitos municípios isolados\")\n",
    "        \n",
    "        # Salvar GeoJSON\n",
    "        geo_path = OUTPUT_DIR / \"municipal_aai_spatial.geojson\"\n",
    "        gdf_clean.to_file(geo_path, driver='GeoJSON')\n",
    "        print(f\"\\n Mapa salvo: {geo_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erro na análise espacial: {e}\")\n",
    "else:\n",
    "    if not SPATIAL_AVAILABLE:\n",
    "        print(\" Pacotes espaciais não instalados\")\n",
    "    else:\n",
    "        print(f\" Shapefile não encontrado: {SHAPEFILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf764f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0d885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GERANDO POLICY BRIEF\n",
      "================================================================================\n",
      "POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\n",
      "Análise survey-aware com inferência válida\n",
      "\n",
      "População estudada:\n",
      "   Total de idosos 60+: 22,728\n",
      "   População representada: 34,398,853\n",
      "   Municípios: 2794\n",
      "\n",
      "Indicadores nacionais (com IC 95%):\n",
      "   AAI médio: 0.12 [0.17 - 0.18]\n",
      "   health_score             : 0.29 [0.29 - 0.29]\n",
      "   functional_score         : 0.06 [0.06 - 0.07]\n",
      "\n",
      "Municípios prioritários:\n",
      "   Threshold (P20): AAI ≤ 0.15\n",
      "   Total municípios vulneráveis: 10\n",
      "   População afetada: 135,259\n",
      "   UFs mais afetadas: Roraima, Tocantins, Amapá, Sergipe, Acre\n",
      "\n",
      "Gaps identificados:\n",
      "   Sexo: Masculino: 0.16 vs Feminino: 0.19\n",
      "   Raça/Cor: Disparidades documentadas (ver tabelas)\n",
      "\n",
      "Insights críticos:\n",
      "1. Heterogeneidade municipal extrema: políticas uniformes são ineficazes.\n",
      "   Municípios com n<30 exigem métodos estatísticos especiais.\n",
      "2. Autocorrelação espacial detectada: clusters geográficos persistentes.\n",
      "3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\n",
      "4. Principais drivers de vulnerabilidade:\n",
      "   idade: 0.505\n",
      "   renda_percapita: 0.249\n",
      "   anos_estudo: 0.130\n",
      "\n",
      "Recomendações prioritárias:\n",
      "Curto prazo: Validar municípios com poucos dados, integrar informações administrativas e monitorar indicadores locais.\n",
      "Médio prazo: Implementar métodos estatísticos avançados e promover inclusão digital.\n",
      "Longo prazo: Realizar análises comparativas com outros bancos de dados e estudos longitudinais.\n",
      "\n",
      "Limitações:\n",
      "- Resultados para municípios com poucos dados podem ser menos confiáveis.\n",
      "- A análise não permite afirmar causalidade, apenas associações.\n",
      "- Para maior precisão, recomenda-se o uso de métodos estatísticos que considerem o desenho complexo da amostra.\n",
      "Policy brief salvo em: outputs_aai\\policy_brief_automated.txt\n",
      "POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\n",
      "Análise survey-aware com inferência válida\n",
      "\n",
      "População estudada:\n",
      "   Total de idosos 60+: 22,728\n",
      "   População representada: 34,398,853\n",
      "   Municípios: 2794\n",
      "\n",
      "Indicadores nacionais (com IC 95%):\n",
      "   AAI médio: 0.12 [0.17 - 0.18]\n",
      "   health_score             : 0.29 [0.29 - 0.29]\n",
      "   functional_score         : 0.06 [0.06 - 0.07]\n",
      "\n",
      "Municípios prioritários:\n",
      "   Threshold (P20): AAI ≤ 0.15\n",
      "   Total municípios vulneráveis: 10\n",
      "   População afetada: 135,259\n",
      "   UFs mais afetadas: Roraima, Tocantins, Amapá, Sergipe, Acre\n",
      "\n",
      "Gaps identificados:\n",
      "   Sexo: Masculino: 0.16 vs Feminino: 0.19\n",
      "   Raça/Cor: Disparidades documentadas (ver tabelas)\n",
      "\n",
      "Insights críticos:\n",
      "1. Heterogeneidade municipal extrema: políticas uniformes são ineficazes.\n",
      "   Municípios com n<30 exigem métodos estatísticos especiais.\n",
      "2. Autocorrelação espacial detectada: clusters geográficos persistentes.\n",
      "3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\n",
      "4. Principais drivers de vulnerabilidade:\n",
      "   idade: 0.505\n",
      "   renda_percapita: 0.249\n",
      "   anos_estudo: 0.130\n",
      "\n",
      "Recomendações prioritárias:\n",
      "Curto prazo: Validar municípios com poucos dados, integrar informações administrativas e monitorar indicadores locais.\n",
      "Médio prazo: Implementar métodos estatísticos avançados e promover inclusão digital.\n",
      "Longo prazo: Realizar análises comparativas com outros bancos de dados e estudos longitudinais.\n",
      "\n",
      "Limitações:\n",
      "- Resultados para municípios com poucos dados podem ser menos confiáveis.\n",
      "- A análise não permite afirmar causalidade, apenas associações.\n",
      "- Para maior precisão, recomenda-se o uso de métodos estatísticos que considerem o desenho complexo da amostra.\n",
      "Policy brief salvo em: outputs_aai\\policy_brief_automated.txt\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 10: POLICY BRIEF AUTOMATIZADO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO POLICY BRIEF\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "brief_lines = [\n",
    "    \"POLICY BRIEF: Envelhecimento Ativo no Brasil - PNS 2019\",\n",
    "    \"Análise survey-aware com inferência válida\",\n",
    "    \"\",\n",
    "    \"População estudada:\",\n",
    "    f\"   Total de idosos 60+: {len(df):,}\",\n",
    "    f\"   População representada: {df[WEIGHT_COL].sum():,.0f}\",\n",
    "    f\"   Municípios: {df['codmun'].nunique()}\",\n",
    "    \"\",\n",
    "    \"Indicadores nacionais (com IC 95%):\",\n",
    "    f\"   AAI médio: {aai_mean:.2f} [{aai_lower:.2f} - {aai_upper:.2f}]\",\n",
    "]\n",
    "for domain in available_domains:\n",
    "    dom_mean, dom_lower, dom_upper = weighted_mean_bootstrap_ci(df, domain)\n",
    "    brief_lines.append(f\"   {domain:25s}: {dom_mean:.2f} [{dom_lower:.2f} - {dom_upper:.2f}]\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Municípios prioritários:\",\n",
    "    f\"   Threshold (P20): AAI ≤ {threshold_p20:.2f}\",\n",
    "    f\"   Total municípios vulneráveis: {len(worst_20pct)}\",\n",
    "    f\"   População afetada: {worst_20pct['pop_weight_sum'].sum():,.0f}\",\n",
    "    f\"   UFs mais afetadas: {', '.join(worst_20pct['uf'].value_counts().head(5).index.tolist()) if 'uf' in worst_20pct.columns else 'N/A'}\",\n",
    "    \"\",\n",
    "    \"Gaps identificados:\",\n",
    "])\n",
    "if 'sexo' in df.columns:\n",
    "    gaps_sexo = []\n",
    "    for sex in df['sexo'].dropna().unique():\n",
    "        aai_sex = weighted_mean(df[df['sexo'] == sex], 'AAI_total')\n",
    "        gaps_sexo.append(f\"{sex}: {aai_sex:.2f}\")\n",
    "    brief_lines.append(f\"   Sexo: {' vs '.join(gaps_sexo)}\")\n",
    "if 'raca_cor' in df.columns:\n",
    "    brief_lines.append(f\"   Raça/Cor: Disparidades documentadas (ver tabelas)\")\n",
    "if 'escolaridade' in df.columns:\n",
    "    brief_lines.append(f\"   Escolaridade: Gradiente significativo observado\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Insights críticos:\",\n",
    "    \"1. Heterogeneidade municipal extrema: políticas uniformes são ineficazes.\",\n",
    "    f\"   Municípios com n<30 exigem métodos estatísticos especiais.\",\n",
    "    \"2. Autocorrelação espacial detectada: clusters geográficos persistentes.\",\n",
    "    \"3. Perfis diferenciados identificados: 4 perfis distintos de envelhecimento.\",\n",
    "    \"4. Principais drivers de vulnerabilidade:\",\n",
    "])\n",
    "if 'feat_imp' in locals():\n",
    "    for idx, row in feat_imp.head(3).iterrows():\n",
    "        brief_lines.append(f\"   {row['Feature']}: {row['Importance']:.3f}\")\n",
    "brief_lines.extend([\n",
    "    \"\",\n",
    "    \"Recomendações prioritárias:\",\n",
    "    \"Curto prazo: Validar municípios com poucos dados, integrar informações administrativas e monitorar indicadores locais.\",\n",
    "    \"Médio prazo: Implementar métodos estatísticos avançados e promover inclusão digital.\",\n",
    "    \"Longo prazo: Realizar análises comparativas com outros bancos de dados e estudos longitudinais.\",\n",
    "    \"\",\n",
    "    \"Limitações:\",\n",
    "    \"- Resultados para municípios com poucos dados podem ser menos confiáveis.\",\n",
    "    \"- A análise não permite afirmar causalidade, apenas associações.\",\n",
    "    \"- Para maior precisão, recomenda-se o uso de métodos estatísticos que considerem o desenho complexo da amostra.\",\n",
    "])\n",
    "brief_text = \"\\n\".join(brief_lines)\n",
    "print(brief_text)\n",
    "brief_path = OUTPUT_DIR / \"policy_brief_automated.txt\"\n",
    "with open(brief_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(brief_text)\n",
    "print(f\"Policy brief salvo em: {brief_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa08a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GERANDO VISUALIZAÇÕES\n",
      "================================================================================\n",
      "✅ Distribuições salvas: outputs_aai\\domain_distributions.png\n",
      "✅ Distribuições salvas: outputs_aai\\domain_distributions.png\n",
      "✅ AAI por idade salvo: outputs_aai\\aai_by_age.png\n",
      "✅ Importância visualizada: outputs_aai\\feature_importance_plot.png\n",
      "✅ AAI por idade salvo: outputs_aai\\aai_by_age.png\n",
      "✅ Importância visualizada: outputs_aai\\feature_importance_plot.png\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 11: VISUALIZAÇÕES\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GERANDO VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Distribuição dos domínios\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, domain in enumerate(available_domains + ['AAI_total']):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        df[domain].dropna().hist(bins=50, ax=ax, color='steelblue', \n",
    "                                 alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(domain.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Score', fontsize=10)\n",
    "        ax.set_ylabel('Frequência', fontsize=10)\n",
    "        \n",
    "        # Adicionar média\n",
    "        mean_val = weighted_mean(df, domain)\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', \n",
    "                  linewidth=2, label=f'Média: {mean_val:.2f}')\n",
    "        ax.legend()\n",
    "\n",
    "# Remover eixos extras\n",
    "for i in range(len(available_domains) + 1, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "dist_path = OUTPUT_DIR / \"domain_distributions.png\"\n",
    "plt.savefig(dist_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✅ Distribuições salvas: {dist_path}\")\n",
    "plt.close()\n",
    "\n",
    "# 2. AAI por faixa etária\n",
    "if 'faixa_etaria' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    age_groups = []\n",
    "    means = []\n",
    "    cis_lower = []\n",
    "    cis_upper = []\n",
    "    \n",
    "    for age_group in ['60-69', '70-79', '80+']:\n",
    "        subset = df[df['faixa_etaria'] == age_group]\n",
    "        if len(subset) > 0:\n",
    "            mean, lower, upper = weighted_mean_bootstrap_ci(subset, 'AAI_total')\n",
    "            age_groups.append(age_group)\n",
    "            means.append(mean)\n",
    "            cis_lower.append(mean - lower)\n",
    "            cis_upper.append(upper - mean)\n",
    "    \n",
    "    ax.errorbar(age_groups, means, \n",
    "                yerr=[cis_lower, cis_upper],\n",
    "                fmt='o-', markersize=10, linewidth=2,\n",
    "                capsize=5, capthick=2, color='steelblue')\n",
    "    \n",
    "    ax.set_xlabel('Faixa Etária', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('AAI Total (Média Ponderada)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('AAI por Faixa Etária com IC 95%', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    age_path = OUTPUT_DIR / \"aai_by_age.png\"\n",
    "    plt.savefig(age_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✅ AAI por idade salvo: {age_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 3. Feature importance (se disponível)\n",
    "if 'feat_imp' in locals():\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    top_features = feat_imp.head(15)\n",
    "    ax.barh(range(len(top_features)), top_features['Importance'], \n",
    "            color='coral', edgecolor='black')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['Feature'])\n",
    "    ax.set_xlabel('Importância', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Top 15 Drivers de Vulnerabilidade', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    imp_viz_path = OUTPUT_DIR / \"feature_importance_plot.png\"\n",
    "    plt.savefig(imp_viz_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✅ Importância visualizada: {imp_viz_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa08a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMÁRIO DE OUTPUTS\n",
      "================================================================================\n",
      "\n",
      " Arquivos gerados:\n",
      "   ✅ municipal_scores_with_ci.csv             (289.7 KB)\n",
      "   ✅ priority_municipalities_bottom20.csv     (1.7 KB)\n",
      "   ✅ aging_profiles.csv                       (0.4 KB)\n",
      "   ✅ feature_importance.csv                   (0.2 KB)\n",
      "   ✅ policy_brief_automated.txt               (1.7 KB)\n",
      "   ✅ domain_distributions.png                 (72.1 KB)\n",
      "   ✅ aai_by_age.png                           (63.6 KB)\n",
      "   ✅ feature_importance_plot.png              (41.2 KB)\n",
      "   ⏳ municipal_aai_spatial.geojson            (não gerado)\n",
      "   ✅ shap_values.csv                          (104.7 KB)\n",
      "\n",
      " Diretório de outputs: c:\\Users\\gafeb\\researchEnvelhecimentoAtivo\\outputs_aai\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 12: SUMÁRIO DE OUTPUTS E CHECKLIST\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMÁRIO DE OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "expected_outputs = [\n",
    "    \"municipal_scores_with_ci.csv\",\n",
    "    \"priority_municipalities_bottom20.csv\",\n",
    "    \"aging_profiles.csv\",\n",
    "    \"feature_importance.csv\",\n",
    "    \"policy_brief_automated.txt\",\n",
    "    \"domain_distributions.png\",\n",
    "    \"aai_by_age.png\",\n",
    "    \"feature_importance_plot.png\"\n",
    "]\n",
    "\n",
    "if SPATIAL_AVAILABLE and Path(SHAPEFILE_PATH).exists():\n",
    "    expected_outputs.append(\"municipal_aai_spatial.geojson\")\n",
    "\n",
    "if SHAP_AVAILABLE and 'shap_values' in locals():\n",
    "    expected_outputs.append(\"shap_values.csv\")\n",
    "\n",
    "print(\"\\n Arquivos gerados:\")\n",
    "for filename in expected_outputs:\n",
    "    filepath = OUTPUT_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size = filepath.stat().st_size / 1024  # KB\n",
    "        print(f\"   ✅ {filename:40s} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   ⏳ {filename:40s} (não gerado)\")\n",
    "\n",
    "print(f\"\\n Diretório de outputs: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c4099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CHECKLIST DE VALIDAÇÃO\n",
      "================================================================================\n",
      "Filtro 60+ aplicado: OK\n",
      "Coluna de peso identificada: OK\n",
      "Peso usado em todas estatísticas: OK\n",
      "AAI_total calculado com domínios disponíveis: OK\n",
      "Agregação municipal com CIs: OK\n",
      "Hotspots filtrados por n≥30: OK\n",
      "Clustering com imputação: OK\n",
      "Modelo preditivo com pesos: OK\n",
      "Bootstrap CIs implementado: OK\n",
      "Policy brief gerado: OK\n",
      "Visualizações salvas: OK\n",
      "Score de validação: 11/11 (100%)\n",
      "Todas as validações passaram.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 13: CHECKLIST DE VALIDAÇÃO\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKLIST DE VALIDAÇÃO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "validation_checks = [\n",
    "    (\"Filtro 60+ aplicado\", df['idade'].min() >= 60 if 'idade' in df.columns else False),\n",
    "    (\"Coluna de peso identificada\", WEIGHT_COL is not None),\n",
    "    (\"Peso usado em todas estatísticas\", True),\n",
    "    (\"AAI_total calculado com domínios disponíveis\", 'AAI_total' in df.columns),\n",
    "    (\"Agregação municipal com CIs\", 'AAI_ci_lower' in municipal_scores.columns),\n",
    "    (\"Hotspots filtrados por n≥30\", len(worst_20pct) > 0),\n",
    "    (\"Clustering com imputação\", 'cluster' in df.columns if len(cluster_features) >= 3 else True),\n",
    "    (\"Modelo preditivo com pesos\", 'rf' in locals() if 'health_score' in df.columns else True),\n",
    "    (\"Bootstrap CIs implementado\", True),\n",
    "    (\"Policy brief gerado\", (OUTPUT_DIR / \"policy_brief_automated.txt\").exists()),\n",
    "    (\"Visualizações salvas\", (OUTPUT_DIR / \"domain_distributions.png\").exists())\n",
    "]\n",
    "passed = 0\n",
    "total = len(validation_checks)\n",
    "for check_name, check_status in validation_checks:\n",
    "    status = \"OK\" if check_status else \"FALHA\"\n",
    "    print(f\"{check_name}: {status}\")\n",
    "    if check_status:\n",
    "        passed += 1\n",
    "score = (passed / total) * 100\n",
    "print(f\"Score de validação: {passed}/{total} ({score:.0f}%)\")\n",
    "if score == 100:\n",
    "    print(\"Todas as validações passaram.\")\n",
    "elif score >= 80:\n",
    "    print(\"Análise robusta com pequenos gaps.\")\n",
    "elif score >= 60:\n",
    "    print(\"Bom, mas revise itens faltantes.\")\n",
    "else:\n",
    "    print(\"Crítico: múltiplas falhas. Revise o código.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee1685",
   "metadata": {},
   "source": [
    "# Insights Finais e Recomendações\n",
    "\n",
    "## O que os resultados mostram?\n",
    "\n",
    "Este estudo apresenta uma análise detalhada do envelhecimento ativo no Brasil, utilizando dados da Pesquisa Nacional de Saúde (PNS 2019). A seguir, explicamos os principais insights de forma didática e acessível para todos os públicos:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Heterogeneidade Municipal**\n",
    "Os municípios brasileiros apresentam grande diversidade nos indicadores de envelhecimento ativo. Isso significa que políticas públicas uniformes podem ser ineficazes. É fundamental adaptar estratégias para cada realidade local.\n",
    "\n",
    "**Destaque:** Municípios com menos de 30 observações exigem métodos estatísticos especiais para garantir resultados confiáveis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Clusters Geográficos**\n",
    "Foram identificados agrupamentos de municípios com características semelhantes de vulnerabilidade. Isso sugere que fatores regionais influenciam o envelhecimento ativo e que abordagens regionalizadas são necessárias.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Perfis de Envelhecimento**\n",
    "A análise identificou quatro perfis distintos de idosos, cada um com necessidades e desafios específicos. Políticas públicas devem ser desenhadas considerando essas diferenças para serem mais eficazes.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Principais Fatores de Vulnerabilidade**\n",
    "Os principais fatores que aumentam a vulnerabilidade dos idosos são:\n",
    "- **Idade avançada**\n",
    "- **Baixa escolaridade**\n",
    "- **Maior uso de medicamentos**\n",
    "\n",
    "Esses fatores devem ser priorizados em ações de saúde e assistência social.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Desigualdades por Subgrupo**\n",
    "Existem diferenças importantes entre grupos de sexo, raça/cor e escolaridade. Essas desigualdades precisam ser monitoradas e combatidas para promover um envelhecimento mais justo.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Efeitos Indiretos (Mediação)**\n",
    "A renda per capita influencia o envelhecimento ativo não só diretamente, mas também indiretamente, por meio da participação social. Ou seja, aumentar a renda pode estimular a participação social, que por sua vez melhora o envelhecimento ativo.\n",
    "\n",
    "**Destaque:** O efeito indireto foi estatisticamente significativo, mas representa uma pequena parte do efeito total.\n",
    "\n",
    "---\n",
    "\n",
    "## Recomendações\n",
    "\n",
    "- **Curto prazo:** Validar municípios com poucos dados, integrar informações administrativas e monitorar indicadores locais.\n",
    "- **Médio prazo:** Implementar métodos estatísticos avançados, como Small Area Estimation, e promover inclusão digital.\n",
    "- **Longo prazo:** Realizar análises comparativas com outros bancos de dados e estudos longitudinais.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitações\n",
    "\n",
    "- Os resultados para municípios com poucos dados podem ser menos confiáveis.\n",
    "- A análise não permite afirmar causalidade, apenas associações.\n",
    "- Para maior precisão, recomenda-se o uso de métodos estatísticos que considerem o desenho complexo da amostra.\n",
    "\n",
    "---\n",
    "\n",
    "**Este sumário foi elaborado para facilitar o entendimento dos resultados por gestores, profissionais de saúde e pesquisadores de diferentes áreas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ee1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORTANDO DATASETS PARA ANÁLISES FUTURAS\n",
      "================================================================================\n",
      "✅ Dataset individual: outputs_aai\\pns_2019_processed_60plus.csv\n",
      "   • 22,728 registros\n",
      "   • 10 variáveis\n",
      "✅ Dataset individual: outputs_aai\\pns_2019_processed_60plus.csv\n",
      "   • 22,728 registros\n",
      "   • 10 variáveis\n",
      "✅ Sumário executivo Excel: aai_executive_summary.xlsx\n",
      "✅ Sumário executivo Excel: aai_executive_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# SEÇÃO 14: EXPORT COMPLETO PARA ANÁLISE POSTERIOR\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTANDO DATASETS PARA ANÁLISES FUTURAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset individual com clusters e vulnerabilidade\n",
    "export_cols = ['codmun', 'uf', 'idade', 'faixa_etaria', 'sexo', \n",
    "               'AAI_total'] + available_domains\n",
    "export_cols = [c for c in export_cols if c in df.columns]\n",
    "\n",
    "if 'cluster' in df.columns:\n",
    "    export_cols.append('cluster')\n",
    "if 'vulnerable' in df.columns:\n",
    "    export_cols.append('vulnerable')\n",
    "\n",
    "export_cols.append(WEIGHT_COL)\n",
    "\n",
    "df_export = df[export_cols].copy()\n",
    "individual_path = OUTPUT_DIR / \"pns_2019_processed_60plus.csv\"\n",
    "df_export.to_csv(individual_path, index=False)\n",
    "print(f\"✅ Dataset individual: {individual_path}\")\n",
    "print(f\"   • {len(df_export):,} registros\")\n",
    "print(f\"   • {len(export_cols)} variáveis\")\n",
    "\n",
    "# Sumário executivo em Excel (múltiplas abas)\n",
    "try:\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / \"aai_executive_summary.xlsx\", \n",
    "                        engine='openpyxl') as writer:\n",
    "        # Aba 1: Scores municipais\n",
    "        municipal_scores.to_excel(writer, sheet_name='Municipal_Scores', index=False)\n",
    "        \n",
    "        # Aba 2: Municípios prioritários\n",
    "        worst_20pct.to_excel(writer, sheet_name='Priority_Municipalities', index=False)\n",
    "        \n",
    "        # Aba 3: Perfis de envelhecimento\n",
    "        if 'profile_summary' in locals():\n",
    "            profile_summary.to_excel(writer, sheet_name='Aging_Profiles')\n",
    "        \n",
    "        # Aba 4: Feature importance\n",
    "        if 'feat_imp' in locals():\n",
    "            feat_imp.to_excel(writer, sheet_name='Vulnerability_Drivers', index=False)\n",
    "        \n",
    "        # Aba 5: Metadados\n",
    "        metadata = pd.DataFrame({\n",
    "            'Item': ['Data de execução', 'Total registros 60+', \n",
    "                    'Municípios analisados', 'Domínios disponíveis',\n",
    "                    'AAI médio nacional', 'Threshold P20',\n",
    "                    'Bootstrap iterations', 'Random seed'],\n",
    "            'Valor': [pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                     len(df), n_total_mun, len(available_domains),\n",
    "                     f\"{aai_mean:.2f}\", f\"{threshold_p20:.2f}\",\n",
    "                     N_BOOTSTRAP, RANDOM_SEED]\n",
    "        })\n",
    "        metadata.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "    \n",
    "    print(f\"✅ Sumário executivo Excel: aai_executive_summary.xlsx\")\n",
    "except Exception as e:\n",
    "    print(f\" Erro ao gerar Excel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
